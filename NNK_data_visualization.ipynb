{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yufanlili211/master_thesis/blob/main/NNK_data_visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nswuog9a6VNK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19DS0ROoc1GI",
        "outputId": "4ccc8689-1e08-4aa9-e044-d8419ee94f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9PIIlfy6aRw",
        "outputId": "1a3b3e84-8082-4c8f-8204-427efee5983f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 挂载google drive\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Clear the mount point directory before mounting\n",
        "os.system('rm -rf /content/drive/*')\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "VK-ns6TF-R_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "path=\"/content/drive/MyDrive/master_thesis/NNK_data_visualization/canya-data-source.xlsx\" # NNK1-3\n",
        "df=pd.read_excel(path)\n",
        "head = df.head()\n",
        "sp = df.shape\n",
        "print(head)\n",
        "print(sp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGJSAx1f8vNJ",
        "outputId": "81257204-ce26-4451-e125-f89dc8dc8de5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 aa_seq  seed_bh dataset train_test\n",
            "0  IWTKSCDCVCSCGGYQGCYR        0    NNK1      train\n",
            "1               ILKSFLD        0    NNK1      train\n",
            "2            WTMLDMFLFS        0    NNK1      train\n",
            "3  CLQCKCYNNCVQLRVTVGCM        1    NNK1      train\n",
            "4       WTWILPMVRTIIYQY        0    NNK1      train\n",
            "(111692, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdSJxRTr6YTr"
      },
      "outputs": [],
      "source": [
        "out_dir=\"/content/drive/MyDrive/master_thesis/NNK_data_visualization\" # set output directory for plots\n",
        "plots=[]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.data visualization"
      ],
      "metadata": {
        "id": "zhPtGFz-2uXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.peptide length vs. counts - bar chart"
      ],
      "metadata": {
        "id": "SAXF2hJm9pr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# distribution\n",
        "length_counts = df[\"aa_seq\"].astype(str).str.len().value_counts().sort_index()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.bar(length_counts.index, length_counts.values)\n",
        "plt.yscale(\"log\")\n",
        "plt.ylim(bottom=1)\n",
        "plt.xticks(range(1, 21))\n",
        "plt.xlabel(\"Peptide length\")\n",
        "plt.ylabel(\"Count (log scale)\")\n",
        "plt.title(\"Peptide length distribution\")\n",
        "plt.tight_layout()\n",
        "p1=os.path.join(out_dir,\"length_overall_logcount.png\")\n",
        "fig.savefig(p1, dpi=200)\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "plots.append(p1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0PQ_cKepEyG-",
        "outputId": "dd3c5701-3f62-4121-fe70-81267e5b6212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASdhJREFUeJzt3Xl8THf////nyC4IgkSQxE6UULsuqFSkLUVrqyUoV+saLVJtuVTRVnWjukwpl7X99KILulBdUksXS9AoV1BcqFqCErEGmfP7o9/MTySYiROJk8f9dpvbrfM+Z97v15nI5Nlzzvs9NsMwDAEAAOCWV6ygCwAAAIA5CHYAAAAWQbADAACwCIIdAACARRDsAAAALIJgBwAAYBEEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAPNa/f39FRkZed7+9e/fKZrNp7ty5po1ts9k0fvx40/rLL23atNFtt91mer9XHv/cuXNls9m0d+9e08e60pU/96yf7xtvvJHvY0vS+PHjZbPZbspYwK2KYAcUcll/uLMe/v7+qlWrloYOHarU1NR8G/fgwYMaP368kpOT822MW92t+h6dPXtW48eP18qVKwu6lBwKc23ArYBgB9wiXnjhBX3wwQd699131apVK02bNk0tW7bU2bNn82W8gwcPasKECbmGlpkzZ2rHjh35Mu6t5Frv0c3St29fnTt3ThEREW6/5uzZs5owYYLH4elm/NyvVdtzzz2nc+fO5ev4wK3Ou6ALAOCeuLg4NWnSRJI0aNAgBQcHa8qUKfr888/Vq1evm1qLj4/PTR0PV+fl5SUvL698HePMmTMKDAws8J+7t7e3vL35swVcC2fsgFvUPffcI0nas2ePq+3DDz9U48aNFRAQoLJly6pnz57av39/ttdl3fu1ceNGtWrVSgEBAapataqmT5/u2mflypVq2rSpJGnAgAGuy8BZ98rldo9dWlqa+vfvr6CgIJUuXVrx8fFKS0vLtfbt27fr4YcfVtmyZeXv768mTZroiy++yPN7ceDAAQ0cOFAhISHy8/NTvXr1NHv27Gz7rFy5UjabTR9//LEmTpyoypUry9/fX+3atdOuXbty9OlwOFStWjUFBASoWbNm+vHHH9WmTRu1adPGrfcoS0pKitq2bavixYurUqVKeu2119w6poyMDI0YMULly5dXyZIl1alTJ/3555859svtHrsNGzYoNjZW5cqVc/18Bw4cKOnv++LKly8vSZowYYKr7qz79vr3768SJUpo9+7duu+++1SyZEn17t3bte1q91a++eabioiIUEBAgFq3bq2tW7dm2375e3e5y/u8Xm253WN36dIlvfjii6pevbr8/PwUGRmpf/3rX8rIyMi2X2RkpB544AH99NNPatasmfz9/VWtWjXNnz8/1+MBblX8rw9wi9q9e7ckKTg4WJI0ceJEjR07Vt27d9egQYN09OhRvfPOO7r77rv166+/qnTp0q7XnjhxQvfdd5+6d++uXr166eOPP9aQIUPk6+urgQMHqm7dunrhhRf0/PPP6x//+IfuuusuSVKrVq1yrcUwDD344IP66aef9Pjjj6tu3bpavHix4uPjc+z73//+V3fccYcqVaqkUaNGKTAwUB9//LE6d+6szz77TF26dPHofUhNTVWLFi1ks9k0dOhQlS9fXl9//bUeffRRpaena/jw4dn2f+WVV1SsWDGNHDlSJ0+e1GuvvabevXtr3bp1rn2mTZumoUOH6q677tKIESO0d+9ede7cWWXKlFHlypUlya336MSJE+rQoYO6du2q7t2769NPP9Wzzz6r+vXrKy4u7prHNWjQIH344Yd65JFH1KpVK/3www+6//77r/t+HDlyRO3bt1f58uU1atQolS5dWnv37tWiRYskSeXLl9e0adM0ZMgQdenSRV27dpUkNWjQwNXHpUuXFBsbqzvvvFNvvPGGihcvfs0x58+fr1OnTslut+v8+fN66623dM8992jLli0KCQm5bs1Z3KntSoMGDdK8efP08MMP66mnntK6des0adIkbdu2TYsXL862765du/Twww/r0UcfVXx8vGbPnq3+/furcePGqlevntt1AoWaAaBQmzNnjiHJ+P77742jR48a+/fvNxYsWGAEBwcbAQEBxp9//mns3bvX8PLyMiZOnJjttVu2bDG8vb2ztbdu3dqQZEyePNnVlpGRYTRs2NCoUKGCceHCBcMwDCMpKcmQZMyZMydHTfHx8UZERITr+ZIlSwxJxmuvveZqu3TpknHXXXfl6KNdu3ZG/fr1jfPnz7vanE6n0apVK6NmzZrXfT8kGePGjXM9f/TRR42KFSsax44dy7Zfz549jaCgIOPs2bOGYRjGihUrDElG3bp1jYyMDNd+b731liHJ2LJli+u9CA4ONpo2bWpcvHjRtd/cuXMNSUbr1q1dbdd6j7Le5/nz57vaMjIyjNDQUOOhhx665jEmJycbkox//vOf2dofeeSRHMef9e9jz549hmEYxuLFiw1JRlJS0lX7P3r0aI5+ssTHxxuSjFGjRuW67fKf+549ewxJrn+HWdatW2dIMkaMGOFqa926dbb37mp9Xqu2cePGGZf/2cp6nwYNGpRtv5EjRxqSjB9++MHVFhERYUgyVq9e7Wo7cuSI4efnZzz11FM5xgJuVVyKBW4RMTExKl++vKpUqaKePXuqRIkSWrx4sSpVqqRFixbJ6XSqe/fuOnbsmOsRGhqqmjVrasWKFdn68vb21mOPPeZ67uvrq8cee0xHjhzRxo0bPa5t2bJl8vb21pAhQ1xtXl5eeuKJJ7Ltd/z4cf3www/q3r27Tp065arzr7/+UmxsrHbu3KkDBw64Pa5hGPrss8/UsWNHGYaR7dhjY2N18uRJbdq0KdtrBgwYIF9fX9fzrDNt//vf/yT9fRnzr7/+0uDBg7Pdz9W7d2+VKVPG/TdFUokSJdSnTx/Xc19fXzVr1sw11tUsW7ZMkvTkk09ma7/y7GNuss7MfvXVV7p48aJH9V7u8p/l9XTu3FmVKlVyPW/WrJmaN2/uOo78ktV/QkJCtvannnpKkrR06dJs7VFRUa6ft/T3GcLatWtf9+cB3Eq4FAvcIhwOh2rVqiVvb2+FhISodu3aKlbs7/8327lzpwzDUM2aNXN97ZU3vYeFhSkwMDBbW61atST9fZ9TixYtPKpt3759qlixokqUKJGtvXbt2tme79q1S4ZhaOzYsRo7dmyufR05ciRbSLiWo0ePKi0tTTNmzNCMGTOu2t/lwsPDsz3PCmsnTpxwHYsk1ahRI9t+3t7ebq3dd7nKlSvnuCesTJky+u233675un379qlYsWKqXr16tvYr38/ctG7dWg899JAmTJigN998U23atFHnzp31yCOPyM/Pz626vb29XZec3ZHbv7tatWrp448/druPvMh6n678WYWGhqp06dKun2WWK3/20t8/j6yfPWAFBDvgFtGsWTPXrNgrOZ1O2Ww2ff3117nOkLwycBUUp9MpSRo5cqRiY2Nz3efKP9Lu9NenT59c7+eTct6fdbUZpIZhuD2uu27mWFlsNps+/fRTrV27Vl9++aW++eYbDRw4UJMnT9batWvd+rfg5+fn+p8GM+vK7bgzMzNN6dsdBfHzAG42gh1gAdWrV5dhGKpatarrzNu1HDx40LWERZbff/9dklxnpTxZ4T8iIkKJiYk6ffp0tuBw5Zpn1apVk/T3GcSYmBi3+7+arBmjmZmZpvQnybUe3K5du9S2bVtX+6VLl7R3795sQTG/vgUhIiJCTqdTu3fvznaWzpM15Fq0aKEWLVpo4sSJ+uijj9S7d28tWLBAgwYNMr3unTt35mj7/fffs53hLFOmTK6XPK88q+bpvzun06mdO3eqbt26rvbU1FSlpaV5tLYfYBXcYwdYQNeuXeXl5aUJEybkOPtgGIb++uuvbG2XLl3S+++/73p+4cIFvf/++ypfvrwaN24sSa7Qd7UlSy5333336dKlS5o2bZqrLTMzU++88062/SpUqKA2bdro/fff16FDh3L0c/To0euOdTkvLy899NBD+uyzz3Isr5GX/iSpSZMmCg4O1syZM3Xp0iVX+//93//luGTnyXvkiawZs2+//Xa29qlTp173tSdOnMjxb6Bhw4aS5FoCJGuWq1l1L1myJNu9kevXr9e6deuyzfytXr26tm/fnu1nsnnzZv3888/Z+vKktvvuu09SzvdlypQpkuTWLGLAajhjB1hA9erV9dJLL2n06NGupTlKliypPXv2aPHixfrHP/6hkSNHuvYPCwvTq6++qr1796pWrVpauHChkpOTNWPGDNf9eNWrV1fp0qU1ffp0lSxZUoGBgWrevLmqVq2aY/yOHTvqjjvu0KhRo7R3715FRUVp0aJFOnnyZI59HQ6H7rzzTtWvX1+DBw9WtWrVlJqaqjVr1ujPP//U5s2bPTr2V155RStWrFDz5s01ePBgRUVF6fjx49q0aZO+//57HT9+3KP+fH19NX78eD3xxBO655571L17d+3du1dz585V9erVs51R8uQ98kTDhg3Vq1cvvffeezp58qRatWqlxMTEXNfbu9K8efP03nvvqUuXLqpevbpOnTqlmTNnqlSpUq4gFBAQoKioKC1cuFC1atVS2bJlddttt+X5u21r1KihO++8U0OGDFFGRoamTp2q4OBgPfPMM659Bg4cqClTpig2NlaPPvqojhw5ounTp6tevXpKT0937edJbdHR0YqPj9eMGTOUlpam1q1ba/369Zo3b546d+6c7YwrUGQUzGRcAO7KWs7iWstXZPnss8+MO++80wgMDDQCAwONOnXqGHa73dixY4drn9atWxv16tUzNmzYYLRs2dLw9/c3IiIijHfffTdHf59//rkRFRVleHt7Z1vW48olKgzDMP766y+jb9++RqlSpYygoCCjb9++xq+//prrciC7d+82+vXrZ4SGhho+Pj5GpUqVjAceeMD49NNPr3uMymUpjNTUVMNutxtVqlQxfHx8jNDQUKNdu3bGjBkzXPtkLXfyySefZHtt1pIdV9b49ttvGxEREYafn5/RrFkz4+effzYaN25sdOjQwa33KOt9vlJu711uzp07Zzz55JNGcHCwERgYaHTs2NHYv3//dZc72bRpk9GrVy8jPDzc8PPzMypUqGA88MADxoYNG7L1/8svvxiNGzc2fH19s/UZHx9vBAYG5lrT1ZY7ef31143JkycbVapUMfz8/Iy77rrL2Lx5c47Xf/jhh0a1atUMX19fo2HDhsY333yT6/txtdquXO7EMAzj4sWLxoQJE4yqVasaPj4+RpUqVYzRo0dnW07HMP5e7uT+++/PUdPVlmEBblU2w+CuUaAoadOmjY4dO5brpUtcndPpVPny5dW1a1fNnDmzoMsBgFxxjx0AXOH8+fM57lObP3++jh8/nuvXYgFAYcE9dgBwhbVr12rEiBHq1q2bgoODtWnTJs2aNUu33XabunXrVtDlAcBVEewA4AqRkZGqUqWK3n77bR0/flxly5ZVv3799Morr2T71goAKGy4xw4AAMAiuMcOAADAIgh2AAAAFlHk77FzOp06ePCgSpYsmW9fDwQAAJBXhmHo1KlTCgsLu+73OBf5YHfw4EFVqVKloMsAAAC4pv3796ty5crX3KfIB7uSJUtK+vvNKlWqVAFXAwAAkF16erqqVKniyizXUmSDncPhkMPhUGZmpiSpVKlSBDsAAFBouXPLWJFf7iQ9PV1BQUE6efIkwQ4AABQ6nmQVZsUCAABYBMEOAADAIgh2AAAAFlFkg53D4VBUVJSaNm1a0KUAAACYgskTTJ4AAACFGJMnAAAAiiCCHQAAgEUQ7AAAACyCb574f988AQAArC9y1FLT+9z7yv2m95lXRfaMnd1uV0pKipKSkgq6FAAAAFMU2WAHAABgNQQ7AAAAiyDYAQAAWATBDgAAwCKKbLDjK8UAAIDVFNlgx6xYAABgNUU22AEAAFgNwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRDsAAAALKLIBjvWsQMAAFZTZIMd69gBAACrKbLBDgAAwGoIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyiywY4FigEAgNUU2WDHAsUAAMBqimywAwAAsBqCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARRTbYORwORUVFqWnTpgVdCgAAgCmKbLCz2+1KSUlRUlJSQZcCAABgiiIb7AAAAKyGYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAjLBLuzZ88qIiJCI0eOLOhSAAAACoRlgt3EiRPVokWLgi4DAACgwFgi2O3cuVPbt29XXFxcQZcCAABQYAo82K1evVodO3ZUWFiYbDablixZkmMfh8OhyMhI+fv7q3nz5lq/fn227SNHjtSkSZNuUsUAAACFU4EHuzNnzig6OloOhyPX7QsXLlRCQoLGjRunTZs2KTo6WrGxsTpy5Igk6fPPP1etWrVUq1atm1k2AABAoeNd0AXExcVd8xLqlClTNHjwYA0YMECSNH36dC1dulSzZ8/WqFGjtHbtWi1YsECffPKJTp8+rYsXL6pUqVJ6/vnnb9YhAAAAFAoFfsbuWi5cuKCNGzcqJibG1VasWDHFxMRozZo1kqRJkyZp//792rt3r9544w0NHjz4mqEuIyND6enp2R4AAABWUKiD3bFjx5SZmamQkJBs7SEhITp8+HCe+pw0aZKCgoJcjypVqphRKgAAQIEr8EuxZurfv/919xk9erQSEhJcz9PT0wl3AADAEgp1sCtXrpy8vLyUmpqarT01NVWhoaF56tPPz09+fn5mlAcAAFCoFOpLsb6+vmrcuLESExNdbU6nU4mJiWrZsuUN9e1wOBQVFaWmTZveaJkAAACFQoGfsTt9+rR27drler5nzx4lJyerbNmyCg8PV0JCguLj49WkSRM1a9ZMU6dO1ZkzZ1yzZPPKbrfLbrcrPT1dQUFBN3oYAAAABa7Ag92GDRvUtm1b1/Os+9/i4+M1d+5c9ejRQ0ePHtXzzz+vw4cPq2HDhlq+fHmOCRUAAABFnc0wDKOgiyhIWWfsTp48qVKlShV0OQAAIB9Fjlpqep97X7nf9D4v50lWKdT32OUn7rEDAABWU2SDnd1uV0pKipKSkgq6FAAAAFMU2WAHAABgNQQ7AAAAiyDYAQAAWESRDXZMngAAAFZTZIMdkycAAIDVFNlgBwAAYDUEOwAAAIsg2AEAAFhEkQ12TJ4AAABWU2SDHZMnAACA1RTZYAcAAGA1BDsAAACLINgBAABYBMEOAADAIopssGNWLAAAsJoiG+yYFQsAAKymyAY7AAAAqyHYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFFNlgxzp2AADAarwLuoCCYrfbZbfblZ6erqCgoIIuB1eIHLXU9D73vnK/6X0CAFCYFNkzdgAAAFZTZM/YAZL5ZwZzOyvI2UcAwM1CsAMs4maEVABA4Uawg8cIEAAAFE4EOwBu47IyABRuBDsAhQ73PgJA3jArFgAAwCKK7Bk7h8Mhh8OhzMzMgi4FgIVxTyqAm6nInrGz2+1KSUlRUlJSQZcCAABgiiJ7xg4ArIL7BQFkIdgBANzCZWWg8CPYAQCKHEIqrKrI3mMHAABgNZyxAwAUGtwvCNwYgh0AALcwLivjclyKBQAAsAjO2AEAkA+4rOw5zj7eOIIdAAC4JkLqrYNLsQAAABZBsAMAALAIgh0AAIBFFNlg53A4FBUVpaZNmxZ0KQAAAKYossHObrcrJSVFSUlJBV0KAACAKYpssAMAALAagh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWIRH3xXrdDq1atUq/fjjj9q3b5/Onj2r8uXLq1GjRoqJiVGVKlXyq04AAABch1tn7M6dO6eXXnpJVapU0X333aevv/5aaWlp8vLy0q5duzRu3DhVrVpV9913n9auXZvfNQMAACAXbp2xq1Wrllq2bKmZM2fq3nvvlY+PT4599u3bp48++kg9e/bUmDFjNHjwYNOLBQAAwNW5Fey+/fZb1a1b95r7REREaPTo0Ro5cqT++OMPU4oDAACA+9y6FHu9UHc5Hx8fVa9ePc8FAQAAIG/yNCv2xx9/VJ8+fdSyZUsdOHBAkvTBBx/op59+MrU4AAAAuM/jYPfZZ58pNjZWAQEB+vXXX5WRkSFJOnnypF5++WXTCwQAAIB7PA52L730kqZPn66ZM2dmm0Rxxx13aNOmTaYWBwAAAPd5HOx27Nihu+++O0d7UFCQ0tLSzKgJAAAAeeBxsAsNDdWuXbtytP/000+qVq2aKUV5Ii0tTU2aNFHDhg112223aebMmTe9BgAAgMLAo2+ekKTBgwdr2LBhmj17tmw2mw4ePKg1a9Zo5MiRGjt2bH7UeE0lS5bU6tWrVbx4cZ05c0a33XabunbtquDg4JteCwAAQEHyONiNGjVKTqdT7dq109mzZ3X33XfLz89PI0eO1BNPPJEfNV6Tl5eXihcvLknKyMiQYRgyDOOm1wEAAFDQPL4Ua7PZNGbMGB0/flxbt27V2rVrdfToUb344ot5KmD16tXq2LGjwsLCZLPZtGTJkhz7OBwORUZGyt/fX82bN9f69euzbU9LS1N0dLQqV66sp59+WuXKlctTLQAAALeyPK1jJ0m+vr6KiopSs2bNVKJEiTwXcObMGUVHR8vhcOS6feHChUpISNC4ceO0adMmRUdHKzY2VkeOHHHtU7p0aW3evFl79uzRRx99pNTU1DzXAwAAcKty61Js165d3e5w0aJFHhUQFxenuLi4q26fMmWKBg8erAEDBkiSpk+frqVLl2r27NkaNWpUtn1DQkIUHR2tH3/8UQ8//LBHdQAAANzq3Ap2QUFB+V1Hri5cuKCNGzdq9OjRrrZixYopJiZGa9askSSlpqaqePHiKlmypE6ePKnVq1dryJAhV+0zIyPDtaiyJKWnp+ffAQAAANxEbgW7OXPm5HcduTp27JgyMzMVEhKSrT0kJETbt2+XJO3bt0//+Mc/XJMmnnjiCdWvX/+qfU6aNEkTJkzI17oBAAAKgsezYgubZs2aKTk52e39R48erYSEBNfz9PR0ValSJR8qAwAAuLnyFOw+/fRTffzxx/rjjz904cKFbNvM/FqxcuXKycvLK8dkiNTUVIWGhuapTz8/P/n5+ZlRHgAAQKHicbB7++23NWbMGPXv31+ff/65BgwYoN27dyspKUl2u93U4nx9fdW4cWMlJiaqc+fOkiSn06nExEQNHTr0hvp2OBxyOBzKzMw0odLCIXLUUtP73PvK/ab3CQAA8ofHy5289957mjFjht555x35+vrqmWee0Xfffacnn3xSJ0+e9LiA06dPKzk52XU5dc+ePUpOTtYff/whSUpISNDMmTM1b948bdu2TUOGDNGZM2dcs2Tzym63KyUlRUlJSTfUDwAAQGHh8Rm7P/74Q61atZIkBQQE6NSpU5Kkvn37qkWLFnr33Xc96m/Dhg1q27at63nW/W/x8fGaO3euevTooaNHj+r555/X4cOH1bBhQy1fvjzHhAoAAICizuNgFxoaquPHjysiIkLh4eFau3atoqOjtWfPnjx9lVebNm2u+7qhQ4fe8KVXAAAAq/P4Uuw999yjL774QpI0YMAAjRgxQvfee6969OihLl26mF5gfnE4HIqKilLTpk0LuhQAAABTeHzGbsaMGXI6nZL+vk8tODhYv/zyizp16qTHHnvM9ALzi91ul91uV3p6eoEtwAwAAGAmj4NdsWLFVKzY/3+ir2fPnurZs6epRQEAAMBzHl+KnTNnjj755JMc7Z988onmzZtnSlEAAADwnMfBbtKkSSpXrlyO9goVKujll182pSgAAAB4zuNg98cff6hq1ao52iMiIlxrz90KmDwBAACsxuNgV6FCBf3222852jdv3qzg4GBTiroZWKAYAABYjcfBrlevXnryySe1YsUKZWZmKjMzUz/88IOGDRvGJAoAAIAC5PGs2BdffFF79+5Vu3bt5O3998udTqf69evHPXYAAAAFyONg5+vrq4ULF+qll15ScnKyAgICVL9+fUVERORHfQAAAHCTx8EuS82aNVWzZk1lZmZqy5YtKlWqlMqUKWNmbfnK4XDI4XAoMzOzoEsBAAAwhcf32A0fPlyzZs2SJGVmZqp169a6/fbbVaVKFa1cudLs+vINkycAAIDVeBzsPv30U0VHR0uSvvzyS/3vf//T9u3bNWLECI0ZM8b0AgEAAOAej4PdsWPHFBoaKklatmyZunfvrlq1amngwIHasmWL6QUCAADAPR4Hu5CQEKWkpCgzM1PLly/XvffeK0k6e/asvLy8TC8QAAAA7vF48sSAAQPUvXt3VaxYUTabTTExMZKkdevWqU6dOqYXCAAAAPd4HOzGjx+v2267Tfv371e3bt3k5+cnSfLy8tKoUaNMLzC/MCsWAABYTZ6WO3n44YdztMXHx99wMTeT3W6X3W5Xenq6goKCCrocAACAG+bxPXYAAAAonAh2AAAAFkGwAwAAsAiCHQAAgEV4PHkiPT0913abzSY/Pz/5+vrecFEAAADwnMfBrnTp0rLZbFfdXrlyZfXv31/jxo1TsWKcEAQAALhZPA52c+fO1ZgxY9S/f381a9ZMkrR+/XrNmzdPzz33nI4ePao33nhDfn5++te//mV6wWZhHTsAAGA1Hge7efPmafLkyerevburrWPHjqpfv77ef/99JSYmKjw8XBMnTizUwY517AAAgNV4fK30l19+UaNGjXK0N2rUSGvWrJEk3Xnnnfrjjz9uvDoAAAC4zeNgV6VKFc2aNStH+6xZs1SlShVJ0l9//aUyZcrceHUAAABwm8eXYt944w1169ZNX3/9tZo2bSpJ2rBhg7Zv365PP/1UkpSUlKQePXqYWykAAACuyeNg16lTJ23fvl3vv/++fv/9d0lSXFyclixZosjISEnSkCFDTC0SAAAA1+dxsJOkqlWr6pVXXjG7FgAAANyAPAW7tLQ0zZo1S9u2bZMk1atXTwMHDmR2KQAAQAHyePLEhg0bVL16db355ps6fvy4jh8/rilTpqh69eratGlTftQIAAAAN3h8xm7EiBHq1KmTZs6cKW/vv19+6dIlDRo0SMOHD9fq1atNLzI/sEAxAACwmjydsXv22WddoU6SvL299cwzz2jDhg2mFpef7Ha7UlJSlJSUVNClAAAAmMLjYFeqVKlcFx/ev3+/SpYsaUpRAAAA8JzHwa5Hjx569NFHtXDhQu3fv1/79+/XggULNGjQIPXq1Ss/agQAAIAb8rRAsc1mU79+/XTp0iVJko+Pj4YMGcISKAAAAAXI42Dn6+urt956S5MmTdLu3bslSdWrV1fx4sVNLw4AAADuy9M6dpJUvHhx1a9f38xaAAAAcAPcCnZdu3Z1u8NFixbluRgAAADknVvBjm+UAAAAKPzcCnZz5szJ7zoAAABwgzxe7gQAAACFk1vBrkOHDlq7du119zt16pReffVVORyOGy4MAAAAnnHrUmy3bt300EMPKSgoSB07dlSTJk0UFhYmf39/nThxQikpKfrpp5+0bNky3X///Xr99dfzu24AAABcwa1g9+ijj6pPnz765JNPtHDhQs2YMUMnT56UJNlsNkVFRSk2NlZJSUmqW7duvhYMAACA3Lm9jp2fn5/69OmjPn36SJJOnjypc+fOKTg4WD4+PvlWYH5xOBxyOBzKzMws6FIAAABMkefJE0FBQQoNDb0lQ50k2e12paSkKCkpqaBLAQAAMAWzYgEAACyCYAcAAGARBDsAAACLINgBAABYhMfBrlq1avrrr79ytKelpalatWqmFAUAAADPeRzs9u7dm+sSIRkZGTpw4IApRQEAAMBzbq9j98UXX7j++5tvvlFQUJDreWZmphITExUZGWlqcQAAAHCf28Guc+fOkv7+pon4+Phs23x8fBQZGanJkyebWhwAAADc53awczqdkqSqVasqKSlJ5cqVy7eiAAAA4Dm3g12WPXv25EcdAAAAuEEeBztJSkxMVGJioo4cOeI6k5dl9uzZphQGAAAAz3gc7CZMmKAXXnhBTZo0UcWKFWWz2fKjLgAAAHjI42A3ffp0zZ07V3379s2PegAAAJBHHq9jd+HCBbVq1So/agEAAMAN8DjYDRo0SB999FF+1AIAAIAb4PGl2PPnz2vGjBn6/vvv1aBBA/n4+GTbPmXKFNOKc8f+/fvVt29fHTlyRN7e3ho7dqy6det2U2sAAAAoDDwOdr/99psaNmwoSdq6dWu2bQUxkcLb21tTp05Vw4YNdfjwYTVu3Fj33XefAgMDb3otAAAABcnjYLdixYr8qCPPKlasqIoVK0qSQkNDVa5cOR0/fpxgBwAAihyP77Ez2+rVq9WxY0eFhYXJZrNpyZIlOfZxOByKjIyUv7+/mjdvrvXr1+fa18aNG5WZmakqVarkc9UAAACFj8dn7Nq2bXvNS64//PCDR/2dOXNG0dHRGjhwoLp27Zpj+8KFC5WQkKDp06erefPmmjp1qmJjY7Vjxw5VqFDBtd/x48fVr18/zZw506PxAQAArMLjYJd1f12WixcvKjk5WVu3blV8fLzHBcTFxSkuLu6q26dMmaLBgwdrwIABkv5eR2/p0qWaPXu2Ro0aJUnKyMhQ586dNWrUKJZiAQAARZbHwe7NN9/MtX38+PE6ffr0DRd0uQsXLmjjxo0aPXq0q61YsWKKiYnRmjVrJEmGYah///6655573Fo0OSMjQxkZGa7n6enpptYMAABQUEy7x65Pnz6mf0/ssWPHlJmZqZCQkGztISEhOnz4sCTp559/1sKFC7VkyRI1bNhQDRs21JYtW67a56RJkxQUFOR6cD8eAACwCo/P2F3NmjVr5O/vb1Z3brvzzjvldDrd3n/06NFKSEhwPU9PTyfcAQAAS/A42F05wcEwDB06dEgbNmzQ2LFjTStMksqVKycvLy+lpqZma09NTVVoaGie+vTz85Ofn58Z5QEAABQqHl+KvfwyZlBQkMqWLas2bdpo2bJlGjdunKnF+fr6qnHjxkpMTHS1OZ1OJSYmqmXLljfUt8PhUFRUlJo2bXqjZQIAABQKHp+xmzNnjqkFnD59Wrt27XI937Nnj5KTk1W2bFmFh4crISFB8fHxatKkiZo1a6apU6fqzJkzrlmyeWW322W325Wenq6goKAbPQwAAIACl+d77DZu3Kht27ZJkurVq6dGjRrlqZ8NGzaobdu2rudZ97/Fx8dr7ty56tGjh44eParnn39ehw8fVsOGDbV8+fIcEyoAAACKOo+D3ZEjR9SzZ0+tXLlSpUuXliSlpaWpbdu2WrBggcqXL+9Rf23atJFhGNfcZ+jQoRo6dKinpQIAABQpHt9j98QTT+jUqVP673//q+PHj+v48ePaunWr0tPT9eSTT+ZHjfmCe+wAAIDVeBzsli9frvfee09169Z1tUVFRcnhcOjrr782tbj8ZLfblZKSoqSkpIIuBQAAwBQeBzun0ykfH58c7T4+Ph6tJwcAAABzeRzs7rnnHg0bNkwHDx50tR04cEAjRoxQu3btTC0OAAAA7vM42L377rtKT09XZGSkqlevrurVq6tq1apKT0/XO++8kx81AgAAwA0ez4qtUqWKNm3apO+//17bt2+XJNWtW1cxMTGmF5efHA6HHA6HMjMzC7oUAAAAU+RpHTubzaZ7771X9957r9n13DQsUAwAAKzG7UuxP/zwg6KiopSenp5j28mTJ1WvXj39+OOPphYHAAAA97kd7KZOnarBgwerVKlSObYFBQXpscce05QpU0wtDgAAAO5zO9ht3rxZHTp0uOr29u3ba+PGjaYUBQAAAM+5HexSU1NzXb8ui7e3t44ePWpKUTcD3zwBAACsxu3JE5UqVdLWrVtVo0aNXLf/9ttvqlixommF5bebPXkictRSU/vb+8r9pvYHAABufW6fsbvvvvs0duxYnT9/Pse2c+fOady4cXrggQdMLQ4AAADuc/uM3XPPPadFixapVq1aGjp0qGrXri1J2r59u2s9uDFjxuRboQAAALg2t4NdSEiIfvnlFw0ZMkSjR4+WYRiS/l7TLjY2Vg6HQyEhIflWKAAAAK7NowWKIyIitGzZMp04cUK7du2SYRiqWbOmypQpk1/1AQAAwE15+uaJMmXK3PKzSflKMQAAYDVuT56wGrvdrpSUFCUlJRV0KQAAAKYossEOAADAagh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARRTbYORwORUVF3fLr8QEAAGQpssGOdewAAIDVFNlgBwAAYDUEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwCIIdAACARRTZYMcCxQAAwGqKbLBjgWIAAGA1RTbYAQAAWA3BDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALCIIhvsHA6HoqKi1LRp04IuBQAAwBRFNtjZ7XalpKQoKSmpoEsBAAAwRZENdgAAAFZDsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWIQlgl2XLl1UpkwZPfzwwwVdCgAAQIGxRLAbNmyY5s+fX9BlAAAAFChLBLs2bdqoZMmSBV0GAABAgSrwYLd69Wp17NhRYWFhstlsWrJkSY59HA6HIiMj5e/vr+bNm2v9+vU3v1AAAIBCrsCD3ZkzZxQdHS2Hw5Hr9oULFyohIUHjxo3Tpk2bFB0drdjYWB05cuQmVwoAAFC4FXiwi4uL00svvaQuXbrkun3KlCkaPHiwBgwYoKioKE2fPl3FixfX7Nmzb3KlAAAAhVuBB7truXDhgjZu3KiYmBhXW7FixRQTE6M1a9bkqc+MjAylp6dnewAAAFhBoQ52x44dU2ZmpkJCQrK1h4SE6PDhw67nMTEx6tatm5YtW6bKlStfM/RNmjRJQUFBrkeVKlXyrX4AAICbybugCzDD999/7/a+o0ePVkJCgut5eno64Q4AAFhCoQ525cqVk5eXl1JTU7O1p6amKjQ0NE99+vn5yc/Pz4zyAAAACpVCfSnW19dXjRs3VmJioqvN6XQqMTFRLVu2vKG+HQ6HoqKi1LRp0xstEwAAoFAo8DN2p0+f1q5du1zP9+zZo+TkZJUtW1bh4eFKSEhQfHy8mjRpombNmmnq1Kk6c+aMBgwYcEPj2u122e12paenKygo6EYPAwAAoMAVeLDbsGGD2rZt63qedf9bfHy85s6dqx49eujo0aN6/vnndfjwYTVs2FDLly/PMaECAACgqCvwYNemTRsZhnHNfYYOHaqhQ4fepIoAAABuTYX6Hrv8xD12AADAaopssLPb7UpJSVFSUlJBlwIAAGCKIhvsAAAArIZgBwAAYBEEOwAAAIsossGOyRMAAMBqimywY/IEAACwmiIb7AAAAKyGYAcAAGARBDsAAACLKLLBjskTAADAaopssGPyBAAAsJoiG+wAAACshmAHAABgEQQ7AAAAiyDYAQAAWESRDXbMigUAAFZTZIMds2IBAIDVFNlgBwAAYDUEOwAAAIsg2AEAAFgEwQ4AAMAiCHYAAAAWQbADAACwiCIb7FjHDgAAWE2RDXasYwcAAKymyAY7AAAAqyHYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0AAIBFEOwAAAAsosgGOxYoBgAAVlNkgx0LFAMAAKspssEOAADAagh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUU2WDncDgUFRWlpk2bFnQpAAAApiiywc5utyslJUVJSUkFXQoAAIApimywAwAAsBqCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYBMEOAADAIgh2AAAAFmGJYPfVV1+pdu3aqlmzpv79738XdDkAAAAFwrugC7hRly5dUkJCglasWKGgoCA1btxYXbp0UXBwcEGXBgAAcFPd8mfs1q9fr3r16qlSpUoqUaKE4uLi9O233xZ0WQAAADddgQe71atXq2PHjgoLC5PNZtOSJUty7ONwOBQZGSl/f381b95c69evd207ePCgKlWq5HpeqVIlHThw4GaUDgAAUKgUeLA7c+aMoqOj5XA4ct2+cOFCJSQkaNy4cdq0aZOio6MVGxurI0eO3ORKAQAACrcCv8cuLi5OcXFxV90+ZcoUDR48WAMGDJAkTZ8+XUuXLtXs2bM1atQohYWFZTtDd+DAATVr1uyq/WVkZCgjI8P1/OTJk5Kk9PT0Gz2Ua3JmnDW1v9zqNXuMmzUOx1I4x+FYCuc4HEvhHIdjKZzjFOSx5Ef/hmFcf2ejEJFkLF682PU8IyPD8PLyytZmGIbRr18/o1OnToZhGMbFixeNGjVqGH/++adx6tQpo1atWsaxY8euOsa4ceMMSTx48ODBgwcPHrfUY//+/dfNUgV+xu5ajh07pszMTIWEhGRrDwkJ0fbt2yVJ3t7emjx5stq2bSun06lnnnnmmjNiR48erYSEBNdzp9Op48ePKzg4WDabLX8OxE3p6emqUqWK9u/fr1KlSt3S43AshXMcjqVwjsOxFM5xOJbCOY6VjsVdhmHo1KlTCgsLu+6+hTrYuatTp07q1KmTW/v6+fnJz88vW1vp0qXzoaq8K1Wq1E35R3QzxuFYCuc4HEvhHIdjKZzjcCyFcxwrHYs7goKC3NqvwCdPXEu5cuXk5eWl1NTUbO2pqakKDQ0toKoAAAAKp0Id7Hx9fdW4cWMlJia62pxOpxITE9WyZcsCrAwAAKDwKfBLsadPn9auXbtcz/fs2aPk5GSVLVtW4eHhSkhIUHx8vJo0aaJmzZpp6tSpOnPmjGuWrJX4+flp3LhxOS4V34rjcCyFcxyOpXCOw7EUznE4lsI5jpWOJT/Y/t9s1AKzcuVKtW3bNkd7fHy85s6dK0l699139frrr+vw4cNq2LCh3n77bTVv3vwmVwoAAFC4FXiwAwAAgDkK9T12AAAAcB/BDgAAwCIIdoXA6tWr1bFjR4WFhclms2nJkiWmjzFp0iQ1bdpUJUuWVIUKFdS5c2ft2LHD9HGmTZumBg0auNb9admypb7++mvTx7ncK6+8IpvNpuHDh5va7/jx42Wz2bI96tSpY+oY0t9fg9enTx8FBwcrICBA9evX14YNG0wdIzIyMsex2Gw22e1208bIzMzU2LFjVbVqVQUEBKh69ep68cUX3fsKHA+dOnVKw4cPV0REhAICAtSqVSslJSXlub/r/Q4ahqHnn39eFStWVEBAgGJiYrRz507Tx1m0aJHat2/vWjA9OTnZ1DEuXryoZ599VvXr11dgYKDCwsLUr18/HTx40PRjGT9+vOrUqaPAwECVKVNGMTExWrdunaljXO7xxx+XzWbT1KlTTT+W/v375/jd6dChg+nHsm3bNnXq1ElBQUEKDAxU06ZN9ccff5g6Tm6fAzabTa+//rppY5w+fVpDhw5V5cqVFRAQoKioKE2fPt2j43BnnNTUVPXv319hYWEqXry4OnTo4PHvpTt/G8+fPy+73a7g4GCVKFFCDz30UI5l2AoTgl0hcObMGUVHR8vhcOTbGKtWrZLdbtfatWv13Xff6eLFi2rfvr3OnDlj6jiVK1fWK6+8oo0bN2rDhg2655579OCDD+q///2vqeNkSUpK0vvvv68GDRrkS//16tXToUOHXI+ffvrJ1P5PnDihO+64Qz4+Pvr666+VkpKiyZMnq0yZMqaOk5SUlO04vvvuO0lSt27dTBvj1Vdf1bRp0/Tuu+9q27ZtevXVV/Xaa6/pnXfeMW2MLIMGDdJ3332nDz74QFu2bFH79u0VExOT7XujPXG938HXXntNb7/9tqZPn65169YpMDBQsbGxOn/+vKnjnDlzRnfeeadeffVVj4/BnTHOnj2rTZs2aezYsdq0aZMWLVqkHTt2uL3Au7vjSFKtWrX07rvvasuWLfrpp58UGRmp9u3b6+jRo6aNkWXx4sVau3atW6vy53WcDh06ZPsd+s9//mPqGLt379add96pOnXqaOXKlfrtt980duxY+fv7mzrO5cdw6NAhzZ49WzabTQ899JBpYyQkJGj58uX68MMPtW3bNg0fPlxDhw7VF198YdqxGIahzp0763//+58+//xz/frrr4qIiFBMTIxHf9fc+ds4YsQIffnll/rkk0+0atUqHTx4UF27dvXoWG4qj77MFflOUo7vxs0PR44cMSQZq1atyvexypQpY/z73/82vd9Tp04ZNWvWNL777jujdevWxrBhw0ztf9y4cUZ0dLSpfV7p2WefNe688858HSM3w4YNM6pXr244nU7T+rz//vuNgQMHZmvr2rWr0bt3b9PGMAzDOHv2rOHl5WV89dVX2dpvv/12Y8yYMTfc/5W/g06n0wgNDTVef/11V1taWprh5+dn/Oc//zFtnMvt2bPHkGT8+uuvee7/emNkWb9+vSHJ2LdvX76Oc/LkSUOS8f3335s6xp9//mlUqlTJ2Lp1qxEREWG8+eabeer/WuPEx8cbDz744A31e70xevToYfTp08e0Ma42zpUefPBB45577jF1jHr16hkvvPBCtrYb/f28cpwdO3YYkoytW7e62jIzM43y5csbM2fOzPM4V/5tTEtLM3x8fIxPPvnEtc+2bdsMScaaNWvyPE5+4oxdEXXy5ElJUtmyZfNtjMzMTC1YsEBnzpzJlwWl7Xa77r//fsXExJjed5adO3cqLCxM1apVU+/evT2+LHI9X3zxhZo0aaJu3bqpQoUKatSokWbOnGnqGFe6cOGCPvzwQw0cONDU70du1aqVEhMT9fvvv0uSNm/erJ9++klxcXGmjSFJly5dUmZmZo4zGQEBAaafUZX+Xlvz8OHD2f6dBQUFqXnz5lqzZo3p491sJ0+elM1my9evVrxw4YJmzJihoKAgRUdHm9av0+lU37599fTTT6tevXqm9ZublStXqkKFCqpdu7aGDBmiv/76y7S+nU6nli5dqlq1aik2NlYVKlRQ8+bN8+W2nMulpqZq6dKlevTRR03tt1WrVvriiy904MABGYahFStW6Pfff1f79u1NGyMjI0OSsn0OFCtWTH5+fjf0OXDl38aNGzfq4sWL2X7/69Spo/Dw8EL7+0+wK4KcTqeGDx+uO+64Q7fddpvp/W/ZskUlSpSQn5+fHn/8cS1evFhRUVGmjrFgwQJt2rRJkyZNMrXfyzVv3lxz587V8uXLNW3aNO3Zs0d33XWXTp06ZdoY//vf/zRt2jTVrFlT33zzjYYMGaInn3xS8+bNM22MKy1ZskRpaWnq37+/qf2OGjVKPXv2VJ06deTj46NGjRpp+PDh6t27t6njlCxZUi1bttSLL76ogwcPKjMzUx9++KHWrFmjQ4cOmTqWJB0+fFiSFBISkq09JCTEte1Wdf78eT377LPq1atXvnwX5ldffaUSJUrI399fb775pr777juVK1fOtP5fffVVeXt768knnzStz9x06NBB8+fPV2Jiol599VWtWrVKcXFxyszMNKX/I0eO6PTp03rllVfUoUMHffvtt+rSpYu6du2qVatWmTJGbubNm6eSJUuaflnxnXfeUVRUlCpXrixfX1916NBBDodDd999t2ljZIWr0aNH68SJE7pw4YJeffVV/fnnn3n+HMjtb+Phw4fl6+ub4398CvPvf4F/8wRuPrvdrq1bt+bL2Q1Jql27tpKTk3Xy5El9+umnio+P16pVq0wLd/v379ewYcP03XffeXz/iScuP9PUoEEDNW/eXBEREfr4449N+z9cp9OpJk2a6OWXX5YkNWrUSFu3btX06dMVHx9vyhhXmjVrluLi4vJ8P9LVfPzxx/q///s/ffTRR6pXr56Sk5M1fPhwhYWFmX4sH3zwgQYOHKhKlSrJy8tLt99+u3r16qWNGzeaOo6VXbx4Ud27d5dhGJo2bVq+jNG2bVslJyfr2LFjmjlzprp3765169apQoUKN9z3xo0b9dZbb2nTpk2mnnnOTc+ePV3/Xb9+fTVo0EDVq1fXypUr1a5duxvu3+l0SpIefPBBjRgxQpLUsGFD/fLLL5o+fbpat259w2PkZvbs2erdu7fpn6PvvPOO1q5dqy+++EIRERFavXq17Ha7wsLCTLvC4uPjo0WLFunRRx9V2bJl5eXlpZiYGMXFxeV5wlZ+/228WThjV8QMHTpUX331lVasWKHKlSvnyxi+vr6qUaOGGjdurEmTJik6OlpvvfWWaf1v3LhRR44c0e233y5vb295e3tr1apVevvtt+Xt7W3a/0VfqXTp0qpVq1a2r8C7URUrVswReOvWrWv6Jd8s+/bt0/fff69BgwaZ3vfTTz/tOmtXv3599e3bVyNGjMiXs6rVq1fXqlWrdPr0ae3fv1/r16/XxYsXVa1aNdPHCg0NlaQcs+BSU1Nd2241WaFu3759+u677/LlbJ0kBQYGqkaNGmrRooVmzZolb29vzZo1y5S+f/zxRx05ckTh4eGuz4F9+/bpqaeeUmRkpCljXE21atVUrlw50z4LypUrJ29v75v6WfDjjz9qx44dpn8WnDt3Tv/61780ZcoUdezYUQ0aNNDQoUPVo0cPvfHGG6aO1bhxYyUnJystLU2HDh3S8uXL9ddff+Xpc+BqfxtDQ0N14cIFpaWlZdu/MP/+E+yKCMMwNHToUC1evFg//PCDqlatetPGdjqdrvshzNCuXTtt2bJFycnJrkeTJk3Uu3dvJScny8vLy7SxLnf69Gnt3r1bFStWNK3PO+64I8fU+t9//10RERGmjXG5OXPmqEKFCrr//vtN7/vs2bMqViz7R4qXl5frbER+CAwMVMWKFXXixAl98803evDBB00fo2rVqgoNDVViYqKrLT09XevWrcuXe0fzW1ao27lzp77//nsFBwfftLHN/Czo27evfvvtt2yfA2FhYXr66af1zTffmDLG1fz555/666+/TPss8PX1VdOmTW/qZ8GsWbPUuHFjU+95lP7+93Xx4sWb+lkQFBSk8uXLa+fOndqwYYNHnwPX+9vYuHFj+fj4ZPv937Fjh/74449C+/vPpdhC4PTp09n+z2/Pnj1KTk5W2bJlFR4ebsoYdrtdH330kT7//HOVLFnSdW9AUFCQAgICTBlDkkaPHq24uDiFh4fr1KlT+uijj7Ry5UpTP2hLliyZ497AwMBABQcHm3rP4MiRI9WxY0dFRETo4MGDGjdunLy8vNSrVy/TxhgxYoRatWqll19+Wd27d9f69es1Y8YMzZgxw7QxsjidTs2ZM0fx8fHy9jb/V79jx46aOHGiwsPDVa9ePf3666+aMmWKBg4caPpY33zzjQzDUO3atbVr1y49/fTTqlOnjgYMGJCn/q73Ozh8+HC99NJLqlmzpqpWraqxY8cqLCxMnTt3NnWc48eP648//nCtK5f1hz40NNTtswPXGqNixYp6+OGHtWnTJn311VfKzMx0fRaULVtWvr6+phxLcHCwJk6cqE6dOqlixYo6duyYHA6HDhw44NESO9d7v64MpT4+PgoNDVXt2rXdHuN645QtW1YTJkzQQw89pNDQUO3evVvPPPOMatSoodjYWNOO5emnn1aPHj109913q23btlq+fLm+/PJLrVy50rRjyfp7kp6erk8++USTJ0/2qG93x2jdurWefvppBQQEKCIiQqtWrdL8+fM1ZcoUU8f55JNPVL58eYWHh2vLli0aNmyYOnfu7NEkjev9bQwKCtKjjz6qhIQElS1bVqVKldITTzyhli1bqkWLFh4dz01TkFNy8bcVK1YYknI84uPjTRsjt/4lGXPmzDFtDMMwjIEDBxoRERGGr6+vUb58eaNdu3bGt99+a+oYucmP5U569OhhVKxY0fD19TUqVapk9OjRw9i1a5epYxiGYXz55ZfGbbfdZvj5+Rl16tQxZsyYYfoYhmEY33zzjSHJ2LFjR770n56ebgwbNswIDw83/P39jWrVqhljxowxMjIyTB9r4cKFRrVq1QxfX18jNDTUsNvtRlpaWp77u97voNPpNMaOHWuEhIQYfn5+Rrt27fL0Pl5vnDlz5uS6fdy4caaMkbWMSm6PFStWmHYs586dM7p06WKEhYUZvr6+RsWKFY1OnToZ69evN22M3OR1uZNrjXP27Fmjffv2Rvny5Q0fHx8jIiLCGDx4sHH48GHTj2XWrFlGjRo1DH9/fyM6OtpYsmSJqceS5f333zcCAgLy/DtzvTEOHTpk9O/f3wgLCzP8/f2N2rVrG5MnT/Z4eaXrjfPWW28ZlStXNnx8fIzw8HDjueee8/jzxp2/jefOnTP++c9/GmXKlDGKFy9udOnSxTh06JBH49xMNsPIh2XhAQAAcNNxjx0AAIBFEOwAAAAsgmAHAABgEQQ7AAAAiyDYAQAAWATBDgAAwCIIdgAAABZBsAMAALAIgh0A/D82m01Lliy56va9e/fKZrMpOTk5z2PMnTtXpUuXzvPrzRYZGampU6cWdBkATEKwA1Co9O/fXzabTTabTb6+vqpRo4ZeeOEFXbp0ybQxxo8fr4YNG+ZoP3TokOLi4kwbpzApbIESQP4w/5vAAeAGdejQQXPmzFFGRoaWLVsmu90uHx8fjR49Ol/HDQ0Nzdf+ASC/ccYOQKHj5+en0NBQRUREaMiQIYqJidEXX3whScrIyNDIkSNVqVIlBQYGqnnz5lq5cqXrtVlnppYsWaKaNWvK399fsbGx2r9/v2v7hAkTtHnzZteZwblz50rKeSl2/fr1atSokfz9/dWkSRP9+uuvOWrdunWr4uLiVKJECYWEhKhv3746duyYR8f7+eef6/bbb5e/v7+qVaumCRMmZDtDabPZ9O9//1tdunRR8eLFVbNmTdf7keWLL75wHW/btm01b9482Ww2paWlaeXKlRowYIBOnjzpOubx48e7Xnv27FkNHDhQJUuWVHh4uGbMmOFR/QAKD4IdgEIvICBAFy5ckCQNHTpUa9as0YIFC/Tbb7+pW7du6tChg3bu3Ona/+zZs5o4caLmz5+vn3/+WWlpaerZs6ckqUePHnrqqadUr149HTp0SIcOHVKPHj1yjHn69Gk98MADioqK0saNGzV+/HiNHDky2z5paWm655571KhRI23YsEHLly9Xamqqunfv7vax/fjjj+rXr5+GDRumlJQUvf/++5o7d64mTpyYbb8JEyaoe/fu+u2333Tfffepd+/eOn78uCRpz549evjhh9W5c2dt3rxZjz32mMaMGeN6batWrTR16lSVKlXKdcyXH8vkyZNdwfWf//ynhgwZoh07drh9DAAKEQMACpH4+HjjwQcfNAzDMJxOp/Hdd98Zfn5+xsiRI419+/YZXl5exoEDB7K9pl27dsbo0aMNwzCMOXPmGJKMtWvXurZv27bNkGSsW7fOMAzDGDdunBEdHZ1jbEnG4sWLDcMwjPfff98IDg42zp0759o+bdo0Q5Lx66+/GoZhGC+++KLRvn37bH3s37/fkGTs2LEj1+ObM2eOERQUlK32l19+Ods+H3zwgVGxYsVsdT333HOu56dPnzYkGV9//bVhGIbx7LPPGrfddlu2PsaMGWNIMk6cOJHruFkiIiKMPn36uJ47nU6jQoUKxrRp03KtH0Dhxj12AAqdr776SiVKlNDFixfldDr1yCOPaPz48Vq5cqUyMzNVq1atbPtnZGQoODjY9dzb21tNmzZ1Pa9Tp45Kly6tbdu2qVmzZm7VsG3bNjVo0ED+/v6utpYtW2bbZ/PmzVqxYoVKlCiR4/W7d+/OUWduNm/erJ9//jnbGbrMzEydP39eZ8+eVfHixSVJDRo0cG0PDAxUqVKldOTIEUnSjh07sh2vJLeP88q+bTabQkNDXX0DuLUQ7AAUOm3bttW0adPk6+ursLAweXv//VF1+vRpeXl5aePGjfLy8sr2mtzCVX47ffq0OnbsqFdffTXHtooVK7rdx4QJE9S1a9cc2y4PlT4+Ptm22Ww2OZ1ODyvOXX72DeDmItgBKHQCAwNVo0aNHO2NGjVSZmamjhw5orvuuuuqr7906ZI2bNjgOmu1Y8cOpaWlqW7dupIkX19fZWZmXrOGunXr6oMPPtD58+ddAWvt2rXZ9rn99tv12WefKTIy0hU+PXX77bdrx44duR6vu2rXrq1ly5Zla0tKSsr23J1jBnDrY/IEgFtGrVq11Lt3b/Xr10+LFi3Snj17tH79ek2aNElLly517efj46MnnnhC69at08aNG9W/f3+1aNHCFfQiIyO1Z88eJScn69ixY8rIyMgx1iOPPCKbzabBgwcrJSVFy5Yt0xtvvJFtH7vdruPHj6tXr15KSkrS7t279c0332jAgAFuh6jnn39e8+fP14QJE/Tf//5X27Zt04IFC/Tcc8+5/b489thj2r59u5599ln9/vvv+vjjj7PN9M065tOnTysxMVHHjh3T2bNn3e4fwK2DYAfgljJnzhz169dPTz31lGrXrq3OnTsrKSlJ4eHhrn2KFy+uZ599Vo888ojuuOMOlShRQgsXLnRtf+ihh9ShQwe1bdtW5cuX13/+858c45QoUUJffvmltmzZokaNGmnMmDE5LrmGhYXp559/VmZmptq3b6/69etr+PDhKl26tIoVc+/jNTY2Vl999ZW+/fZbNW3aVC1atNCbb76piIgIt9+TqlWr6tNPP9WiRYvUoEEDTZs2zTUr1s/PT9LfM2Mff/xx9ejRQ+XLl9drr73mdv8Abh02wzCMgi4CAMwyd+5cDR8+XGlpaQVdSoGaOHGipk+f7lq/D0DRwD12AGAB7733npo2barg4GD9/PPPev311zV06NCCLgvATUawAwAL2Llzp1566SUdP35c4eHheuqpp/L9K9gAFD5cigUAALAIJk8AAABYBMEOAADAIgh2AAAAFkGwAwAAsAiCHQAAgEUQ7AAAACyCYAcAAGARBDsAAACLINgBAABYxP8HYzbOJkecNN4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one_aa_df = df[df[\"aa_seq\"].astype(str).str.len() == 1].reset_index(drop=True)\n",
        "one_aa_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "gKFL6Z9PHdFc",
        "outputId": "4615890e-f55e-40b5-8ed8-255e9e26867a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   aa_seq  seed_bh dataset train_test  length\n",
              "0       W        0    NNK1      train       1\n",
              "1       I        0    NNK1      train       1\n",
              "2       V        0    NNK1      train       1\n",
              "3       C        0    NNK1      train       1\n",
              "4       H        0    NNK1      train       1\n",
              "5       Y        0    NNK1      train       1\n",
              "6       Q        0    NNK1      train       1\n",
              "7       T        0    NNK1      train       1\n",
              "8       E        0    NNK1      train       1\n",
              "9       G        0    NNK1      train       1\n",
              "10      P        0    NNK1      train       1\n",
              "11      S        0    NNK1      train       1\n",
              "12      M        0    NNK1      train       1\n",
              "13      L        0    NNK1      train       1\n",
              "14      D        0    NNK1      train       1\n",
              "15      K        0    NNK1      train       1\n",
              "16      F        0    NNK1      train       1\n",
              "17      R        0    NNK1      train       1\n",
              "18      N        0    NNK1      train       1\n",
              "19      A        0    NNK1       test       1\n",
              "20      Y        0    NNK2      train       1\n",
              "21      E        0    NNK2      train       1\n",
              "22      D        0    NNK2      train       1\n",
              "23      V        0    NNK2      train       1\n",
              "24      F        0    NNK2      train       1\n",
              "25      W        0    NNK2      train       1\n",
              "26      S        0    NNK2      train       1\n",
              "27      T        0    NNK2      train       1\n",
              "28      H        0    NNK2      train       1\n",
              "29      N        0    NNK2      train       1\n",
              "30      G        0    NNK2      train       1\n",
              "31      K        0    NNK2      train       1\n",
              "32      Q        0    NNK2      train       1\n",
              "33      R        0    NNK2      train       1\n",
              "34      P        0    NNK2      train       1\n",
              "35      L        0    NNK2      train       1\n",
              "36      C        0    NNK2      train       1\n",
              "37      I        0    NNK2      train       1\n",
              "38      M        0    NNK2      train       1\n",
              "39      A        0    NNK2       test       1\n",
              "40      G        0    NNK3      train       1\n",
              "41      I        0    NNK3      train       1\n",
              "42      S        0    NNK3      train       1\n",
              "43      M        0    NNK3      train       1\n",
              "44      Y        0    NNK3      train       1\n",
              "45      F        0    NNK3      train       1\n",
              "46      P        0    NNK3      train       1\n",
              "47      N        0    NNK3      train       1\n",
              "48      D        0    NNK3      train       1\n",
              "49      H        0    NNK3      train       1\n",
              "50      E        0    NNK3      train       1\n",
              "51      V        0    NNK3      train       1\n",
              "52      W        0    NNK3      train       1\n",
              "53      C        0    NNK3      train       1\n",
              "54      T        0    NNK3      train       1\n",
              "55      Q        0    NNK3      train       1\n",
              "56      L        0    NNK3      train       1\n",
              "57      K        0    NNK3      train       1\n",
              "58      A        0    NNK3       test       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46317674-9281-427c-a189-a3391e3b4cf4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa_seq</th>\n",
              "      <th>seed_bh</th>\n",
              "      <th>dataset</th>\n",
              "      <th>train_test</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>H</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>E</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>G</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>K</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>R</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>E</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>H</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>G</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>K</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>R</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>I</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>G</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>I</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>S</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>M</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Y</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>F</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>P</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>D</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>H</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>E</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>W</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>C</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>T</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Q</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>L</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>K</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>train</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46317674-9281-427c-a189-a3391e3b4cf4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46317674-9281-427c-a189-a3391e3b4cf4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46317674-9281-427c-a189-a3391e3b4cf4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-12c4187d-5549-4348-a938-36e97c442b22\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12c4187d-5549-4348-a938-36e97c442b22')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-12c4187d-5549-4348-a938-36e97c442b22 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_72a851ab-cca0-4308-8c40-8e6ffb44c719\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('one_aa_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_72a851ab-cca0-4308-8c40-8e6ffb44c719 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('one_aa_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "one_aa_df",
              "summary": "{\n  \"name\": \"one_aa_df\",\n  \"rows\": 59,\n  \"fields\": [\n    {\n      \"column\": \"aa_seq\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"W\",\n          \"R\",\n          \"K\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_bh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NNK1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_test\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"length\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UaNooh-cBAG7",
        "outputId": "d1010b15-e446-4864-87b0-59a9d8572193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 aa_seq  seed_bh dataset train_test  length\n",
              "0  IWTKSCDCVCSCGGYQGCYR        0    NNK1      train      20\n",
              "1               ILKSFLD        0    NNK1      train       7\n",
              "2            WTMLDMFLFS        0    NNK1      train      10\n",
              "3  CLQCKCYNNCVQLRVTVGCM        1    NNK1      train      20\n",
              "4       WTWILPMVRTIIYQY        0    NNK1      train      15"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45c7a280-0ee6-426f-a0bf-81f80faf0b92\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa_seq</th>\n",
              "      <th>seed_bh</th>\n",
              "      <th>dataset</th>\n",
              "      <th>train_test</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IWTKSCDCVCSCGGYQGCYR</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ILKSFLD</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WTMLDMFLFS</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CLQCKCYNNCVQLRVTVGCM</td>\n",
              "      <td>1</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WTWILPMVRTIIYQY</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td>train</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45c7a280-0ee6-426f-a0bf-81f80faf0b92')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45c7a280-0ee6-426f-a0bf-81f80faf0b92 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45c7a280-0ee6-426f-a0bf-81f80faf0b92');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3eb496d4-a570-41d3-83e5-2c5ec7833bfb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3eb496d4-a570-41d3-83e5-2c5ec7833bfb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3eb496d4-a570-41d3-83e5-2c5ec7833bfb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Zz0aIn8MDoL",
        "outputId": "b7bab47a-ae30-49bb-92f6-db27084b5f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([0, 1], dtype='int64', name='seed_bh')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = int(df[\"length\"].max())\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUcVKBWkuHiB",
        "outputId": "f67945d0-a902-4ed2-ff60-ef1f852c4d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.stacked plot"
      ],
      "metadata": {
        "id": "ZiMl94jNuOh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) stacked bar chart by aggregation label\n",
        "# 计算长度\n",
        "df[\"length\"] = df[\"aa_seq\"].astype(str).str.len()\n",
        "max_len = int(df[\"length\"].max()) # max_len = 20 最长的序列为20\n",
        "\n",
        "# 统计每个长度下的聚集/非聚集数量\n",
        "counts = (\n",
        "    df.groupby([\"length\", \"seed_bh\"])\n",
        "      .size()\n",
        "      .unstack(fill_value=0)\n",
        "      .reindex(range(1,21), fill_value=0))\n",
        "\n",
        "\n",
        "# 绘图\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(counts.index, counts.get(0, 0), label=\"Non-aggregator (0)\")\n",
        "ax.bar(counts.index, counts.get(1, 0), bottom=counts.get(0, 0), label=\"Aggregator (1)\", color= \"red\")\n",
        "\n",
        "ax.set_xticks(range(1, 21))\n",
        "ax.set_yscale(\"log\")\n",
        "ax.set_ylim(bottom=1)\n",
        "ax.set_xlabel(\"Peptide length\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(\"Peptide length counts by aggregation (stacked)\")\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "p2=os.path.join(out_dir,\"length_stacked_by_label.png\")\n",
        "fig.savefig(p2, dpi=200)\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "plots.append(p2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "QBDyjd-6KG8c",
        "outputId": "534092ca-b23a-4247-b4c9-ba2f4b33e672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 看看长度=1有没有数据\n",
        "(df[\"aa_seq\"].astype(str).str.len() == 1).sum()\n",
        "\n",
        "# 直接查看长度分布\n",
        "df[\"aa_seq\"].astype(str).str.len().value_counts().sort_index()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "vPJVZlMyLAHp",
        "outputId": "50da2ee4-ac3f-4fda-b248-6a66083dc8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "aa_seq\n",
              "1        59\n",
              "2       918\n",
              "3      3387\n",
              "4      3871\n",
              "5      3626\n",
              "6      3615\n",
              "7      3479\n",
              "8      3294\n",
              "9      3269\n",
              "10     3218\n",
              "11     3023\n",
              "12     2844\n",
              "13     2770\n",
              "14     2522\n",
              "15     2662\n",
              "16     2308\n",
              "17     2481\n",
              "18     2267\n",
              "19     2323\n",
              "20    59756\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aa_seq</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>59756</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.heatmap"
      ],
      "metadata": {
        "id": "iTtoKYNatXKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmap for 20 aa\n",
        "\n",
        "df = df[df[\"length\"] == 20].copy()\n",
        "\n",
        "aa_order = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "max_len = 20\n",
        "\n",
        "def freq_matrix(sub_df, max_len=20):\n",
        "    mat = pd.DataFrame(0, index=aa_order, columns=range(1, max_len+1), dtype=float)\n",
        "    seqs = sub_df[\"aa_seq\"].astype(str)\n",
        "    for seq in seqs:\n",
        "        for pos, aa in enumerate(seq[:max_len], start=1):\n",
        "            if aa in mat.index:\n",
        "                mat.loc[aa, pos] += 1\n",
        "    mat = mat.div(mat.sum(axis=0), axis=1)\n",
        "    return mat\n",
        "\n",
        "freq_agg = freq_matrix(df[df[\"seed_bh\"] == 1], max_len)\n",
        "freq_non = freq_matrix(df[df[\"seed_bh\"] == 0], max_len)\n",
        "\n",
        "diff = freq_agg - freq_non\n",
        "\n",
        "fig = plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(diff, cmap=\"PRGn\", center=0, linewidths=0.2, linecolor=\"white\",\n",
        "            cbar_kws={\"label\": \"Normalized frequency (Agg - Non-agg)\"})\n",
        "plt.xlabel(\"Position\")\n",
        "plt.ylabel(\"Amino acid\")\n",
        "plt.title(\"Position-specific AA frequency differences (length=20)\")\n",
        "plt.tight_layout()\n",
        "p3=os.path.join(out_dir,\"heatmap-position-specific-aa-frequency-differences.png\")\n",
        "fig.savefig(p3, dpi=200)\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "plots.append(p3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "tJ0TFS_JsGlm",
        "outputId": "c28a3e6c-8523-4269-8ad6-bb091a198c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.aggregation rate VS aa length plot"
      ],
      "metadata": {
        "id": "en7g5NXD0o5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"length\"] = df[\"aa_seq\"].astype(str).str.len()\n",
        "df[\"seed_bh\"] = pd.to_numeric(df[\"seed_bh\"], errors=\"coerce\")\n",
        "\n",
        "# 每个长度下 label=1 的比例\n",
        "rate = df.groupby(\"length\")[\"seed_bh\"].mean()\n",
        "\n",
        "# 如果你只要 1–20\n",
        "rate = rate.reindex(range(1, 21))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(rate.index, rate.values, marker=\"o\",  markersize=5, markerfacecolor=\"black\", markeredgecolor=\"black\")\n",
        "ax.set_xlabel(\"Peptide length (aa)\")\n",
        "ax.set_ylabel(\"Aggregation rate (P(label=1))\")\n",
        "ax.set_title(\"Aggregation rate vs peptide length\")\n",
        "ax.set_xticks(range(1, 21))\n",
        "ax.set_ylim(bottom=0)\n",
        "fig.tight_layout()\n",
        "p4=os.path.join(out_dir,\"aggregation_rate_heatmap_source_length.png\")\n",
        "fig.savefig(p4, dpi=200)\n",
        "plt.show()\n",
        "plt.close(fig)\n",
        "plots.append(p4)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ctQYcX0czgjA",
        "outputId": "26a0d221-f45e-49d9-8080-e1c603969ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.sampling from 100,000 to 5000"
      ],
      "metadata": {
        "id": "sQM2NSk42y7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "out_dir_2=\"/content/drive/MyDrive/master_thesis/sampled_data_5000\"\n",
        "os.makedirs(out_dir_2, exist_ok=True) # set output directory for sampled data\n",
        "\n",
        "df = df.copy()\n",
        "df[\"length\"] = df[\"aa_seq\"].astype(str).str.len()\n",
        "group_cols = [\"length\", \"seed_bh\", \"dataset\"]\n",
        "\n",
        "# 每组大小\n",
        "group_sizes = df.groupby(group_cols).size()\n",
        "\n",
        "n_target = 5000\n",
        "total = group_sizes.sum()\n",
        "proportional = (group_sizes / total) * n_target # 按比例\n",
        "\n",
        "# 先取 floor，保证不超过组容量\n",
        "alloc = np.floor(proportional).astype(int)\n",
        "alloc = alloc.clip(upper=group_sizes)\n",
        "\n",
        "# 还需要分配的名额\n",
        "remaining = n_target - alloc.sum()\n",
        "\n",
        "# 可继续分配的容量\n",
        "capacity = (group_sizes - alloc)\n",
        "\n",
        "# 按剩余的小数部分优先分配，但不能超过容量\n",
        "fractional = (proportional - np.floor(proportional)).fillna(0)\n",
        "\n",
        "# 只在容量>0的组中分配\n",
        "candidates = fractional[capacity > 0].sort_values(ascending=False)\n",
        "\n",
        "for idx in candidates.index:\n",
        "    if remaining <= 0:\n",
        "        break\n",
        "    if capacity.loc[idx] > 0:\n",
        "        alloc.loc[idx] += 1\n",
        "        capacity.loc[idx] -= 1\n",
        "        remaining -= 1\n",
        "\n",
        "# 如果还有剩余（极端情况），再按容量大的组继续补\n",
        "if remaining > 0:\n",
        "    extra_candidates = capacity[capacity > 0].sort_values(ascending=False)\n",
        "    for idx in extra_candidates.index:\n",
        "        if remaining <= 0:\n",
        "            break\n",
        "        take = min(remaining, capacity.loc[idx])\n",
        "        alloc.loc[idx] += take\n",
        "        remaining -= take\n",
        "\n",
        "# 分层不放回抽样\n",
        "sampled_parts = []\n",
        "for group_key, n_take in alloc.items():\n",
        "    if n_take == 0:\n",
        "        continue\n",
        "    sub = df.set_index(group_cols).loc[[group_key]].reset_index()\n",
        "    sampled_parts.append(sub.sample(n=n_take, replace=False, random_state=42))\n",
        "\n",
        "sampled_df = pd.concat(sampled_parts, ignore_index=True)\n",
        "sampled_df = sampled_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 设定列顺序\n",
        "cols = [\"aa_seq\", \"seed_bh\", \"dataset\", \"train_test\"]\n",
        "# 确保 train_test 列存在且为空\n",
        "sampled_df[\"train_test\"] = \"\"\n",
        "# 只保留并重排列\n",
        "sampled_df = sampled_df[cols]\n",
        "\n",
        "print(sampled_df.head())\n",
        "print(sampled_df.shape)\n",
        "\n",
        "out_path = os.path.join(out_dir_2, \"canya_data_sampled_5000.xlsx\")\n",
        "sampled_df.to_excel(out_path, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nm-0itw4d9P",
        "outputId": "54ba1a02-c2dd-458f-c4ac-fe0b708349de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 aa_seq  seed_bh dataset train_test\n",
            "0          GYVCMKLDRYLS        0    NNK3           \n",
            "1  SQLFYAILSIHYWCVTFFRC        0    NNK1           \n",
            "2  SGTSLPNITLLDTFCTRCFV        0    NNK1           \n",
            "3             MYEGGSTLW        0    NNK2           \n",
            "4               DGRFFFV        0    NNK1           \n",
            "(5000, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### convert seq to SMILES"
      ],
      "metadata": {
        "id": "JWQLY-0vlHNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "from rdkit import Chem\n",
        "\n",
        "def seq_to_smiles(seq):\n",
        "    if not isinstance(seq, str) or len(seq) == 0:\n",
        "        return \"\"\n",
        "    mol = Chem.MolFromSequence(seq)\n",
        "    if mol is None:\n",
        "        return \"\"\n",
        "    return Chem.MolToSmiles(mol) # canonical smiles\n",
        "\n",
        "sampled_df[\"SMILES\"] = sampled_df[\"aa_seq\"].apply(seq_to_smiles)\n",
        "\n",
        "# 把 SMILES 放到 aa_seq 右侧\n",
        "cols = list(sampled_df.columns)\n",
        "cols.remove(\"SMILES\")\n",
        "aa_idx = cols.index(\"aa_seq\")\n",
        "cols = cols[:aa_idx+1] + [\"SMILES\"] + cols[aa_idx+1:]\n",
        "sampled_df = sampled_df[cols]\n",
        "\n",
        "print(sampled_df.head())\n",
        "print(sampled_df.shape)\n",
        "\n",
        "out_path_smiles = os.path.join(out_dir_2, \"canya_data_sampled_5000_smiles.xlsx\")\n",
        "sampled_df.to_excel(out_path_smiles, index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph5a439clW2G",
        "outputId": "acbbb6a4-69a7-45d7-f2a2-b584aabcce19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "                 aa_seq                                             SMILES  \\\n",
            "0          GYVCMKLDRYLS  CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...   \n",
            "1  SQLFYAILSIHYWCVTFFRC  CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...   \n",
            "2  SGTSLPNITLLDTFCTRCFV  CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...   \n",
            "3             MYEGGSTLW  CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...   \n",
            "4               DGRFFFV  CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...   \n",
            "\n",
            "   seed_bh dataset train_test  \n",
            "0        0    NNK3             \n",
            "1        0    NNK1             \n",
            "2        0    NNK1             \n",
            "3        0    NNK2             \n",
            "4        0    NNK1             \n",
            "(5000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.get 1000 from sampled 5000(with smiles)"
      ],
      "metadata": {
        "id": "gksTXmbSuSzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === 再从 sampled_df 中分层不放回抽样 1000 ===\n",
        "df2 = sampled_df.copy()\n",
        "df2[\"length\"] = df2[\"aa_seq\"].astype(str).str.len()\n",
        "group_cols = [\"length\", \"seed_bh\", \"dataset\"]\n",
        "\n",
        "group_sizes = df2.groupby(group_cols).size()\n",
        "n_target = 1000\n",
        "total = group_sizes.sum()\n",
        "proportional = (group_sizes / total) * n_target\n",
        "\n",
        "alloc = np.floor(proportional).astype(int).clip(upper=group_sizes)\n",
        "remaining = n_target - alloc.sum()\n",
        "capacity = group_sizes - alloc\n",
        "fractional = (proportional - np.floor(proportional)).fillna(0)\n",
        "\n",
        "candidates = fractional[capacity > 0].sort_values(ascending=False)\n",
        "for idx in candidates.index:\n",
        "    if remaining <= 0:\n",
        "        break\n",
        "    if capacity.loc[idx] > 0:\n",
        "        alloc.loc[idx] += 1\n",
        "        capacity.loc[idx] -= 1\n",
        "        remaining -= 1\n",
        "\n",
        "if remaining > 0:\n",
        "    extra_candidates = capacity[capacity > 0].sort_values(ascending=False)\n",
        "    for idx in extra_candidates.index:\n",
        "        if remaining <= 0:\n",
        "            break\n",
        "        take = min(remaining, capacity.loc[idx])\n",
        "        alloc.loc[idx] += take\n",
        "        remaining -= take\n",
        "\n",
        "sampled_parts = []\n",
        "for group_key, n_take in alloc.items():\n",
        "    if n_take == 0:\n",
        "        continue\n",
        "    sub = df2.set_index(group_cols).loc[[group_key]].reset_index()\n",
        "    sampled_parts.append(sub.sample(n=n_take, replace=False, random_state=42))\n",
        "\n",
        "sampled_1000 = pd.concat(sampled_parts, ignore_index=True)\n",
        "sampled_1000 = sampled_1000.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# 保持列顺序\n",
        "cols = [\"aa_seq\", \"SMILES\", \"seed_bh\", \"dataset\", \"train_test\"]\n",
        "sampled_1000[\"train_test\"] = \"\"\n",
        "sampled_1000 = sampled_1000[cols]\n",
        "\n",
        "out_path_1000 = os.path.join(out_dir_2, \"canya_data_sampled_1000_smiles.xlsx\")\n",
        "sampled_1000.to_excel(out_path_1000, index=False)\n",
        "\n",
        "print(sampled_1000.head())\n",
        "print(sampled_1000.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL39yHgRuayS",
        "outputId": "0a8c8dd1-7724-427d-9fd4-bdc6eb89ab81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 aa_seq                                             SMILES  \\\n",
            "0  YDMIWSSMLGFIERQAYMLP  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)CN...   \n",
            "1  LFNYVEEIRAVRRIRLGYIK  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O...   \n",
            "2  DNPTYRYTICGMTLEHPKEE  CC[C@H](C)[C@H](NC(=O)[C@@H](NC(=O)[C@H](Cc1cc...   \n",
            "3  IMCEGSLTNIVDGGLMHTSW  CC[C@H](C)[C@H](N)C(=O)N[C@@H](CCSC)C(=O)N[C@@...   \n",
            "4     RFMVSRYFISGPIIVSC  CC[C@H](C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C...   \n",
            "\n",
            "   seed_bh dataset train_test  \n",
            "0        0    NNK1             \n",
            "1        0    NNK3             \n",
            "2        0    NNK3             \n",
            "3        0    NNK2             \n",
            "4        0    NNK2             \n",
            "(1000, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### convert to fingerprint"
      ],
      "metadata": {
        "id": "ZBAcTcY3GuN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy first 40 to see the structure by SMILES\n",
        "\n",
        "df_small = sampled_df.head(40).copy()\n",
        "df_small.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZeFWoCcXG04u",
        "outputId": "3e257bf3-caee-4ae2-b739-e22a5571298d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 aa_seq                                             SMILES  \\\n",
              "0          GYVCMKLDRYLS  CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...   \n",
              "1  SQLFYAILSIHYWCVTFFRC  CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...   \n",
              "2  SGTSLPNITLLDTFCTRCFV  CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...   \n",
              "3             MYEGGSTLW  CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...   \n",
              "4               DGRFFFV  CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...   \n",
              "\n",
              "   seed_bh dataset train_test  \n",
              "0        0    NNK3             \n",
              "1        0    NNK1             \n",
              "2        0    NNK1             \n",
              "3        0    NNK2             \n",
              "4        0    NNK1             "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65dd558a-48f2-42a8-8e42-e8ffbb5ef56d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa_seq</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>seed_bh</th>\n",
              "      <th>dataset</th>\n",
              "      <th>train_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GYVCMKLDRYLS</td>\n",
              "      <td>CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SQLFYAILSIHYWCVTFFRC</td>\n",
              "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGTSLPNITLLDTFCTRCFV</td>\n",
              "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MYEGGSTLW</td>\n",
              "      <td>CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DGRFFFV</td>\n",
              "      <td>CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65dd558a-48f2-42a8-8e42-e8ffbb5ef56d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-65dd558a-48f2-42a8-8e42-e8ffbb5ef56d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-65dd558a-48f2-42a8-8e42-e8ffbb5ef56d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_small",
              "summary": "{\n  \"name\": \"df_small\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"aa_seq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"VMFMIAGNC\",\n          \"VEDKCVWFV\",\n          \"WFIRIAIMARSFCIIALVPR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"CC[C@H](C)[C@H](NC(=O)[C@H](CCSC)NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](CCSC)NC(=O)[C@@H](N)C(C)C)C(=O)N[C@@H](C)C(=O)NCC(=O)N[C@@H](CC(N)=O)C(=O)N[C@@H](CS)C(=O)O\",\n          \"CC(C)[C@H](N)C(=O)N[C@@H](CCC(=O)O)C(=O)N[C@@H](CC(=O)O)C(=O)N[C@@H](CCCCN)C(=O)N[C@@H](CS)C(=O)N[C@H](C(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)N[C@@H](Cc1ccccc1)C(=O)N[C@H](C(=O)O)C(C)C)C(C)C\",\n          \"CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@@H](NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@@H](N)Cc1c[nH]c2ccccc12)[C@@H](C)CC)[C@@H](C)CC)C(=O)N[C@@H](CCSC)C(=O)N[C@@H](C)C(=O)N[C@@H](CCCNC(=N)N)C(=O)N[C@@H](CO)C(=O)N[C@@H](Cc1ccccc1)C(=O)N[C@@H](CS)C(=O)N[C@H](C(=O)N[C@H](C(=O)N[C@@H](C)C(=O)N[C@@H](CC(C)C)C(=O)N[C@H](C(=O)N1CCC[C@H]1C(=O)N[C@@H](CCCNC(=N)N)C(=O)O)C(C)C)[C@@H](C)CC)[C@@H](C)CC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_bh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NNK3\",\n          \"NNK1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_test\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_one_smile_string = df_small[\"SMILES\"][0] # get the first aa seq\n",
        "print(my_one_smile_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdt7jwyzIaHC",
        "outputId": "15c6c53a-4ecd-4925-ddad-b7ee27c86d37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C@H](Cc1ccc(O)cc1)NC(=O)CN)C(C)C)C(=O)N[C@@H](CCCCN)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CC(=O)O)C(=O)N[C@@H](CCCNC(=N)N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CO)C(=O)O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_one_mol_object = Chem.MolFromSmiles(my_one_smile_string,sanitize=True)"
      ],
      "metadata": {
        "id": "bMLEPTK_IjW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(my_one_mol_object)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TvgxcocIn4h",
        "outputId": "ba92c836-ef22-494f-8f9a-07df91b8c5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "rdkit.Chem.rdchem.Mol"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_one_mol_object"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "jOcbEwm7Ioyu",
        "outputId": "98dbba33-5d17-4cdc-cfcf-6ddc17075bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7e70503c1cb0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem import PandasTools\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "# 这一行非常关键，它会启用 RDKit 对 Jupyter 的渲染支持\n",
        "IPythonConsole.ipython_useSVG = True  # 或者 False，取决于你想要的格式\n",
        "\n",
        "PandasTools.AddMoleculeColumnToFrame(df_small, smilesCol='SMILES',molCol='Mol')\n",
        "PandasTools.RenderImagesInAllDataFrames(images=True)"
      ],
      "metadata": {
        "id": "0jNRnR3jHGWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wx_SoUyOHiDZ",
        "outputId": "6584d132-8dbe-4c7a-9102-a575042bd2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 aa_seq                                             SMILES  \\\n",
              "0          GYVCMKLDRYLS  CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...   \n",
              "1  SQLFYAILSIHYWCVTFFRC  CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...   \n",
              "2  SGTSLPNITLLDTFCTRCFV  CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...   \n",
              "3             MYEGGSTLW  CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...   \n",
              "4               DGRFFFV  CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...   \n",
              "\n",
              "   seed_bh dataset train_test  \\\n",
              "0        0    NNK3              \n",
              "1        0    NNK1              \n",
              "2        0    NNK1              \n",
              "3        0    NNK2              \n",
              "4        0    NNK1              \n",
              "\n",
              "                                                Mol  \n",
              "0  <rdkit.Chem.rdchem.Mol object at 0x7e7058ce9070>  \n",
              "1  <rdkit.Chem.rdchem.Mol object at 0x7e7058cea960>  \n",
              "2  <rdkit.Chem.rdchem.Mol object at 0x7e7058ce8d60>  \n",
              "3  <rdkit.Chem.rdchem.Mol object at 0x7e7058ce9150>  \n",
              "4  <rdkit.Chem.rdchem.Mol object at 0x7e7058ce8e40>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6a0dcf5-bf1b-47b3-bf28-ea01c6c2b4c0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa_seq</th>\n",
              "      <th>SMILES</th>\n",
              "      <th>seed_bh</th>\n",
              "      <th>dataset</th>\n",
              "      <th>train_test</th>\n",
              "      <th>Mol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GYVCMKLDRYLS</td>\n",
              "      <td>CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK3</td>\n",
              "      <td></td>\n",
              "      <td style=\"text-align: center;\"><div style=\"width: 200px; height: 200px\" data-content=\"rdkit/molecule\"><img src=\"data:image/png;base64,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\" alt=\"Mol\"/></div></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SQLFYAILSIHYWCVTFFRC</td>\n",
              "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "      <td style=\"text-align: center;\"><div style=\"width: 200px; height: 200px\" data-content=\"rdkit/molecule\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO2dZ1xU19bGnzMz9C4KWEABEewFu7FgNFGDvcUajYoaEVS8KmLHgth77IrGRBIwRAUVe1ewYEGFAFZAeh/KzKz3wxkmCNMoo7n3Pf+fH0Zms/c+wzO7rL3W2gwRgYOjpuF96Q5w/G/CCYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjfDlhXX9+vXMzMwv3QuOGuYLC+vZs2ffffddx44dU1NTv2xPOGqWLymsjIyMoUOH5uXlderUqU6dOl+wJxw1DvOlLsIUi8Wurq7nzp1r27btzZs39fX1v0g3ODTEFxux5s2bd+7cOUtLy5CQEE5V/3sINFr7okWLYmNjnZycmjVr5uTk5OTkZGBgACAgIGD79u1aWlqBgYHW1tYa7QPHF0GzwgoPD3/48KHsvwzDNGzYsH79+vfv3wewe/fuHj16aLQDHF8Kza6xnj59+vz58+jo6BcvXrx8+TImJqa4uBiAjY2Nvb395cuXNdc0x5flsy7eRSJRfHz8wYMH/f39W7Zs+eTJk8/WNMdn5gvsCouLixs0aJCamvrw4cO2bdtW6nc/ftxsaTmvuPh1fv4DLS2L7OxQXd1m5uYTNNRVjirzBXaF2tra48aNA3D48OHK/m5xcQIAiUQoEiWnpx+ztJzPqerfyZexYz179qxly5a1atVKTEzU0dFR/xdjY/saGvYSiVJ1dR2MjfunpOzQ0qprZbVAc13lqBpfxo7VokWLdu3aZWRkhISEVOoXdXWd6tb1qVNnOgCBoLa19SahMEozfeSoFl/MQDp58mRUfjY0MRkMQCCwMDDompd3LTFxlYnJgNzcaxrpIkd1oC9ERkaGQCDQ09N78eJF2Z9HRpK/PxHRrl30/DldvkxE9MsvlJ4up5K8vLuRkczTp42JJJ+hzxzqI2/EevIEMTEAEBwMIkRHY80abN6MgoIaFHRISIhIJNLT0wsNDf3rr788PDzGjsWLF0hPx7Vr0i5kZSE5GQASElBUJKcSA4MO2trWRUV/5+XdqMG+cdQAcsQWHEwXLxIReXhQSQlNnEglJRQXR97eNSXnO3fusGv2vXv3sj+RSCQnTlB2Np0/T6dP07Rp5OFBt27RqFG0ejX17UuJifKrionx27On58KFM2uqbxw1goI11okTWLMGERFIS0PDhhAIYGeHjIwakXJSUtKIESOKiorc3d3d3NzYHzIMM2YMjI0BQEsLY8ciNBQAhgyBjw969lRYm0Aw6qefru/cGZCbm1sj3eOoERQIa+xY+PigQwfUqoXERABIS4OhoaJaPD0BoLgY//kPpk/HL78AwNy5ckoWFhYOHTr0w4cPX3311aZNmyoWsLWFrS26dcO336KoCC1aAED37jAykt+0ra1tjx49eDze48ePlTwnx2dG3iF0/frQ0wOANm2gpYUffsCKFQAwdKiiWvLzERWFkhJIJDAywsOHGDAARPDzg6MjmjWDvb1EIOABmDVr1r179xo2bBgcHKytrV2xKgcHAFiyBLt2QSzGnj0AoOSoWiKR7Nmzx8bGhvWbqAgRMQyj8Pc5ABDh1SsYG6NevZqqUj0DaUEBWrRAcjISE2FqWvH9iRMxahREIty4AYaBlxe2bUNKClhjAsOgVi07Kyt9kUj06tUrPT29O3futG7dWkmD0dFo3hwmJkhMhHJnrZMnTx49ejSUnTg/5e3bt15eXgUFBWfPnlX9jP+fWbAA7drhzRvY2GDMmJqpU93FWN++BNCePXLfdHcnIiospHnzyMuLiGjnTho3jry8qF8/at++qOyY0aBBA3Ua/P77d506rTtxIlBJmYSEhA8fPsTHx8t9NysrS19fn2GYuLg4dVr8f0pBAc2ZI33t5lZTtaorLNGvvyZ37Ljn++/lvhsTQ0QkkVBsrPR1SQlFR/9TID8//8CBAwB4PB6Ae/fuqWxxz549APr27aukzMGDB+/fv6+kAHsouWLFCpXNEZFEIpk5c+bTp0/Lv3H4MC1fTnPn0pMn6tRTI+Tl5aWkpHyOlgoLpQMDEU2bVlO1qissoVBoZmYGICoqSlEZf39auVJhDRKJxMHBQZfHW+To+GbJEpUt7tmzh2EYPp/fqVOnqVOnbty4MTQ0ND4+XiKR2kKDgoJEIpHySi5evAigUaNGYrFYZYtEFBgY+Pfff3/yo6IimjmTiKi4mGbMUKeS6vPbb78ZGRnNnPm5bChr1tDWrbRwIYWFUUFBjVRZCcv7zJkzAdSvX9/Ly2v//v23bt3KyMiQvZuYmDh27KwHD5TV8HznTrG5OQFkYkL5+UpKRty6JXdpD0BfX79du3Zff/11dNkhUQGSkpLB9es3BC5duqS8ZGxs7JUrV+S8kZlJixZJX0+frrLFGuHZs2cATExMCmroz6xOkzRxItnYkKdnjdRXCWGFhYVV9ESwsrLq3bv3iBEjPD09k5KSVFTx/j3x+cQwBNAvvygs9uGDxNZ2VePGrIwOHTq0d+/ehQsXurq62tnZscs1S0tLX19f1Z3+6adfxoxZCOzo3l15wdu3b0dERMh/b/JkevmSQkJo82bVLdYQHTp0AHDixInP1N6yZQQQQObmVFhY/frUFVZ2dnbTpk0PHz4cFBS0du3a8ePHOzs7y3b4enp6dnZ2KicmIqJ+/ah2bfrxR1Kw4iahkNq3J4AY5lbPnoGB5RfvmZmZq1evBtCkSRPZtCiflBTy8Xn9+rUuj/eSxyuaNEnRR6ZidZ+bSydO0NKl9MMPtG+fspKlrF279ueff1anpCJ2796tcolZkyQkEI9HPJ7IwiL+9Onq16eWsPLz85s0abJw4cJyP5dIJAkJCaGhoWy4aVhYmOq6UlLo+HHy8SFvb/r1VzkFJBJavpz4fALIx0duHSUlJfXq1bO0rHf37jtlbWVlkZcXFRWdtbRkv459O3d2c3Pz8/P766+/4uLiWF0WFhbKnwTL4u0t/UK3aKH6GYlev35969YtdUoq7nuWvr4+j8d78+ZNdepRn9eTJ89p1EiHxxswYED1a1MtrKKiop49e7Zr107J8LB27VoAo0aNUqvNqVOlL8rtQRISaMkSWrqUIiLoyBEaPZoUr7jXrn3F54tUbGLi48nXl1avlmoCKGe9NzU1dXZ2/uuvv1T3+coVAojHI6AoMlJJwezs7G3btqmuUA3Gjh0LYNWqVTVSm0oCAgIAMAzD4/GuXLlSXFwse+vhQ5JIqLCQEhIoNlb6Q9kLuagQlkgkGjhwYN26dV+/fq2k2Pv37/l8vra2dmpqquonkC2By62FZ8wgoZAkEpo0SWUdr14Rw5CxseI9QGQk8Xjk4EDnz9OyZbRiRY6X16WwsL1793p4ePTp08fKyoqdxNu0aaO6zxJJibPzTVtb1wYNlG/WMjIyLrJH+NUmPDyc3S1duXIlMjLy+fPncXFxKSkpGRkZlJNDEybQwIEKD+crT35+ftk1tLGxVbNmNHw4LV5Mrq505AglJtK6df+YJmQv5KJMWGKxeNiwYYaGhjt37lTZrf79+wPYsWOH6idYsYL++IN+/53KfRdlm/mZMxWNVRkZxI6b6ek0aBB5elJ6OqWlySs6YoR0oLKxoZISubXFx8ezFtRY5d8+IiJatWpV6SdurGizpsQWUwVycnKMjY0tLCzKbZiMgLPsozEMTZigfH+tPufOnePxeAzDtGjRws7OrmnTcWwj2to0dy7Nm0dPn9K6dTR+PG3ZQlu2kHJjiDJhZWZmdunSZeDAgep0KzAwEEC7du3UeoiICKo4oXh6UlIS5eXRjz8q+j1vb8rOJiJyd6eAAJrb77lk7txTPbeUKxYXE5PUqRM7c9HWrUo6MmnSJABL1LCrvXv3jrXuAqhdu3afPn3c3Ny2bt0aHh4u2w5Xc11VFolEMmrUKHb/2717d2dnZycnJzs7O3Nzc0djY5IJ6+BBUsParJJXr16ZmpoCWFlqiiwoED18SCdO0LZt5OVFycn0ww+0bh3NmkX5+ZSfX40Ri4iKioqy2b+kKoqKimrXrs2aue/evZuVlaXeE5UhO5s2bKA1a+j9e0VFvL3p+HEKCqKxYynELzrc0JmAR/xGjo6u3bsvdHc/GhgYnpmZOXvSpJ7ANCOjuL59KS9PSZvXrl1jT5lUbmnj4uL09PQA8Pn8itY1CwuLObKDkZrA19cXgJGR0bNnz8q/l51NHTrQlCnk6Um+vpSQUM22cnJymjdvDmDo0KFyV9KyY7pyU+HjxxQQQHL/1DXpmsx++1k2dulC9etTnz60ejXdukXLltHKlfL9iyuDtzdFRFB0NE2ZQv49VrBf3Eg0LDdTTAcIeFPm+6cIiUTSuHFjAOfPn1dSLDeXRo4M1tHRcXV1LSoqiouLCw8P37p1q5ubW7du3YyMjHR1dfX19dPVfECRiM6epTNnSIGaw8LC+Hw+j8dTuLFITqZ582jVKtq0iTIz1WnzzZs3N2/erNhDNu0PgGbNmqk5iJTl0iWSa6upMWHl5+c7ODiwkwWPxztlZSUdrrt2pcmTSSKh5GSaP7+arcimwsGD3zbnDdkAy/Otenjgn/AvhmE6lu4B3wDq/KVZq9j3Co5BiUgioaFDCaABAyLkfvQSiaRXr14A1FmMEhH95z907Rpdvy4dCj7lxYsXJiYmANauXausktOnqVMnMjCgMWPUadPf35/9iCwtLV1cXGbOnLljx47w8HD2QKVWrVrlz7LU4P59WrNGvrBrRlgSCc2d+zu7sK1bty6A1127SoU1dCgtWyYtV+0jkcxMkkjo1atXJiaNAMMlS3zj4+NXrNg1ZcqUzp07s6uElkCCjs5L4DLDSI8IAwPJ15dCQ+XWKdvSpsnfBVByMjk4kKkpvXqlsGMnT560tGwzbpyKgyMpivbFRBkZGQ4ODgCGDx+uwvy7bZv0E65bV3lrSUlJd+/e3bdvX/v27Q0reGtqaWlpaWldZqNWKklqKsXFyV9r1Iyw1q4lhqFvvrn6/PlzIsrKyhLev0+HDtGCBXThAv3wA4lE9Po1LV6sZoVKzoxzcnKG2du3BYYMGVKx2IcPHy5evBgfHy8QCKRDyKVLxHrW+/pSRc8FIiJq2LChvr6+t7e3SCQSCoXsBFVURK1aUX4+/fYbXb9OEycSEd27R8HBcmooLCxhrbCPH6vxeFOmSF/ITHqlsAb3tm3b5qvc6z1+zJrWimxtM1iXEgVcu3ZtxIgR7GuJRPL69etz585t3rzZzc2te/fuFhYW//nPf9TodOWoAWG9f0+6usTjkUJDY1QUrVhB/v7K19FlGTBggImJSbdu3WQ7L/bURSwWBzg67gSi9PRKlBqIu3XrBsDBwYH8/Ykd5O/coaNHK5YMDQ3l8/l6enrr1q27d+9er1695s2jbduoqIi+/55WrqSjRykykiZPprdvKTiYFB3fubsTQCpW8Dt30sOHFBZGCxfSokV09mzFIocOHVLL2i4W7+vb11ZXF8D+/fsVlfr111/Dw8NV11bTVE5YCQl0/ToRUWgoffggXTJdvky//041ZG0mItq8ebNsY1+W2rVr29vbXwJi2QMfpacr7HYPQMahQ/Tnn0REe/fSnTv07FlZz5CK22z2MZOSqKiIvL1p7VpavJgiI+nbb+noUVqy5BNhSSTSQTAlhS5dolGjKDqaMjJIvjk5JIR4PBIIaPduJT0/cODAjRs31PmgBg0axD7j4MGD5e5qS0pKXr58mZOTo05tNUvlIqHT0xEXBwDPnyM7G7duITAQCQlwcICHR6VqUkh8fPyWLVs6deoUGxsr23n16dOnTp06aWlp8fHxdXi8xmKxynp69OjBLoHnX7+OuDisXQuJBO/eoVs39OuH3FwAubm5Q4cOzcrKGjp06NKlS2W/26gRrKykr+fOxZkzAODggIkT0a/fJ62IxTh4EAAeP0ZuLhIT8fIl4uNxrUJs9vPnzxO2bYNEApEIy5cjO1tRz4uLi9XMndmpUycADMOEhITo6enZ29sPHDhw0aJFAQEBDx48yM7OPnbsWOPGjY0UBaJolErJMDKShg+n1aupXz+KjqalS8ndnbZuVbawYI3eYrGSc79/EIvF7du3b9u2bVlPLxnv3r0bOXLkEiAMuKyrK5Zn1Tx58mTDhg19fHyIaMqUKS2BQ9ratG4dEdHLl2RmxvrtnJ08OSsrS/k2WyyWeoyyg9CjR0REaWn09u0nT9e1K61eTZMn059/kpcXzZpFV6/S4sXUvTu5udHOnbnnz59//Pixvb09j2FOWFuTtjapWimr4/IqFou//vprAIaGhjY2NhX/sjo6OjV1uFQFKi2sw4eJiDZskArrzRtq1kyhsIRC6XQZGkpnzlDLlvTiBd27p9AXa+7cudbW1op2Z1TqAafNMFpAWMuWFQts3boVgKen5/nz51eNHBkKEJBuZ0dElJdHLi4EHLG0NAUm1KrlUtVttoySEumi6sIFqbASEmjwYBo/Xrpja9Pmn7GL9SS7cOCAympDQkLKngHLZenS4u7dp8v6n5OTExERcfTo0UWLFg0ZMqRWrVoMw/yo+AyjPOfO0erVctd8VaNywnr9mthDi/PnKTGRQkKIiLZsoTNn5JcXCmnsWLp1izZtojNnaPZsmj6d7t2jDRto7VoKDqaXL8UlpQd59+7ds7S0fPdOqScMUQc21BAYBVQ8Jly2bBkrLDMzM9dSg1a6nd2pU6eePn06eeLEwPHjTYF5DMMauqq2zZYhEkl3uleuUGgosWOonx/t30/h4bR9Oy1bdr1Xr14WFhbsLnXcuHHqVSs6d+6ckgInTxLDkEBAV6/KP6WIiYlhGMbQ0FCtBdbDh8TazDZsoLt31emhSqq7Kzx/nhiGOnaU/65QSKNH0+XL5OdHZ86QlxdduEAeHjRlivQL3bz5PW1t7ebNmw8ePLhx48bqHAbv3rwZAANoA6kVHI5nzZoFgLWlOQDLgcs9e1LppqmoqCgmJmasvT3b/Hs+v3pPXwnYQ/qNGzeqWT4sLOz69evl5uj0dCoqIiI6coT09WnLFiIiRdZyV9cpPXuePn5cDWHt3UusU/nz57R9u5o9VE51hSUUkpkZAST3XF82FZ49S3/8IbUzjxtHK1eSlxf170+DB59kJwh9fX0rKyuV4z8RZWVl6ZSe1k2vYAf6/vvvS2ceHoAhQyZWrKHk0aNoPb0HwFmGKVHg+FDjBAUFAWgpb/quSHR0tJWVFXs0Wb9+/fHj02bPpj17yMND6hEyZw4tXCg9U1V0GHzoEAHUo4ca7V28SMePExH9/ntNzYY1YMdasCCpV68VS5f6V3xLIpEudefPp8aNifXTzMr65MwwPz//wYMHjRo1AnDq1Cl1WjQ1NR0IbASWtG1b7i07OzsADMMDYG09QiyWb7wuLCxk56Zt2+SZOzVAUVER62f79PRpunpViUlPZnw3MTHR1dUFYGoqYQf4CRNo1Sp69ozmzKF16+joUTp9mkaPll9Pbi4ZGhLDKLB9sERF0ZAh9OEDbdpEq1bRhg2k3NyvNjUgLDZpu4WFhaLxJiiogGGIz6cLFxRWwuZxGDRokDotejVpEgEQ4A8YGRk1bz5m6NCV+/ad9fcvsBUM7Ak4YrK5uW9sbAERKTpw69PHG4Cd3QR1WqwR5syZ4wKEduhAN27QxInSWe1TxGLxgAEDALRu3TovL08sFv/9d/yZM+TvTz/+SHPnUmYmubmRpyetW0cXLtDjx/TDD5/UcOUKCYVERGFhtGkTHTtGRCR/d5iWRra2BJCpqaIziSpTM0c6LVq0YBjG2dl5/vz5Bw4cKBsZ9vjx41q16nXr9veW8k5Tn5CWlqatrS0QCBJVuUSKxeIjbAwZ4P/pBtsa3nvRjYBj/C7z52d9+EAlJfTTT/LruXEjAeABeq9fq+UdQERnz549efKkmoUr8vTp052ARa1aQqGQDhygO3do+fJyTi9eXl4AzM3N5cZ3+PhQQQFduECDB9O6dfKnwiVLiP3s3d3pxAnq04dycmjOnPKOFCUlJQtGjRI2aCD1WivNJ1VT1Iyw1q9fX6tWrXJ2FCsrq+7du7OnnuPGjVdZydChQwFs2LBBeTFvb29XYIeu7qtBg/YOHtyxY2dLy/Ha2j2AhovwLSu4c1YDfX1pyRLy8yNXV4VV1a07BDDfvn3f27eUkSFdBcudOLKzsz08PAwNDQ0NDbt06VJl+1CApeVxIK1xY5o9mzw8CCA+P2/yZDbs8dixYwC0tLQUBXekp0tnqpQUysiQaqVcvPSSJbRkCa1eTYMH04kTFBRES5bQnDnUpQvZ2dF339G6dX8cPHhw5MiRAGpra39o106FM2iVqAFh5eTk/Pnnn/fu3QsKClqzZk25yDB2ba6Oa+Vff/0FwNHRUUmZoKAgNjxabkTQ8Z7b3unrv4LZz2YTfX0pOZmIaNYshbXNmHGrLTadq13nXMelwcHEbjFnzy5vyw0JCalfvz4AHo8ns4n37t27Cv6i96ytSwAChK6ukjZt2FPkE82bA5htablMIGgF7FGQIENNyo1YERG0cSMNGEClozy1bNmt7PffpVcvibxJuZpUV1hpaWkZGRlCdlYvAxsZJjtMCAoKUllVSUmJlZXVdOD91KlyQ0AePXrE6lVRGMy9e/TixSuG0dbXH3TjhpA9Erx6VWGLp5bdu8rYEPBIYDd0aMCwYW+2by/p1esfYX38+HHCBGkeefb4cteuXX5+fmy2AQB9+vRRnjyiLFFRUQ/YeQeI3bgx76ef8nV1xdraVgLBaIZ5CRBwtGdPNWtTxMGDlJtLRLRtG12+TK9eUVERubtTcTFFR9Mff9D69VvHjh3LxpIYGhp+/Pixmi3KpbrC2rRpkxIbo+ziiS3KV1ilzDcySgIIcLO2njp1RkCAJDJS6gT/6mzkAKuWtTCsfXvpIbCisOQuXboACAgIUNncz99tZP/MEWgEDAUG6evXt7EJ27Jl2/PnzwMDA1lna1ZSDMNMmDCB9RzMzMxcunQp+7VhGKZ3794fPnxQ3lZqKg0Y8K6/fu2tvXrRqVPEusnn5785ftzOzu6szDlx+XJ1Pqjqk5CQwOPx9PT0MtVzQK0sVReWUCicMGGCckP5K3f3tw0aFNWpI5LnKlmOU6dOPSr9fPsDPF7T0ogB8dRetyO0HAjwqj12xgzpKlSR/Wbfvn0AXFxclDd340Zaa6OJ81FvhWE9D/PdgwYdtrWdwjAMsJ21gcn0BKBx48YV1z1paWnLly/X0tIyNTXdrdRhobiYevUigAYNyqk4uhNRrLv7UYHgILCwWzfl3a5BXFxcoNTlpjpUa8Q6cOCACr2z61PWj1QpIpFoeIMGPsDPwC9GRsG+vgsWHHJxSW3QILN27dQb+m3ZeoIH7xo9mlavptWrFQorNzfX0NCQYRglh4APH5JAMA6l8Zk3b95kj8mTkpIOHz42YcIEHR0dPp/v5OQkEAg8PDzyFJidevfuzcbiHTlyRMnTpaSQszPVraskTIR8fHwAXROTz2f+YCNUu3btqonKqyis58+fz5o1S3XKio3SuYacnZUX3Dx+PAFvGGZ969bHK7jjPXAam6Kl9QFmu1w2yBbjSsKPJk6cCGCZzCX6Uz5+TGnU6DeZHXXevHkVy3Tu3Jk12EYqjXtu06YNO9fLAiofPSL2lHnzZoqOJhsbysqio0fp9m1Snh1HKCzm8T4CdOjQc2Xlao6CggLWF02dvD2VpYo3U0RGRu7atWvXrl0qyo0YAX9/TJ+O+fOxcSM2boQ8V6pjx441OH4cgA3RgoyMcf8cy0jJ2vXLb5s2WfO67M/sOHiw9IelXm5y+PHHH9kRKyYm5unTp2XfKnn1yr9XT5O34wAQSWxtbVeuXFmxBnb9pK+v7+zsrOT5ZLuTsjmb37xBZCTevQOAr7/G+vUAoKODpk2V1ARdXS1n5xcANm5MU1au5tDT02NDF48ePVrztVdNjzKxl7tXojzPntHKlVRYGNesGTt0uU+dunXr1vPnz8u8b5+dOtVaV/cQIFEaX5qQkMMwEkBOoGtFJBIJOw/u2LHDz8/vyJEjO3fu/Pvvv99evXrHyYmAwwAb9avIbZc1qv3xxx/KG2Kt5AAWl7rzP3pEc+fSuXM0fTpFR9PixbR1K82ZQ8ozh7GEhcUDR42NHd++LYiJoZs3iYiKikhReqXqc+fOHQAmJiZXrlxRN3ZNPaq+xpo6dSqARbKkZHI5epRu335644YsLYduGU0bGRkNbdGiGCDgQuvWdPgwLVyoJGC8QQMC6Ntvq9LboqKivLy87NKkMYcBR0dHN8UpN9nJVPnKiYjYbzyA2bNnsz8pNxUuXkwlJeTsrJawiMjYOOJXNEo0bxC66DI76Wdmkhpx2lXHyclJZpyzsLBwcXGZMWPG9u3bw8PDVYwaSqm6sG7dugXAyspKmYPAzZu5W7c2t7W9AjwzNz8OaJWqio0nLi4VXEl8PM2cqdAFhIiI1q7NNTHxdXLqIRRKcnOlZkCxWH4krnwOH35vafkAWA6MGTNGSSQM636jMhXFlClT2MeZVJrIJC9Paph9/57y8yk29p/YUnUINelVAC0CBvG+NjAIt7c/1KHDuQEDHty4cUMTruslJSW+vr6urq5yI8P09PTOVtXZoVq7wqZNmwJQ0nZxcfF2B4elwNb69ZMTE318fIYPH960aVMtLanAsrS0ioBsIC0qinbuVJ49ViwWa2m9mIMGUd/8cGbTS3bxnppK6g6UkXMAABcWSURBVKWulRIfH88wDMMw7dv7btmi8CuxaNEiAGvXrr3JTkgKWLx4MeuzMHz4cEVlIiPVTZQXERERydiw37SBzNfATgCAKeALQF9fv3///qqerxIUFNCvvxaV9dd9/fr1+fPnt2zZ4ubmZm1tDWDs2LFVq7xawvLz8wMgi1mryE8//cSOauXMXcXFxS9evAgKCrp27dpRJ6fmrAV1xgypzVgxay2mf4QRAad/Chw1ShwcTEePVk5YRNSjRw+gCY8nUeRwkZKSwi6e2rdvD6Bz586KQt1v3rxpY2Ojp6fXUZGvIxERtW5NDCMJCZHjyC8jKiqlTp1xHTC5DzC1kXvIwcRZs5JOnjzp7b22bdvDLVq0EAgEfD5fpSVWTbKy6Nw5haFsRPTu3Ts+n6+rq1s1C2q1hJWYmMjGEA8bNmzp0qW//vrro0ePpAbA4uKTW7ZYALq6unfu3FFSScjJk/OAnRYWpCrmKSUlJYpnzX6hpzUYp6UVYGTUqWHDMQ0bHvr2228HDBigpq2PvSTRxuawlhaVdUAvKaHTp8ndfSubV7dBgwYoNZMCcHFxKTt6ZWdnz5w5U2Y+Ve5JvH//vYYNG7sqPg/PzS02Nn4GiBhmDICDBw+WKzBmzBi2LT8/P3WekYiKi4k9rcnI+Gfh+uGD1BMsMJD69FFRw8px4x727CmskgW1WsI6fvw4ANNP76rg8/mOdnbz7O0J+Bs4zEZfKIY9IgSg3GKUn1/crVuvuRj8S92651rMY6fCFy9e+PhscXQ84eTkBMDQ0FCdNMN5eXlGRkYA79Sp+MGDKTyccnNp1CiqW5cAatv2kkAgGDhwoI+PT4tS/3qZvPr165eZmXn27Fk2MEZLS2vhwoWFqia5tLQ0LS0tgUCgKIFWmzaLABHwBrDwkndKMW3aNLYDqjOvlvLunTQ66dixfxzZ2RydROTpqYZL34kTBCh0PFdK1YX18OFDdjdhZ2e3d+/exYsXDxs2zNHRUSAQdCtdkifw+SrdYIho7ty5AGYp8UMgat58BgBz82bv378vKKDcXKkbqmzx3qpVKwC//fabOp1nszAuXLhw7lyaMYNSU2naNAKoaVPasEEsy3clkUgCAwMdHR1l3xlra2vZgr1t27YPHz5UpznWxs2q08zMzNnZecKECbJUqEdbtvQGTJlvgLZ9+/aVuxm6ffu2bMejplfFu3c0fDgdOEBTp34irI0b6f599bJus47n2tqfhLypRxWFlZyczM4UAHR1dcue8BcVFT3YsUMMiIFXAI/He6uqW0+fPmUAa8WZ8qZMYZexuocOKYwhYa2136pnjRg4cCD7lzY1Peji8lPPngUDB1JAAPn4SOPbFi2iTZuITXy5cKHkyJEjrNMzKw4DA4OtW7eqeSlBTmSkpYkJ+1mx/tBlmQ+wjjS2QOPGjeUGVLI0LTWwTq3g6S+Xd+/Ix4eSkmjnzk+ElZdHbm5Uah5RxYULtH49+fpSZCSlp0u9y+/eJVXBVFURVnFxcY8ePWSf8oEKgXLlLkVavXq1ktpSU1NXTp0apK9/jmGSGzakp0/Jz4/27Ck8fDgwMDAgIMCzZ892gBYwZUr5lUdZsrKy9PT01EkznJSUxPqSAwA2AdDTkzqVf/89zZtHKSnk6UmrVlFUFL1/L83BW1xcvG/fvkaNGnXp0iVB/VxniYlUv/7HevUcDQz09PQiIiIyMjJu3LghS4VayGa9B2a7urIpVRSxnjXhA4aGhrmqdjlUYSoMCaGwMPLxIaGQbt8m9ZzAidavpwcPSCymqVPp2TPatImI6OBBlXa5qgiLne/ZYVnuQZtYLGY3qyy2traKlgUlJSW9e/deBxxjGAKKtbVp+nT2g/5gaAigTekXeoAa8S1jxowBoPJigad+fo7m5uzA4+f3PCjoz2XLqGdPatuWZs2ixETy8pIKa/t2OnyYyloS5Pj1P3tGYWHS9Ims++nbtySzObm6sh4aIkvLcHluzeJp045paR0CnqiKcExOTtbS0mIY5k8gw8QkT1WyZ4lE6lVfXCz1Nd29mwoKpEsrdROXyhIt7dhB585R//60ejUNG1bzwmINPOxY1adPH0XWUW9v77KD1rVr1+QWc3d3B7C39FtLAgE1b86+ljCMoIwFtViNG7wuXLigXMdERJmZZGQk4vOj2rXbs3Qpu64Ti8nDg4ho4UIqKaF9++j772nVKumuStna7/ffaetWunuXJk6kFy+kqVH27v0nGi4+nmrXJoAUpwqaPXs2ACXHADIWLVp0Tle3CCDAFTAzMyubkCdGaTKjgwdJadJCBci88j09KSpKUyOWSCTS19cXCAQODg729vZKTpfYSFyZsCbJy7B95MgRAAzDLAWSdHTEAwaQvT116yY7/2nD578GEoFEIFoNN3OxWNywYUMAV5W4jfr6StPCamnRmzejRtGaNbR6tVRYT56QREJ379Lw4XT/vtSkqWyBLvtCb9xIFy6QqyutWUNDhtC5czRrFq1eTYsWUW4urVunKCskET158oRdqqrcXe7atSui9MMZVuGuIQMDgx6KwwgfPlQvd1c5cnJo1SpauZLOnKGPH6WpqhTlhyxDpUes0aNHA/Dx8VEZC//VV18BaAx4Ad62tuWWurdv35ZlFf+pdu2sw4fp3j16+JDWryeBgBwcaNy4W/v337p1y8rKCjAYNmypOt1bsGABn8/X0tKS7bwCAwOfPXv2T5afoCCysCCAJk+m0tFINmKx9O5NgHqXm8yeLU2KtGQJ3bpF27aRREJ799KUKdKV/7Zt8mN5P4VdORxjY7UUcOfOHR6P1xLoAnh27ChKS4uLiztz5oy/v/+PP/7YsWNHgUCgzlbp81BpYV29ehXqpRk+dOhQSz29wwABz4yNy90Zxu7LAOjp6T28fJkmT6bQUJo+nd6+LXdiuHx5MJCjo6NW6o4HDx7IzQGkr6/f1Mnp2jffkJsbTZ1Kp06xFyuyE5REQmUP048dI4C6d1cVYvD2LUVHk7s7rVpF69bR33/Trl1ERAcP0vjx0uHuyBG6fVtlt9mFuYODw4sXL+7fv18x+016enrZ+JSKUWiDS92JlG+VPhuVFpYszfAFJeGnREQkFAqDSrOu3P70z2xpadm0aVP2zE5qecrLo8hIuYfQQmEJj5dcKQ842c6r7J1hw3R0/A0MpPOs3Gt8SsnPp2+/9TYzq6XMA+7KFdLRke67KnL1Kq1YQffv08SJ6lymlZ6ebsjjPQHiDQ31AADW1tZ9+/b18PDYs2dPWloaO8WzyHVgZHPUql5ifi6qsitkU5CPUZWs9/bt2x14vOPAaROT6O+/l3tnmLvyLPSldOkSDpwcPXplZiYVF0stovn5lbj/LCsra239+rLVG6ky27q5uU0Gnjk4kLygjHcJCeJGjQigBQsUVhEbS2Fhyv01/iE//5WWFtu3inemH7S2XgOwgUGDBw+Waz9j49HZrbqirdLnpCrCkh1PKrHmJSYm1rOyAuBUq1a5ACk2v2pgYKD6NsaLF+N08XibtsHtbvOePxGxWR1PnqRKfYDBS5ZkMkyqkQWZmZEq4/UjD4+/oUNA/MiRXl5JN26kBgWJiSgggGJi8lu3bj3Q3j5n3DglS/LKkZMjE305Ya0oY0Ft3ry5EucZ9uxB0VbpM1NFy/s333wDYPPmzXZ2dgMGDGAj62/fvs2ehAuFwo4dOwLoA5R8/XX1e5nwQnhAvy/7ufdzmdW6ddycOTRhAoWE0ODBVFJCf/5JsbHSeSkiguS6hWZnFwwyu+bDrEn8TYUehULhr6V56v+w71W79nE9va56erPt7R2trbfVqtUeQJMmTWoycEokogsX2H+v4+P3798/adKkDh06WFhYCEsFN7NfP+U54tj8F+z28IvkHS1LFYX122+/Aah44SoANzc39iTOVkcnFZD/R64krx9nyr7QOmhWr97V0vRaNHgwbd9OBw7Qkyc0axaJRHTpEv3+u/x6JkwggFSG7k2a5NYVvRYat7szcfPaQXdmzqTISPHXX2f07Blap849U9N2hoaG1fGurBTiuXN3CwTbgamdOsnNIyLj48ePrAUVGgvqUp8qCosNsZKJ6SugPsDj8UYzTK1atToD63R0kj09la+R1SQlhXZuDNlv3KNwlscBE4+N68/26/d+5EiytqaBA2nZMvL2plWr6MkT6tqV1q2jadM+EVZJifSk7O1b+uMP6t2bbt2ijx9J0Zffx2cvcBsgV9eMU6foyROysqKHD4n1ZNm0ieLiSKWppWbx9PQEMFMgUJkof9WqVW3bttXR0WlbIcHTZ6bq3g2JiYlhYWE///yzp6fn1mbNvq1bF8AOwIhhjunoZLJr23IpdipPQQHZ22fx+Tdv3vxAROnpVFwsvWMjL4/S0mjZMsrMJCcnevJEGhB25conwkpNlfp9rFhBq1aRnh5F9FsS22XCurFyvFVXrFjBML8DxONJdHWl2RxCQyk1VRq89eiRusvxGuTly5cATIB8Pp8q3tlUhosXLwoEAoZh1HEq0Sg1dJfO3r00e3bh0qXZzs4H5s7NlyWgqJ4rrUQiGTjwMUB16mTJ3ScUF1NEBBUX0/r1dPSoNE3D+/efZH5ITSVzcxozhlq1olWr6EDdJdl8MwIWtQmzsSEXF5o/PysoKCg9Pd3vu+9GAjYw19LKZvuuzrWenwc28/Yvbm50+zb98gulpVFeHrHTcVwc6/+fkJDA5gRQ55Y8TVNzwmLty+7ulJ0tNW0DNF519qLAwECRSJSXl1feCS4vz2/06OY8vqnpbqWn/hQWRgA1aSLfcy01lVq3ppgY6blyjH5rtm+T64axfdTTuwSgOxAFEDABaNt2jp9fTaW2qxl+/vlnAOtatPg4ZUpeo0YiGxuKiSE2o+mhQ/TgQW5ubsuWLQEMGjRIzb22RqkhYV26RKyzCuvNFBJC3t60bJnKAJrt27cDGD58+PXr111cXKKjo+fPn5+bm5vw7Fn42LEExALH2fSYihGLydqaAJIb91B2Kly2jFbYHilZ67+1vv/M/glTp1LnztSq1TEtLa0LpZuDSXz+v8EOVA727vFTwAd9fQLeAcMMDe+YmQU7O8e0bJl1+TKb78rJyakqN0VqgJq8r7CyvHlzTV9fV3ZAIRKJSkpKkpOTCwoKXh08yP6Z49VLbOzn975zZ383N/nmVtYLf80aatNGemuiUFg+buN5//7XgevAAB7vyenT1Xw0TdC/f/8Q9q4XIBnoCHgBACYD60aOBGBmZqZO2unPwxcTVmFh3OPH5nfutPP3lxdkc/9+toFBInCbx1OnNllac0UecAkJxfr6ZG5O8fHya5BIJObm5gJG/2cjB2ratMYsnzVHRESEW/v24QYGvzDMNsAacAMAjAJa8/l8Pl/lIdvn5EsJSxwd3SYyErGxrkTyFwS5ubms19cviu6xKENKSgp78mhoaFjxzjAiatToWL16acr9LvcvuKODwtHMSQLo0KHKP9RnorCwMCoq6uTJkytWrBg1alSrVq2MjY3nzp37pfv1CZ9DWJmZwcXFSUSUkrJLIhElJq5MTFyVkfHby5dfiUTK9u5s3rZWrVqpbGLv3r0VTbUs5ubmjo6Ojo6OKgN4XrwggKyQRAYGci+g+9ei0tPk81PFbDOVoqjotURSAEAojC4qiiES16271MxstKPjDT7fWMkvsveXPH36NCsrS3kTj8PD2Rffffdd2TvDLCws0tPT4+PjTUxM2Hz8SnB0RNNGwo6O2UL/HXj5Er6+EAor8ZxfDrn3n39hPoN4k5M3v3vnlZi4OibmGyJxUtL616+nsmOYSljnKhUXxKenk7b2R1PTv7p1O1/hNOfSpUs6OjrqBFkQUa9e9PLS+5c/rBUaWxBAS5fm5qo+AuKoyOcYsQDUqfNT3bo+OjoORGIrq/lmZiNycy+q84uurq4tAJudO1NWrFBY6M8/UVxskZ098MED9nS8LL179x42bJhEImGD+5TTsiW2bCb74I26OSkAXkdlxcSguFidnnJ8wucQloFBR4HADICJybciUVpS0tr8/LumpkPU+d3NP/7oC8wVieJWrvzmm2+ioqLkFLp4EQCI0K8fjOXMrZMnTwZw6NAhIlLenLY2ho7RFRZK//u3bsvoaHW6yVGBLz1kquDSrFkyH1QGCALmmJpOHD8+MDBQGspRWEgnT5KHB02dKr2itwJqBVkQEUmvkRrf+8P+IWfcez4hkSgnh7y96fVrCg2t4Uf73+ZfLazsbEk3Y9NNwGaGmQ24lxrHjwMA2OSzhVOm0MyZ5OCg7AoKIvZm3h9UHYqzAVRpafT+PbHnSCIRvXpFyckUGkqqbmPh+Id/tbCmTyyw0nrYwrzVzz//7Ghn94HHI0AEeAA7gaUMs9XAoKBFC+mlC0pzV8THx/N4PAMDA7m39KokJeW/y/7w5flMi/cqcO0a9gXoZpY0O9m6x/Tp01/GxdWLiChwdk5o2vSrhg1/b936r1at3uXn89PTkZ4OABKJktpsbW3r1asnkUjmzZsXHR2dkpJCqtZbZYmOhp4e0j5T1tn/BcrnqPg38OABnJ3RuDEmWF1wTL7ebPVY6Rvt2ulHRDTOy2vs7T1882aXvn2zgZTu3RvweBCJUCHXclnOnDmTmJioo6OTlZU1Y8aMqKgoiURSu3btOnXqGBgY1K9fn03JpIiePWvw+f5/8KWHzFIuXJD6R+zf37EjJX81TNjI6VXvGfJT7oWHk6/vwt53jvMnnj2l+oKhly9fmpiYAFizZo3sh3FxcVu2bBkyZIizs3OXLl1q7EE4iOhftMbau1eagHTWrOttZ5fwdQi4M/WAQuvkq1freoQaIUel87PswlLWmiW3jDrp2jgqxb9pKty/H5aWiI5u8vajQFwEQGhiheSIggLIiW1u0uRdiyaCpxVr+QSJRDJ+/PjY2NjWrVsHBASUTSdRFpWnPRyV5d+0eJ82DT4+aNbsYucl+Oqrv/rvJob313P7li3lrJqzs5GairQ08PmIj8e2bQBw5w5u3vyk2IIFC0JDQ83NzYODg2WBshyfgX+NsFq2RO3aAODiMu7MGGzZ8l2n9L/P/T36tmd8PHx8YsSf3pUiEqGoCIcOISUFBQXS+0Wys1H2tNrPz2/Tpk1aWlrBwcFsPj6Oz8a/Zirs0kX6YvhwAGjfnt++fcR7FD6DsXHYvn0DTE0XsJkzIiJw5Ajs7dGpE16+BHuZzb17WLMGsbEYMeKfKi9fvqynp9ehQwc2/yDH5+RfM2LJY+dOjBiRrq09n2GYxMTEzZs3jxmzu2NH7N6N/fsBYOFCsFaCTp3g41Pe4ODp6SkUCpOTk6kyJiuOmuFL7x5UkJiYyN7HzLocWVnVr1NH5OZGd+9KswNdvEgpKdIkDgkJn+QDE4lEbAbeKlzezFFN/u3CIqK7d++2aNHCyMho0KBBf/75Z3FxJbwl2cSWaqYZ5qhBGPpvmCZu375tY2MjSwCuPjExMU5OTgYGBklJSRUvIeLQHP/qNZaMrl27VkFVAJo0adK1a9e8vLzg4OAa7xWHEv47hFUdWC8/9v4cjs/G/76wRo0axXrLCP9LIiP+N/jvWGNVk3fv3pW90IDjM/D/Qlgcn5///amQ44vACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjcAJi0MjcMLi0AicsDg0AicsDo3ACYtDI3DC4tAInLA4NAInLA6NwAmLQyNwwuLQCJywODQCJywOjfB/9YMB2FnSiIEAAAjRelRYdHJka2l0UEtMIHJka2l0IDIwMjUuMDkuMwAAeJzN1HtcTdkeAPB11tlOJ0mJIoqtVDsKCYXq7I300Dtv0jYe7YqMkopK5VFOpVSSV6FDiTxmmFHUWfsyxh0G45XPjCFX04hruBl3zIxr5pxfHmfy8Zl8+OOez+d81rfV+v3W67fOw/rqm0jzMdZ8MWr7HNZ8j2m+aRIZ4jWtRNrWYiyjh2tbCfXqHy879JCggRRrQhgtKHlb+2ZIR0dqZmPbBshYiJBKdPAyFDokkjeHfJhp3op3SA+ttN1ZvtM5vGrbBr6IlOCXEX+TSqK9Hpj0VSp5299vBLzO9DLy77bR8QwdnBM23uFVtb87PdYVlinV6YEh77DQ96q7D7P2d6nIF2M7PK/xh7qH97upDuH/Jn279o0X96rj1eN8/wt5XWV/jZBIXz+ltzzK9gF/Xb9EaoAkml8DhKUUxhSiOlG4k4yW6TFYJkdyfQrLO6POBrRBFwYbGCLDrhTuaoSMjAVs3I3vZiJgk+60SQ++h6mADc2QWU+6Zy8G9zRH5r0pSe8+qI+FgC0secu+Au7bj+9HC9i8P+pvRVtZM9hqABpgQ2EbW2Rrh2wZNMAe2Q+kBw5i8EAH5OBIYcfBaPAQNGQoPcSJwQ7D0DBn2nk4g51HoBEjKTzCBbm4ImoUGjWawaPG0GPckJs7hd09kIcCebDIjUPcWAZz4+hx49F4T0riOQGN90Je3gz28qF9fSiJ70Q00Y/BE/1p/wAUEEhJAoNQULCAg0P4kFA+dJKAAyajyVMYPHkqPXUamjadkkyfgWbMFPDMWfysMAGHzabDwvlwXsDT5qA5HzF4zlx67jw0bz6F5y9ACyIEHCHwQiQfGSXgqGg+eqGAFy7iF8UIeN5itPhjBi9eQi+JRbFxFI5bimLjUfwyBscn0IkJFE5MQknLGZy0gk5eQeHkFJSSyuCUlfTKNJSWTuH0DJSxSsCrVvOr1wh4zVp+baaA07JQ1joGZylpZTbKzqEkObkod72A1+fxefkCzt/AbygQcHYhKixicOFGemMxKt5ESTaVoJLNaPMWtGUrvXUbg7dup4tLUWkZg0t30Dt2op27KLyrHO1UIdVuBqv20MkVqKKSklTsRYlVqGofqtqPfKtR9QFKUn0QHTyETI14ug8/KYjnZ/AxC/jMDL4gl4+J5MfKNRUnM+5m0sPUSGZh2bcf3adTcNCk0BDZzFmag5zRKWJBTKQgi4peuCgmUrZq9Zq1mRmy9Xn5Gwpye07RxErQi8/hHk331a6DzrLaP87nVag/DSwFez0e4tG/uhg8wzVP0b35OHj27uEKl/JQcNwjA7b77PHg6Fxv9llEJth7ri2bPu4IeFxVIXtFuRJMnh5mw56rwJPVKvaryzbgO1ZX2N3rzcDhS1rZbDQH/LPLD2zM7DiF1qJ/Z+6Gz0iw73UTzq9gqFrrLoel3H8cHoCLxnThMvyDiNYzH1hzFQXhYE+VExfluAm8uYczJ9Km4G7KgdzNPYsgNrHlNFumml6vtfJ5A1u56zz0Gx6qYUeddCIdnUs3P3/al2uePwDcEhTKPbJIBe+zH89Fe6nATQkO3HXVNtJ+X7r7XZR0l32q2gP+Y6k5VyN/BF52z5hbcDwYzupIN5rbY7Ye7JDZkxvUWgvmDV25JT454NO2TtzHqd9ALBXAcpZOztB/MG80l+6cBT77x1Tu1/vWYH27CO5mWAz44vVUrrZXOFgPZXJBXxSB710v4OqscsEnazO4KztE8CQlz92MLIK5+rglcvbqaPD+w6u4Q3M6wZiQuWncs1H/hTOfX7aE8429BHsf4ZbD5Tu5gpPS87mYk3pwPsajE+pDnPQhdquqUr3DxA9sfGSjB93iDvm/3WynvneiAXIWVMtJrt0Y8NGGgcRKfxuMES6sJtGFteDIH62J7ylHyBOt/KUuIKwF5i21Gqu+WzQR5s03PaA491gKvhbZqrhWFQbWezaV/e3hQnCan5I1TbUCnw2PVczuWgS+13hJ4bSyHlx+Qq4+G50DHltSp65XHQa7F7oTB1wFfpw0k7SUNrTVT1048fdfDvYYW0bs5dHg2vw6ole3BVy5Yj/JKfkSXOefTNIHXAE3ZiWQfZ2xqPWTskrivLEzuOT4aeJ15iGMCZx6iPQL7gauCGgkRz8zBF+WF5C4+lw4hybLcpJRX+yhdWz6JXI5Tg7n9tOFR+RkaH8YU29uLM5JPQPn/IztJ86Vfgn9cZ+Zicdd3SFnVgstphopwdP1n5PGFD/w97W3yO8GmLS/l/OZSlKwxY1tf3dJ8TfUy5b1YtvXg24NJNjoqT8vksIavBZf9vg2pAH8g89dRdHzAnB2vg+7a/s9cHmfXJZPygAPr1Gyot0T2O9FGcs+v9tWwwPJTUWryafQ3zjPmKQ5xsK8PZ0uqG+va/tN+33QYhJSkwY22pdFGoqqwbY1k8hXX18C+9xZRgL3/gHe3vUYiXI5CjYPu0YSnueBD1j/kzw0+RfYLfMpST/aAr4RZSCuTz4FDm3Eov7OTeByC2uR7ncOfHvcMHFw8x7wtBp7McR0KXiDnonoeHEeuLjRVVxYbg/uOmWoeOp6GezRL0Uhbgk86K71ydaRYu+kSjgTSe8JYuyBvnBHiXnuYvL8RPAn39uIQVdXkfZ3rVsDXqpe4oqAdMjf44yp2Or3BOpEP0VftDY3gDWsLr5D/lfxC4zR8/6CNHlOgP7lTRsJQS5s+9p4Wz3o3ovuXejW7bYfm8lQm9A3alu35pW+nuSE935wBG1NhO+GwL5KPslS59IKsO5b1n3vwdH6bFN2DDjbqkIRuPcfYN23Ni34FjkktwG/7V17//xvEt+7EPzRzk6iEHoMrPver/6WQT4/egt86TYh1QaP28Y88RFJ1gHYe7PFdPHrwHVgp7QQ0XPed2C785S4ytuA0/qnlRbiOXMj8Df+98mzJkvwr5mx6nFpNyFnfJFccdWqGfwgpVW99YYEfk8q7A+ow3x7gc3+BDYRs7C1iYAdAAANpHpUWHRNT0wgcmRraXQgMjAyNS4wOS4zAAB4nI1azXKcuQ28+ym+F9AUQQIEechhbW+2UqmVq+LNvkPuef9KNzgiRwqUjC3BEofDafw2wM9fLv75x/e//+vf1/5Tv3/5cl3lf3zNOa8/Wynly+8Xf7i+/vrb316vb3/88vVt5duPf77+8fMS90uG4l34+373L3/8+P1tRa5v14vchtYxx9VvTWep/Sq3En/OW+va2Mos3i+9TfVaZ7KxYWO5icuo3Odl9KbJPsU+uYkMHHjZbeANzZJ9Fud5sa7jagDQR/NkX79er3qT0c0E+7Ctak32Oc5rN2mttwp8tYlqS/aN6wfOszmHAMStt1a1JPsmztNbFzWo2W5z1gGg/70Pp3zDOdali+EHsV4sO1AEmuB1hT16QJBimSZCn/Rbr7PawMZmVS3znTTo4jdzKDGB0fDZlmKkU/wmvZVBaNNK7ylGemXcurY5aDyXWnrmZenYOBEOPopdL+XWx/SWauNxZG3Fq0ZMWp1p5MiInd7VtF8v7VZNvUm2k86RcoNdFE7BVp3wYxrfBTYSBCTCn0gRuYifmX1+ZdJwK+yOFHiB5VuRmm6tCwDM7Qhz6I/waDWL39rg9n6r0rmMnVWgV2apquF31zkABZZC8NGxyU6DUsitUl2FQN3d0iiu/VnrV3/W+nU8b/35tElZ4hD6t+5NEUjYah3FIy1F4SgghFLWCGCijkgGoNV1Kpwvjq3GCoGSlG1tSy33Wb0wUsY0qVkNgQFfn4v+9mxCtR65XFEN8ZEsyDJLqrxH5rF64CA41K32VPURG4sx4FEdqnvpqTb3bCoFhmftVEWyZDVbSxypsHYRBqBCmyxE9J5KVhrB6a2NNvMjK0yJnQWuxk4Efevd0zPbciUNo4666KjhnimkunIeNa74JBlYryNLTrUVSQoC1smi3KV6Fh3KRBLaxgttxjKinjlI6SAxVARHWmCnDhsjpcpIpE4XFtRysA1YemS+BDZYaYAK4HfaU6XozKxkUe9I+IKkQzmBq8bIrGTkI2hUkBAwOJLUpo70zLo0MtHuVGRWnJnhtLY+Xbu4GexZhpbU8qZL96JDZ2cO6ShT0o83AkXmFlEQFAujQrtUp/ASKBFFDn3PCxOOZJdtdUIdaCgQ9IX1Rqq0kp5KP7Fyq7A0Yaeiy0ibmolD2U5B/UrfC+yUtzUFSuHIWdtgFKGQj5YFXpf14R1lGR6noYAzTeQezRzgMUyUW9GseU9PbWtr71OFaVeRVWnf1+koFENBLqNuyk3Rb6QVvNs6Ew0Q+1kkqJiktu996YRiOPoMWkK/lnYknW6iH200ch1NWmZaQqHoKysnsh55ByBlRWGyMyoe6nsbeJ0EBnemvZiXaCubqyNgsNNLFc0cihT6wUJXw480Axyr2ad7jdZ3IpmQTTBtrx30ne2MdEK4uyJIQF7TWt7GOxkJZkKzKuDnF1bcIWkz6LZafuR6LXEqOuuWGt/78ujsVdCVYmtDeUzruIefYElkHsLkBX1MG5J2zE4/RddgLJCkb4FL061zBd9EFLfoSrrXlhb9QU/RRLVN9Jykb/jUM6xD1tY2S5lGrDzTM/+PSCkg1Ip2h1vRlufd+GhLrQG3stcZN9qqZH4dugDUPkHe3NrR66WOHSx+RIiCz/7R2WzJzIw1+jqVSWcRguhjkKzZ1vCWY32iMYqt+HzP4nqEtxRZ3QwbXthKw1ipXecCUNAMzRnVTWG3bLgKZ3WMLgMBfTFu0fBkHz/DV6zoyKcahRA7Uzqd4St0PAVsH20ZIsFGVtRmW1uRT2g3qJSh200JderaqiASNBbMBk5ZmQOmRfUv7LmKxLCBKbTlx/alF0pQv9c1dJspUU9fxpqTs2UUNkZAeup4tljPYCrWK8zpnDJRjj4Zywqp6imuAEOv2uK1tkb+h88we6Rb67OkKmXdPfx/rkSOrEMNvZdECKC0zdRZGL6DgVEvJ7MFZRZY0yGCJBZ8gcpv0YBwiE9nSOTGuodQhH5kC8bC2fJTR1wxKHJwzWbobNsndl23EbAp3wXQjuqe7pRFWFhcvsLMn9d2kejRYcxSY8hsOnMWErn3FWijBSwIEkRXlw67ElcSMbqOjnrE6w74Kp3hRVe9RDEpxi691NrTaiFxLYFgRT2D3jhV0Xx/on9fBbshVvACSsxABuQA/PoZBZs5UjF8TRB2OhpKXE2gsrkJdOe1EatQbqxILPAEwg5tinK2GGmzCvq91/aBvO4AgIlupC2w1HsZ9N7Rz2MrOlVNeyuJuwlQiqMNRLp0uKDUkiZWDW+BqBwE67zVa+zX063hLdQ2QWCjomHCQAyWNLLq6jCYJoiXCnNVQUeanxv+4lVKcYxBCC4Ya5TcCMFamLtrH3FpCHqvnxghWEuirjP+UL0wBnwCd97horUDIbLAKVRLXRa3FNyLfqXMOI7OS+E2ue/VBm4fay7oGHPTzesilhVTkIlMNxBSm2mWxVUFTx4oSDX6UuSF5BWp6d3CYLooNKAHmZ7yosR9xXNsh57xaRKVuLXAXtPCEslah6DMjx3Ly60Detyt8dBP3MG5GAGMRpJ9MUjEkRapZnF3gQxCNZO4YQHbjTyF4/YCeSmIGeUUVyYiMnWb1lWZEJD8hIpiglYxNUHcXzzFzaL67HQmak8zrvany3jcYTxXm+MS46lWDpy4uk5UA+dlXMHYByZLDWtRG5/pJTFkLsM+0aGK3fv5MjhzRUqqTU/tZfcZGRVkWAyUmAJZJ7O9K8lQwX1a9GgTg3/P8drTs5rEhcZTsyJdGk9K1MVjqPXqNc9cu0/K6FMRwHBeQY1MBzCx+fRQwQE+qA/FBWYI0zmf26R7ZY0VT0x2su41nhrtZF1sYEoqyg6JYTFBxamDQc8/WT3QVU3OVuB3lPK0sZZ1ufHUzCi9r966YFIjBrbu+Dnf68tmSERjEcWkgzngE93GnSOQiij87IMMhTq32SI1cCRmTLgAzRMw5MXZw2/Yi3CroKeOKmZzpjZzWd1F4yVL4QODAg5OIfh9HvOBgtuwdWrzvAvwu9eatYoqMTFEozalRvB7iz8VzYqHca0x+LO96yGjsW+2KP6TF3Pp1n5/YooyQ65GU4RYsrTmut8fmqJr47MS0BqiJo3zX1+/v3suu57Ufv3x+n2fFn/r26+Vv1zt7VcQFb6h8l9/+8te1Fi0femIX+3q7/eANfDt+yIFh/o19qSOV/2aexjErzOeZD4eIWUty+ltiRVfGy0mg0oh501EzBU9ZZ8rGs8W3x1P3BT9BC1VA3I/puYKn3jvlcEV4N/ghegh6jZ6DRNhZSMHIytFPXauC1XdeNgUUNSNHORcQ2xTV2LmysZcaWi2Hh7anU90rsPsG3klcoi6kYPRlaJt5OFc/rvPaUQO0TZyPt6maCdI2sLQNvIWIYJtGzl7A4q2kTci58q2diNmCD45evRUY7hAtI280eYQupFrua9s5CrrNN3IlTaH0BPJMDeFbuRK5FzZyJU2h9APEa7ED6EbvxI/hG6bK5FD6EbOpzxcsXNnX9b5tpEbkUPYRm6Mcwjbn260OVc2ciNyCPsQ52b39W15I3II28jNI4dtA+eDfwrbwI0mx0p/fIQgFH0D7wQOQcJ8VwxoeIh+Vggfom/4fJgYK9vw3e6nbeAgqErRN/BO4FzZyDtNDtE38k7kEF7ep4gTv/PmfK/Ifec2vNPwEL6RO5FzZSN3Ikepd/1wvt3XN34nfgg/dZH4ubLxe9RGjNgbvxM/xPiAfxD/4HXyXmGyQoyNfzBZIcbGP1jOIcbGP5Qr+NqWH3b/xI18EDnE2MgHkXPlFHUihxgb+SByiPkB+YzKzsvVvULkEHMjn0QOMTfySeQQcyOftDzE3MjRGmmsbOSTRR1ibuTT76g28sloh5iHkYKSBi8fDx0FWZa4ZjyLwUmUpX6kryjxlOVhkUpQSjkMVTQW+W1n0WLReP13FoOiIDFinMVgKY615fBUCaIqVOFQVZmxSFJ9d2WnIeWRardeD2y76Jbs+kC4i3Fj8Wi0SJdSjkaLcSnlQy3lgiz5QL4k3vv+o5eMwDB403UWg4O5eFiY11sSN1f86f3HVdkvPfQSq5ng98PO1U9w8WhXQzuScdWPJ9t+6XiN/BxS6tEuGHotHu3qiEUqcrSroR1l+6hICx3jp+O74GxKOawtQduU0h7eHtFI/j7czQsbDSmHvnkxEwu8djmLfQM7ejX2epTSjl5B4Wvx6BUsHvLwuASRh+Q1yGPVkGD0kIfTeQOiIeXQOu86NKToQx8YepHgD7nz/iIWeD1xFiPLSPCH3CXYfQE7emlEI2n+UDzvGWQt2sMgG3pZ3BecxdCI0uoHZS2qB6U9tKwRjZSH9yWIP6QdvWx1t8YR/ixGHJL+D/VLcP9aPHrZ2MCOXjbj7ZOT9l7sSy8uHvDRCITsx1PRBYTkkPwujKMdCHkaAomOYO0/enX2kZTSH/r2iMNYPHp1f8vE0xxIdAchOaC+M3i0CfGSvxtN74XidAkSbULI0yhw2nxbPHqtZsE4NZ61UIvS7QOE6BjWS0c5D+Uo/WEuYclnVXrYx4KPVH6oJvzPRyTz0yHIYLEHA86HpSgXLPgPPDVWuejvCstYaeXvEjDah/X2DYZj5+OQyd/f/jMxfv7yHw1oRah78xGVAAAGYnpUWHRTTUlMRVMgcmRraXQgMjAyNS4wOS4zAAB4nKWXO68cRw6F/8qGGqBvo1gPsmhhgQXGgSMpWGxkOLq5Uyf+8f4OeyxYUi/WwAbCaM5Usfg4POR9Pn9+/uunXz48H9fnp+eHf35+/Il99e3d3t/fP3x+vL/bzQ/foU/uf2MB7NODr1/AevHx/Pwo4NMLeV39GvvLGX396jcc+PnXn355/9Ue3/3wxeX7K/1yvX/z87/vX7t7+Qr9b8HPpyL/9Ph0/9qXlDwfilY5+AI8n//4/cObnXv2PPwcM9s4PgKMlm0f88wZHaSdFra7g0TbDmKn2U471rn5ZepItOVzH4PLLqSftn0tAL53gHHaGFyeZx8268TK3DLiY+jEPN3mGlzJ7HsdH9e53FwnbHkrwOYefuiqCfDTe3YBY/Xpx8c4V/iY2FjcKcB8EE07czUB+/Q5UkBYb867SXyxj7d2+s4YXWf6aNEPJWf1HELCJ+G8jbOvGcpBO/tcU8jMMYSQloYzb+SpK6eFZOcW/o1mvW752qHHiHH0UAzdXEA3THcBMXPX6ySEYIh7tx5TdiKCR/8PD7/xp58eoywv3yGE+43r3EqKep3p3nhrqYRxRRHBo0S6c8nOXQ6/zXNgZhKXCGawh0sqowPsWEpFnm2ROqrXI/hBD7U2RZo5lVpOTJwS8WavA3auNnRg7JEXoLyQuuEe5TyPQZCAbFG/uzcTDZdXjZSd1AnI1jeAHgt8wJOp74tSRQLMvbYAl79YcDpGFjbsWyknrc2sA2OSFSecti+TOLnxyla+bC7jEbGAE153ptvGjbZnu4w0HlRK525pVres2SxizFkIfO85dShMBC9vmlMAKmrd1NCiATzq2OZDlVCPGyknJuP1amD6aOxUuaZtfNU9X9MplFzAlDpfVitYMDQhfBfmnlNJ73ZpyCTQNoRM+rHXGdKrMtiS47pO5J7FYBTBC4u1yZy4Z8SsaM7hDZPcb25RyM6xi+fTcUXKMmLyE0i0bktKMrp0Sa8S1FJ8OT3UQpStO+X7qCTSaKJ1rtGuTC0VbuvU2LucIoRNInVsLZJQsaR3K2hYl1Nyhi4k6zTv2PKhum7l1UjWMiotGVJHIEdaBYlcI3u1EtFc0MgGBbDFmTqFidlpjLcSvHm9uAkI8/t8+bDoLyIR4hIOIGlL41pIAXqdWSYZJIZOI6l6QYvlhdhUA+DKIrNbpbEWLzeJYB6iycSTMr1ij0Mpo52jDK1OuksEgDQF3ujo5r2wkbYgmDC8xCrmF0p1QRP6VsFy+RKk1icdqgSxZNmn8F7Z47DtciKxWs63YblvqSc2aKB1cSDHLWGNbu/oCMK4e7/vmvseQbhwQQHCjlS30y3W88ofs0/ZgrRWFLWaYFnjcOZcRf+hFoa09L2XpKNYkmscH+oWDAZsrFsNPZTjTLVR3RAIowrD+K7JoDpqbErAUJIrOJSFVtP4xO8iD2Vtmuit91eS4APeL4g8NYU4M4gWEWNe+QXsyih12DkvNsWy0CVXxasgntKzKVHdF8Isp/WhGepvVcdwX0LouimE2YWqaAkxoinAIiO0cYxdR6CDKV9IayjJb5plkzBhvRhQJ7yFVpBtVRtmUvetFWShdXbdgXFigpdWCkAxxIP5p9H0rYw3nG72usQQHkeJZiXCxBIrUYK+8zqzZ5QoUSh78ZcJVNsAwH9j+W0vrKmXRYNWbieWyE/pMGSrmm5mp0QLdsaVRDYddErcyDFfqTfi1DhtudtVZeSHCdIp5VXCO6X+383xPce+Z9SdQFCqqOWHlTC23wrLjfoQAPtnZWnMVVKKslOyWmUQ/4hys3lkQcma6veCfjMJ1OGBhwqiRy0FUHNF6W3bw+JeOVEfgtg1ZviP/22FR46bNiHFml6ypR3CahgFvNv3Y4DkJhPnKN1reSk8m6F0EvV9iaJ2ut61JLH9XVykBTxVHIQwXwhdM2inzTTPy4GmTWqf19YH64LBJyDnuAbFWAO7yeQpcVcq6c8of9a4srukWUv+sOMpu1K41EalrrarLjXWnVOQ3VSWx/Hbjz+QWQkHL7Iq6e+FY9Du/CUCSKMTBP1Pl8PNhhzAbGOzYo84+Mfn4lPfk0/eYq3lrwd6II/f/vND13g8XOEdga6sI3inHZv4aLaBWvAIzUBieN7xnzM0F6uI/f4HD9gLQDZaPKMAAAAASUVORK5CYII=\" alt=\"Mol\"/></div></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SGTSLPNITLLDTFCTRCFV</td>\n",
              "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "      <td style=\"text-align: center;\"><div style=\"width: 200px; height: 200px\" data-content=\"rdkit/molecule\"><img src=\"data:image/png;base64,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\" alt=\"Mol\"/></div></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MYEGGSTLW</td>\n",
              "      <td>CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK2</td>\n",
              "      <td></td>\n",
              "      <td style=\"text-align: center;\"><div style=\"width: 200px; height: 200px\" data-content=\"rdkit/molecule\"><img src=\"data:image/png;base64,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\" alt=\"Mol\"/></div></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DGRFFFV</td>\n",
              "      <td>CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...</td>\n",
              "      <td>0</td>\n",
              "      <td>NNK1</td>\n",
              "      <td></td>\n",
              "      <td style=\"text-align: center;\"><div style=\"width: 200px; height: 200px\" data-content=\"rdkit/molecule\"><img src=\"data:image/png;base64,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\" alt=\"Mol\"/></div></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6a0dcf5-bf1b-47b3-bf28-ea01c6c2b4c0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6a0dcf5-bf1b-47b3-bf28-ea01c6c2b4c0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6a0dcf5-bf1b-47b3-bf28-ea01c6c2b4c0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_small",
              "summary": "{\n  \"name\": \"df_small\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"aa_seq\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"VMFMIAGNC\",\n          \"VEDKCVWFV\",\n          \"WFIRIAIMARSFCIIALVPR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SMILES\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"CC[C@H](C)[C@H](NC(=O)[C@H](CCSC)NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](CCSC)NC(=O)[C@@H](N)C(C)C)C(=O)N[C@@H](C)C(=O)NCC(=O)N[C@@H](CC(N)=O)C(=O)N[C@@H](CS)C(=O)O\",\n          \"CC(C)[C@H](N)C(=O)N[C@@H](CCC(=O)O)C(=O)N[C@@H](CC(=O)O)C(=O)N[C@@H](CCCCN)C(=O)N[C@@H](CS)C(=O)N[C@H](C(=O)N[C@@H](Cc1c[nH]c2ccccc12)C(=O)N[C@@H](Cc1ccccc1)C(=O)N[C@H](C(=O)O)C(C)C)C(C)C\",\n          \"CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@@H](NC(=O)[C@H](CCCNC(=N)N)NC(=O)[C@@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@@H](N)Cc1c[nH]c2ccccc12)[C@@H](C)CC)[C@@H](C)CC)C(=O)N[C@@H](CCSC)C(=O)N[C@@H](C)C(=O)N[C@@H](CCCNC(=N)N)C(=O)N[C@@H](CO)C(=O)N[C@@H](Cc1ccccc1)C(=O)N[C@@H](CS)C(=O)N[C@H](C(=O)N[C@H](C(=O)N[C@@H](C)C(=O)N[C@@H](CC(C)C)C(=O)N[C@H](C(=O)N1CCC[C@H]1C(=O)N[C@@H](CCCNC(=N)N)C(=O)O)C(C)C)[C@@H](C)CC)[C@@H](C)CC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seed_bh\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dataset\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"NNK3\",\n          \"NNK1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_test\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mol\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"<rdkit.Chem.rdchem.Mol object at 0x7e7058ce8350>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Morgan fingerprint"
      ],
      "metadata": {
        "id": "Z3MRP_YuNvWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
        "\n",
        "path_smiles = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "out_path = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles_morganFP.xlsx\"\n",
        "\n",
        "df = pd.read_excel(path_smiles)\n",
        "\n",
        "morgan_gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
        "\n",
        "def smiles_to_bitstring(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return \"\"\n",
        "    fp = morgan_gen.GetFingerprint(mol)\n",
        "    return fp.ToBitString()\n",
        "\n",
        "df[\"Morgan_fp\"] = df[\"SMILES\"].apply(smiles_to_bitstring)\n",
        "\n",
        "cols = list(df.columns)\n",
        "cols.remove(\"Morgan_fp\")\n",
        "smiles_idx = cols.index(\"SMILES\")\n",
        "cols = cols[:smiles_idx + 1] + [\"Morgan_fp\"] + cols[smiles_idx + 1:]\n",
        "df = df[cols]\n",
        "\n",
        "df.to_excel(out_path, index=False)\n",
        "out_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IGY8liJiUZkz",
        "outputId": "1d5d0dfb-2d50-49a3-902f-644dfdce74a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles_morganFP.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWTAOMN5Ueu3",
        "outputId": "391f6d91-30b7-4d31-e9cf-0a6f057519cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    aa_seq                                             SMILES  \\\n",
            "0             GYVCMKLDRYLS  CSCC[C@H](NC(=O)[C@H](CS)NC(=O)[C@@H](NC(=O)[C...   \n",
            "1     SQLFYAILSIHYWCVTFFRC  CC[C@H](C)[C@H](NC(=O)[C@H](C)NC(=O)[C@H](Cc1c...   \n",
            "2     SGTSLPNITLLDTFCTRCFV  CC[C@H](C)[C@H](NC(=O)[C@H](CC(N)=O)NC(=O)[C@@...   \n",
            "3                MYEGGSTLW  CSCC[C@H](N)C(=O)N[C@@H](Cc1ccc(O)cc1)C(=O)N[C...   \n",
            "4                  DGRFFFV  CC(C)[C@H](NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](C...   \n",
            "...                    ...                                                ...   \n",
            "4995  TLVLSLAHPCASGNKPDKSG  CC(C)C[C@H](NC(=O)[C@H](CO)NC(=O)[C@H](CC(C)C)...   \n",
            "4996                 HQGFE  NC(=O)CC[C@H](NC(=O)[C@@H](N)Cc1c[nH]cn1)C(=O)...   \n",
            "4997  GFLNLCRSTSRELMCEMYSA  CSCC[C@H](NC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](CS)...   \n",
            "4998  TRKMLLVVSKYVMTPYGFGL  CSCC[C@H](NC(=O)[C@H](CCCCN)NC(=O)[C@H](CCCNC(...   \n",
            "4999              CPPSYLMT  CSCC[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H](Cc1cc...   \n",
            "\n",
            "                                              Morgan_fp  seed_bh dataset  \\\n",
            "0     0100000000010000000000000001000000000000010000...        0    NNK3   \n",
            "1     0100000000000000000000000000000000000000000000...        0    NNK1   \n",
            "2     0100000000000000000000000000000000000000010000...        0    NNK1   \n",
            "3     0100000000010000000000000000000000000000010000...        0    NNK2   \n",
            "4     0100000000000000000000000000000000000000010000...        0    NNK1   \n",
            "...                                                 ...      ...     ...   \n",
            "4995  0100000000000000000000000000000000000000010000...        1    NNK1   \n",
            "4996  0100000000000000000000000000000000000000010000...        0    NNK3   \n",
            "4997  0100000000010000000000000001000000000000010000...        0    NNK2   \n",
            "4998  0100000000010000000000000000000000001000010000...        0    NNK3   \n",
            "4999  0100000000010000000000000000000000000000000000...        0    NNK1   \n",
            "\n",
            "      train_test  \n",
            "0            NaN  \n",
            "1            NaN  \n",
            "2            NaN  \n",
            "3            NaN  \n",
            "4            NaN  \n",
            "...          ...  \n",
            "4995         NaN  \n",
            "4996         NaN  \n",
            "4997         NaN  \n",
            "4998         NaN  \n",
            "4999         NaN  \n",
            "\n",
            "[5000 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.PCA（check sampling）"
      ],
      "metadata": {
        "id": "chgKyCojDwGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 抽样代表性检查\n",
        "sampled_df[\"aa_seq\"].astype(str).str.len().value_counts().sort_index() # check the number of 1 aa sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "collapsed": true,
        "id": "opZBUxF5Dzvq",
        "outputId": "7f0fba57-e29f-4d8e-b85b-9a49fb815cb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "aa_seq\n",
              "1        3\n",
              "2       40\n",
              "3      152\n",
              "4      173\n",
              "5      163\n",
              "6      161\n",
              "7      156\n",
              "8      148\n",
              "9      147\n",
              "10     144\n",
              "11     136\n",
              "12     127\n",
              "13     124\n",
              "14     112\n",
              "15     119\n",
              "16     104\n",
              "17     111\n",
              "18     101\n",
              "19     104\n",
              "20    2675\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aa_seq</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2675</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import ks_2samp\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "# === paths ===\n",
        "path = \"/content/drive/MyDrive/master_thesis/NNK_data_visualization/canya-data-source.xlsx\"\n",
        "out_dir_2 = \"/content/drive/MyDrive/master_thesis/sampled_data_5000\"\n",
        "out_path = os.path.join(out_dir_2, \"canya_data_sampled_5000.xlsx\")\n",
        "out_dir_pca = os.path.join(out_dir_2, \"out_dir_pca\")\n",
        "os.makedirs(out_dir_pca, exist_ok=True)\n",
        "\n",
        "AA_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "AA_INDEX = {aa: i for i, aa in enumerate(AA_ALPHABET)}\n",
        "FEAT_DIM = len(AA_ALPHABET) ** 2\n",
        "\n",
        "def load_data(file_path):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(file_path)\n",
        "    if ext in [\".csv\", \".tsv\", \".txt\"]:\n",
        "        sep = \"\\t\" if ext == \".tsv\" else \",\"\n",
        "        return pd.read_csv(file_path, sep=sep)\n",
        "    raise ValueError(f\"Unsupported file type: {ext}\")\n",
        "\n",
        "def featurize_dipeptide(seqs):\n",
        "    n = len(seqs)\n",
        "    X = np.zeros((n, FEAT_DIM), dtype=np.float32)\n",
        "\n",
        "    for i, seq in enumerate(seqs):\n",
        "        if not isinstance(seq, str):\n",
        "            continue\n",
        "        s = seq.strip().upper()\n",
        "        if len(s) < 2:\n",
        "            continue\n",
        "        counts = np.zeros(FEAT_DIM, dtype=np.float32)\n",
        "        valid = 0\n",
        "        for j in range(len(s) - 1):\n",
        "            a1, a2 = s[j], s[j + 1]\n",
        "            if a1 in AA_INDEX and a2 in AA_INDEX:\n",
        "                idx = AA_INDEX[a1] * len(AA_ALPHABET) + AA_INDEX[a2]\n",
        "                counts[idx] += 1\n",
        "                valid += 1\n",
        "        if valid > 0:\n",
        "            X[i, :] = counts / valid\n",
        "    return X\n",
        "\n",
        "def run_pca(X_df, X_samp):\n",
        "    pca = PCA(n_components=2, random_state=0)\n",
        "    X_df_pca = pca.fit_transform(X_df)\n",
        "    X_samp_pca = pca.transform(X_samp)\n",
        "    return pca, X_df_pca, X_samp_pca\n",
        "\n",
        "\n",
        "def plot_overlay(X_bg, X_samp, labels=None, out_file=\"pca.png\", title=\"\", show=False):\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "    hb = ax.hexbin(X_bg[:, 0], X_bg[:, 1], gridsize=60, mincnt=1, cmap=\"viridis\")\n",
        "    cb = fig.colorbar(hb, ax=ax)\n",
        "    cb.set_label(\"Density\")\n",
        "\n",
        "    green = \"#009E73\"\n",
        "    # 代理图例：背景（用 hexbin colormap 的低值色）\n",
        "    bg_proxy = Patch(facecolor=hb.cmap(hb.norm(0.0)), edgecolor=\"none\", label=\"Background (hexbin)\")\n",
        "\n",
        "    if labels is None:\n",
        "        samp = ax.scatter(\n",
        "            X_samp[:, 0], X_samp[:, 1],\n",
        "            s=10, alpha=0.9, edgecolors=\"black\", linewidths=0.3, c=green, label=\"Sampled (n=5000)\"\n",
        "        )\n",
        "        ax.legend(handles=[bg_proxy, samp], frameon=False, loc=\"best\")\n",
        "    else:\n",
        "        colors = {0: \"tab:blue\", 1: \"tab:red\"}\n",
        "        handles = [bg_proxy]\n",
        "        for lab in [0, 1]:\n",
        "            mask = labels == lab\n",
        "            h = ax.scatter(\n",
        "                X_samp[mask, 0], X_samp[mask, 1],\n",
        "                s=10, alpha=0.9, edgecolors=\"black\", linewidths=0.3,\n",
        "                c=colors.get(lab, \"gray\"), label=f\"seed_bh={lab}\"\n",
        "            )\n",
        "            handles.append(h)\n",
        "        ax.legend(handles=handles, frameon=False, loc=\"best\")\n",
        "\n",
        "    ax.set_xlabel(\"PC1\")\n",
        "    ax.set_ylabel(\"PC2\")\n",
        "    ax.set_title(title)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_file, dpi=200)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    plt.close(fig)\n",
        "\n",
        "def stats_checks(df, sampled_df, X_df_pca, X_samp_pca):\n",
        "    ks_pc1 = ks_2samp(X_df_pca[:, 0], X_samp_pca[:, 0])\n",
        "    ks_pc2 = ks_2samp(X_df_pca[:, 1], X_samp_pca[:, 1])\n",
        "\n",
        "    def coverage(pc_all, pc_sub, low=0.01, high=0.99):\n",
        "        q_low, q_high = np.quantile(pc_all, [low, high])\n",
        "        within = np.mean((pc_sub >= q_low) & (pc_sub <= q_high))\n",
        "        return within, (q_low, q_high)\n",
        "\n",
        "    cov_pc1, q_pc1 = coverage(X_df_pca[:, 0], X_samp_pca[:, 0])\n",
        "    cov_pc2, q_pc2 = coverage(X_df_pca[:, 1], X_samp_pca[:, 1])\n",
        "\n",
        "    df_len = df[\"aa_seq\"].astype(str).str.len()\n",
        "    samp_len = sampled_df[\"aa_seq\"].astype(str).str.len()\n",
        "\n",
        "    length_table = pd.concat(\n",
        "        [\n",
        "            df_len.value_counts(normalize=True).sort_index().rename(\"df\"),\n",
        "            samp_len.value_counts(normalize=True).sort_index().rename(\"sampled_df\"),\n",
        "        ],\n",
        "        axis=1,\n",
        "    ).fillna(0)\n",
        "\n",
        "    seed_table = pd.concat(\n",
        "        [\n",
        "            df[\"seed_bh\"].value_counts(normalize=True).rename(\"df\"),\n",
        "            sampled_df[\"seed_bh\"].value_counts(normalize=True).rename(\"sampled_df\"),\n",
        "        ],\n",
        "        axis=1,\n",
        "    ).fillna(0)\n",
        "\n",
        "    dataset_table = pd.concat(\n",
        "        [\n",
        "            df[\"dataset\"].value_counts(normalize=True).rename(\"df\"),\n",
        "            sampled_df[\"dataset\"].value_counts(normalize=True).rename(\"sampled_df\"),\n",
        "        ],\n",
        "        axis=1,\n",
        "    ).fillna(0)\n",
        "\n",
        "    return {\n",
        "        \"ks_pc1\": ks_pc1,\n",
        "        \"ks_pc2\": ks_pc2,\n",
        "        \"coverage_pc1\": (cov_pc1, q_pc1),\n",
        "        \"coverage_pc2\": (cov_pc2, q_pc2),\n",
        "        \"length_table\": length_table,\n",
        "        \"seed_table\": seed_table,\n",
        "        \"dataset_table\": dataset_table,\n",
        "    }\n",
        "\n",
        "# === load ===\n",
        "df = load_data(path)\n",
        "sampled_df = load_data(out_path)\n",
        "\n",
        "required_cols = {\"aa_seq\", \"seed_bh\", \"dataset\", \"train_test\"}\n",
        "missing_df = required_cols - set(df.columns)\n",
        "missing_sampled = required_cols - set(sampled_df.columns)\n",
        "if missing_df:\n",
        "    raise ValueError(f\"df missing columns: {missing_df}\")\n",
        "if missing_sampled:\n",
        "    raise ValueError(f\"sampled_df missing columns: {missing_sampled}\")\n",
        "\n",
        "# === featurize ===\n",
        "X_df = featurize_dipeptide(df[\"aa_seq\"].astype(str).tolist())\n",
        "X_samp = featurize_dipeptide(sampled_df[\"aa_seq\"].astype(str).tolist())\n",
        "\n",
        "# === PCA ===\n",
        "pca, X_df_pca, X_samp_pca = run_pca(X_df, X_samp)\n",
        "evr = pca.explained_variance_ratio_\n",
        "\n",
        "# === background subsample for hexbin ===\n",
        "max_bg_points = 200000 # 最大背景点，20万，没有用下采样，包括了全部10万+数据作为背景点\n",
        "if len(X_df_pca) > max_bg_points:\n",
        "    rng = np.random.default_rng(0)\n",
        "    idx = rng.choice(len(X_df_pca), size=max_bg_points, replace=False)\n",
        "    X_bg = X_df_pca[idx]\n",
        "else:\n",
        "    X_bg = X_df_pca\n",
        "\n",
        "# === plots ===\n",
        "plot_overlay(\n",
        "    X_bg, X_samp_pca,\n",
        "    labels=None,\n",
        "    out_file=os.path.join(out_dir_pca, \"pca_hexbin_overlay.png\"),\n",
        "    title=\"PCA overlay: sampled on full data (hexbin background)\",\n",
        "    show=True\n",
        ")\n",
        "\n",
        "labels = pd.to_numeric(sampled_df[\"seed_bh\"], errors=\"coerce\").fillna(-1).astype(int).to_numpy()\n",
        "plot_overlay(\n",
        "    X_bg, X_samp_pca,\n",
        "    labels=labels,\n",
        "    out_file=os.path.join(out_dir_pca, \"pca_hexbin_overlay_by_label.png\"),\n",
        "    title=\"PCA overlay by seed_bh\",\n",
        "    show=True\n",
        ")\n",
        "\n",
        "# === stats ===\n",
        "stats = stats_checks(df, sampled_df, X_df_pca, X_samp_pca)\n",
        "\n",
        "print(\"Sample sizes:\")\n",
        "print(f\"  df: {len(df)}\")\n",
        "print(f\"  sampled_df: {len(sampled_df)}\\n\")\n",
        "\n",
        "print(\"Explained variance ratio:\")\n",
        "print(f\"  PC1: {evr[0]:.4f}\")\n",
        "print(f\"  PC2: {evr[1]:.4f}\\n\")\n",
        "\n",
        "print(\"KS tests:\")\n",
        "print(f\"  PC1: statistic={stats['ks_pc1'].statistic:.4f}, pvalue={stats['ks_pc1'].pvalue:.4g}\")\n",
        "print(f\"  PC2: statistic={stats['ks_pc2'].statistic:.4f}, pvalue={stats['ks_pc2'].pvalue:.4g}\\n\")\n",
        "\n",
        "cov1, q1 = stats[\"coverage_pc1\"]\n",
        "cov2, q2 = stats[\"coverage_pc2\"]\n",
        "print(\"Coverage of df 1%-99% interval by sampled_df:\")\n",
        "print(f\"  PC1: {cov1:.4f} (interval {q1[0]:.4f} to {q1[1]:.4f})\")\n",
        "print(f\"  PC2: {cov2:.4f} (interval {q2[0]:.4f} to {q2[1]:.4f})\\n\")\n",
        "\n",
        "print(\"Distribution comparison (proportions):\")\n",
        "print(\"\\nLength distribution:\")\n",
        "print(stats[\"length_table\"])\n",
        "print(\"\\nseed_bh distribution:\")\n",
        "print(stats[\"seed_table\"])\n",
        "print(\"\\ndataset distribution:\")\n",
        "print(stats[\"dataset_table\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S8ey-rXQN9pw",
        "outputId": "dd2b0801-21f9-4a45-f357-085ba2873e4b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample sizes:\n",
            "  df: 111692\n",
            "  sampled_df: 5000\n",
            "\n",
            "Explained variance ratio:\n",
            "  PC1: 0.0112\n",
            "  PC2: 0.0107\n",
            "\n",
            "KS tests:\n",
            "  PC1: statistic=0.0119, pvalue=0.5034\n",
            "  PC2: statistic=0.0126, pvalue=0.4331\n",
            "\n",
            "Coverage of df 1%-99% interval by sampled_df:\n",
            "  PC1: 0.9790 (interval -0.0484 to 0.1226)\n",
            "  PC2: 0.9780 (interval -0.0443 to 0.1222)\n",
            "\n",
            "Distribution comparison (proportions):\n",
            "\n",
            "Length distribution:\n",
            "              df  sampled_df\n",
            "aa_seq                      \n",
            "1       0.000528      0.0006\n",
            "2       0.008219      0.0080\n",
            "3       0.030324      0.0304\n",
            "4       0.034658      0.0346\n",
            "5       0.032464      0.0326\n",
            "6       0.032366      0.0322\n",
            "7       0.031148      0.0312\n",
            "8       0.029492      0.0296\n",
            "9       0.029268      0.0294\n",
            "10      0.028811      0.0288\n",
            "11      0.027066      0.0272\n",
            "12      0.025463      0.0254\n",
            "13      0.024800      0.0248\n",
            "14      0.022580      0.0224\n",
            "15      0.023833      0.0238\n",
            "16      0.020664      0.0208\n",
            "17      0.022213      0.0222\n",
            "18      0.020297      0.0202\n",
            "19      0.020798      0.0208\n",
            "20      0.535007      0.5350\n",
            "\n",
            "seed_bh distribution:\n",
            "               df  sampled_df\n",
            "seed_bh                      \n",
            "0        0.793208      0.7934\n",
            "1        0.206792      0.2066\n",
            "\n",
            "dataset distribution:\n",
            "               df  sampled_df\n",
            "dataset                      \n",
            "NNK3     0.347509      0.3470\n",
            "NNK2     0.335718      0.3358\n",
            "NNK1     0.316773      0.3172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.构建GNN"
      ],
      "metadata": {
        "id": "9xqiZAXW0Ziu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1000数据，预训练"
      ],
      "metadata": {
        "id": "UyQTV62U0fhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.utils_gnn.py"
      ],
      "metadata": {
        "id": "bKy8f8cBN6yM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "!{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "AA_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "ATOM_CHIRALITY = [\n",
        "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
        "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
        "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
        "    Chem.rdchem.ChiralType.CHI_OTHER,\n",
        "]\n",
        "HBOND_TYPES = [\n",
        "    Chem.rdchem.HybridizationType.SP,\n",
        "    Chem.rdchem.HybridizationType.SP2,\n",
        "    Chem.rdchem.HybridizationType.SP3,\n",
        "    Chem.rdchem.HybridizationType.SP3D,\n",
        "    Chem.rdchem.HybridizationType.SP3D2,\n",
        "    Chem.rdchem.HybridizationType.OTHER,\n",
        "]\n",
        "BOND_TYPES = [\n",
        "    Chem.rdchem.BondType.SINGLE,\n",
        "    Chem.rdchem.BondType.DOUBLE,\n",
        "    Chem.rdchem.BondType.TRIPLE,\n",
        "    Chem.rdchem.BondType.AROMATIC,\n",
        "]\n",
        "BOND_STEREO = [\n",
        "    Chem.rdchem.BondStereo.STEREONONE,\n",
        "    Chem.rdchem.BondStereo.STEREOZ,\n",
        "    Chem.rdchem.BondStereo.STEREOE,\n",
        "    Chem.rdchem.BondStereo.STEREOCIS,\n",
        "    Chem.rdchem.BondStereo.STEREOTRANS,\n",
        "    Chem.rdchem.BondStereo.STEREOANY,\n",
        "]\n",
        "\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def check_columns(df):\n",
        "    required = {\"aa_seq\", \"SMILES\", \"seed_bh\", \"dataset\", \"train_test\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "\n",
        "def smiles_to_mol(smiles):\n",
        "    if not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return None\n",
        "    return Chem.MolFromSmiles(smiles)\n",
        "\n",
        "\n",
        "def one_hot(val, choices):\n",
        "    return [1 if val == c else 0 for c in choices]\n",
        "\n",
        "\n",
        "def atom_features(atom):\n",
        "    feats = []\n",
        "    feats.append(atom.GetAtomicNum())\n",
        "    feats.append(atom.GetDegree())\n",
        "    feats.append(atom.GetFormalCharge())\n",
        "    feats.append(atom.GetTotalNumHs())\n",
        "    feats.append(1 if atom.GetIsAromatic() else 0)\n",
        "    feats.append(1 if atom.IsInRing() else 0)\n",
        "    feats += one_hot(atom.GetChiralTag(), ATOM_CHIRALITY)\n",
        "    feats += one_hot(atom.GetHybridization(), HBOND_TYPES)\n",
        "    return feats\n",
        "\n",
        "\n",
        "def bond_features(bond):\n",
        "    feats = []\n",
        "    feats += one_hot(bond.GetBondType(), BOND_TYPES)\n",
        "    feats.append(1 if bond.GetIsConjugated() else 0)\n",
        "    feats.append(1 if bond.IsInRing() else 0)\n",
        "    feats += one_hot(bond.GetStereo(), BOND_STEREO)\n",
        "    return feats\n",
        "\n",
        "\n",
        "def mol_to_pyg(mol, label):\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "    x = torch.tensor([atom_features(mol.GetAtomWithIdx(i)) for i in range(num_atoms)], dtype=torch.float)\n",
        "\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        bf = bond_features(bond)\n",
        "        edge_index.append([i, j])\n",
        "        edge_attr.append(bf)\n",
        "        edge_index.append([j, i])\n",
        "        edge_attr.append(bf)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2i_u-YEN1sx",
        "outputId": "0086bd2b-403d-45f0-e51f-85338f132019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_scatter-2.1.2%2Bpt23cpu-cp312-cp312-linux_x86_64.whl (513 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m513.6/513.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcpu/torch_sparse-0.6.18%2Bpt23cpu-cp312-cp312-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2+pt23cpu torch-sparse-0.6.18+pt23cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cpu.so\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cpu.so\n",
            "  import torch_geometric.typing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 写入py文件"
      ],
      "metadata": {
        "id": "9xIfbOHBVLwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 写入py文件\n",
        "\n",
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "AA_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "ATOM_CHIRALITY = [\n",
        "    Chem.rdchem.ChiralType.CHI_UNSPECIFIED,\n",
        "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CW,\n",
        "    Chem.rdchem.ChiralType.CHI_TETRAHEDRAL_CCW,\n",
        "    Chem.rdchem.ChiralType.CHI_OTHER,\n",
        "]\n",
        "HBOND_TYPES = [\n",
        "    Chem.rdchem.HybridizationType.SP,\n",
        "    Chem.rdchem.HybridizationType.SP2,\n",
        "    Chem.rdchem.HybridizationType.SP3,\n",
        "    Chem.rdchem.HybridizationType.SP3D,\n",
        "    Chem.rdchem.HybridizationType.SP3D2,\n",
        "    Chem.rdchem.HybridizationType.OTHER,\n",
        "]\n",
        "BOND_TYPES = [\n",
        "    Chem.rdchem.BondType.SINGLE,\n",
        "    Chem.rdchem.BondType.DOUBLE,\n",
        "    Chem.rdchem.BondType.TRIPLE,\n",
        "    Chem.rdchem.BondType.AROMATIC,\n",
        "]\n",
        "BOND_STEREO = [\n",
        "    Chem.rdchem.BondStereo.STEREONONE,\n",
        "    Chem.rdchem.BondStereo.STEREOZ,\n",
        "    Chem.rdchem.BondStereo.STEREOE,\n",
        "    Chem.rdchem.BondStereo.STEREOCIS,\n",
        "    Chem.rdchem.BondStereo.STEREOTRANS,\n",
        "    Chem.rdchem.BondStereo.STEREOANY,\n",
        "]\n",
        "\n",
        "def seed_all(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def check_columns(df):\n",
        "    required = {\"aa_seq\", \"SMILES\", \"seed_bh\", \"dataset\", \"train_test\"}\n",
        "    missing = required - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns: {missing}\")\n",
        "\n",
        "def smiles_to_mol(smiles):\n",
        "    if not isinstance(smiles, str) or smiles.strip() == \"\":\n",
        "        return None\n",
        "    return Chem.MolFromSmiles(smiles)\n",
        "\n",
        "def one_hot(val, choices):\n",
        "    return [1 if val == c else 0 for c in choices]\n",
        "\n",
        "def atom_features(atom):\n",
        "    feats = []\n",
        "    feats.append(atom.GetAtomicNum())\n",
        "    feats.append(atom.GetDegree())\n",
        "    feats.append(atom.GetFormalCharge())\n",
        "    feats.append(atom.GetTotalNumHs())\n",
        "    feats.append(1 if atom.GetIsAromatic() else 0)\n",
        "    feats.append(1 if atom.IsInRing() else 0)\n",
        "    feats += one_hot(atom.GetChiralTag(), ATOM_CHIRALITY)\n",
        "    feats += one_hot(atom.GetHybridization(), HBOND_TYPES)\n",
        "    return feats\n",
        "\n",
        "def bond_features(bond):\n",
        "    feats = []\n",
        "    feats += one_hot(bond.GetBondType(), BOND_TYPES)\n",
        "    feats.append(1 if bond.GetIsConjugated() else 0)\n",
        "    feats.append(1 if bond.IsInRing() else 0)\n",
        "    feats += one_hot(bond.GetStereo(), BOND_STEREO)\n",
        "    return feats\n",
        "\n",
        "def mol_to_pyg(mol, label):\n",
        "    num_atoms = mol.GetNumAtoms()\n",
        "    x = torch.tensor([atom_features(mol.GetAtomWithIdx(i)) for i in range(num_atoms)], dtype=torch.float)\n",
        "\n",
        "    edge_index = []\n",
        "    edge_attr = []\n",
        "    for bond in mol.GetBonds():\n",
        "        i = bond.GetBeginAtomIdx()\n",
        "        j = bond.GetEndAtomIdx()\n",
        "        bf = bond_features(bond)\n",
        "        edge_index.append([i, j])\n",
        "        edge_attr.append(bf)\n",
        "        edge_index.append([j, i])\n",
        "        edge_attr.append(bf)\n",
        "\n",
        "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
        "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"utils_gnn.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OB6o5fs3SkYi",
        "outputId": "bd869b12-c029-4d47-80d6-2c928a4a7ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/Models/utils_gnn.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the file\n",
        "\n",
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGVhZvRZTm89",
        "outputId": "68b8a6fd-9179-4c60-b224-e19bbd354ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utils_gnn.py']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.data_gnn.py"
      ],
      "metadata": {
        "id": "POC4pjl9OU-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils_gnn import check_columns, smiles_to_mol, mol_to_pyg # utils\n",
        "\n",
        "\n",
        "def load_excel(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    return pd.read_excel(path)\n",
        "\n",
        "\n",
        "def clean_df(df):\n",
        "    check_columns(df)\n",
        "    df = df.copy()\n",
        "    df[\"SMILES\"] = df[\"SMILES\"].astype(str)\n",
        "    df[\"mol\"] = df[\"SMILES\"].apply(smiles_to_mol)\n",
        "    df = df[df[\"mol\"].notna()].reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def stratified_split(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
        "    df = df.copy()\n",
        "    df[\"length\"] = df[\"aa_seq\"].astype(str).str.len()\n",
        "\n",
        "    bins = [0, 5, 10, 15, 20, 1e9]\n",
        "    labels = [\"1-5\", \"6-10\", \"11-15\", \"16-20\", \"21+\"]\n",
        "    df[\"length_bin\"] = pd.cut(df[\"length\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
        "\n",
        "    df[\"stratum\"] = df[\"seed_bh\"].astype(str) + \"|\" + df[\"dataset\"].astype(str) + \"|\" + df[\"length_bin\"].astype(str)\n",
        "\n",
        "    stratum_counts = df[\"stratum\"].value_counts()\n",
        "    use_stratify = (stratum_counts.min() >= 2)\n",
        "    stratify_col = df[\"stratum\"] if use_stratify else None\n",
        "\n",
        "    train_df, temp_df = train_test_split(\n",
        "        df, test_size=(1 - train_ratio), random_state=seed, stratify=stratify_col\n",
        "    )\n",
        "\n",
        "    val_size = val_ratio / (val_ratio + test_ratio)\n",
        "    stratify_temp = temp_df[\"stratum\"] if use_stratify else None\n",
        "\n",
        "    val_df, test_df = train_test_split(\n",
        "        temp_df, test_size=(1 - val_size), random_state=seed, stratify=stratify_temp\n",
        "    )\n",
        "\n",
        "    df[\"train_test\"] = \"\"\n",
        "    df.loc[train_df.index, \"train_test\"] = \"train\"\n",
        "    df.loc[val_df.index, \"train_test\"] = \"val\"\n",
        "    df.loc[test_df.index, \"train_test\"] = \"test\"\n",
        "\n",
        "    df.drop(columns=[\"mol\", \"length\", \"length_bin\", \"stratum\"], errors=\"ignore\", inplace=True)\n",
        "    return df, train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def build_pyg_dataset(sub_df):\n",
        "    data_list = []\n",
        "    for _, row in sub_df.iterrows():\n",
        "        mol = smiles_to_mol(row[\"SMILES\"])\n",
        "        if mol is None:\n",
        "            continue\n",
        "        data = mol_to_pyg(mol, row[\"seed_bh\"])\n",
        "        data_list.append(data)\n",
        "    return data_list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY70Wk2M1TIK",
        "outputId": "c76d1493-1d80-413c-e591-b0be34558131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 写入py文件"
      ],
      "metadata": {
        "id": "up7WEKsqVO24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from utils_gnn import check_columns, smiles_to_mol  # mol_to_pyg 这里暂时用不上也可以不导入\n",
        "\n",
        "\n",
        "def load_excel(path):\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    return pd.read_excel(path)\n",
        "\n",
        "\n",
        "def clean_df(df):\n",
        "    check_columns(df)\n",
        "    df = df.copy()\n",
        "    df[\"SMILES\"] = df[\"SMILES\"].astype(str)\n",
        "    df[\"mol\"] = df[\"SMILES\"].apply(smiles_to_mol)\n",
        "    df = df[df[\"mol\"].notna()].reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def stratified_split(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
        "    # 只按 seed_bh 分层：每个类内部 shuffle 后按比例切\n",
        "    df = df.copy()\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    df[\"train_test\"] = \"\"\n",
        "    for label, sub_idx in df.groupby(\"seed_bh\").groups.items():\n",
        "        sub_idx = np.array(list(sub_idx))\n",
        "        rng.shuffle(sub_idx)\n",
        "\n",
        "        n = len(sub_idx)\n",
        "        n_train = int(round(n * train_ratio))\n",
        "        n_val = int(round(n * val_ratio))\n",
        "        # n_test 用剩余，保证总数一致\n",
        "        # n_test = n - n_train - n_val\n",
        "\n",
        "        train_idx = sub_idx[:n_train]\n",
        "        val_idx = sub_idx[n_train:n_train + n_val]\n",
        "        test_idx = sub_idx[n_train + n_val:]\n",
        "\n",
        "        df.loc[train_idx, \"train_test\"] = \"train\"\n",
        "        df.loc[val_idx, \"train_test\"] = \"val\"\n",
        "        df.loc[test_idx, \"train_test\"] = \"test\"\n",
        "\n",
        "    train_df = df[df[\"train_test\"] == \"train\"].copy()\n",
        "    val_df = df[df[\"train_test\"] == \"val\"].copy()\n",
        "    test_df = df[df[\"train_test\"] == \"test\"].copy()\n",
        "\n",
        "    # 清理临时列\n",
        "    df.drop(columns=[\"mol\"], errors=\"ignore\", inplace=True)\n",
        "    return df, train_df, val_df, test_df\n",
        "\n",
        "\n",
        "def report_split(df_split):\n",
        "    # 打印你关心的三个统计\n",
        "    print(df_split[\"train_test\"].value_counts(normalize=True).rename(\"proportion\"))\n",
        "    print(df_split.groupby(\"train_test\")[\"seed_bh\"].mean().rename(\"seed_bh\"))\n",
        "    print(df_split[\"seed_bh\"].mean())\n",
        "\n",
        "def save_split(df_split, out_path=\"/content/drive/MyDrive/master_thesis/sampled_data_5000\",\n",
        "               filename=\"canya_1000_splits_train-test-val\"):\n",
        "    \"\"\"\n",
        "    Save df_split (with train_test column) to an Excel file in out_path.\n",
        "    Returns the full saved file path.\n",
        "    \"\"\"\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # 自动补 .xlsx 后缀\n",
        "    if not filename.lower().endswith(\".xlsx\"):\n",
        "        filename = filename + \".xlsx\"\n",
        "\n",
        "    full_path = os.path.join(out_path, filename)\n",
        "    df_split.to_excel(full_path, index=False)\n",
        "    return full_path\n",
        "\n",
        "'''\n",
        "out_path = os.path.join(out_dir, \"data_gnn.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "print(\"Wrote:\", out_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcAkBnMiVRjB",
        "outputId": "ebca8541-0386-421e-8c69-fdf912430362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/drive/MyDrive/master_thesis/sampled_data_5000/Models/data_gnn.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")\n",
        "\n",
        "import importlib\n",
        "import data_gnn\n",
        "importlib.reload(data_gnn)\n",
        "\n",
        "from data_gnn import load_excel, clean_df, stratified_split, save_split\n",
        "\n",
        "# Define path for this cell\n",
        "path = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_1000_smiles.xlsx\"\n",
        "\n",
        "df = load_excel(path)\n",
        "df = clean_df(df)\n",
        "df_split, train_df, val_df, test_df = stratified_split(df, 0.7, 0.15, 0.15, seed=42)\n",
        "\n",
        "saved_path = save_split(df_split)  # 用默认目录+默认文件名\n",
        "print(\"Saved to:\", saved_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOZD0nkfhkVZ",
        "outputId": "488969fc-41be-41ab-a4b1-a2aa7260f92a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to: /content/drive/MyDrive/master_thesis/sampled_data_5000/canya_1000_splits_train-test-val.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check train/val/test sets\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")\n",
        "\n",
        "# Explicitly reload the module to ensure the latest version is used\n",
        "import importlib\n",
        "import data_gnn\n",
        "importlib.reload(data_gnn)\n",
        "\n",
        "from data_gnn import load_excel, clean_df, stratified_split, report_split\n",
        "\n",
        "# Corrected excel path\n",
        "path = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_1000_smiles.xlsx\"\n",
        "\n",
        "df = load_excel(path)\n",
        "df = clean_df(df)\n",
        "\n",
        "df_split, train_df, val_df, test_df = stratified_split(df, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42)\n",
        "\n",
        "report_split(df_split)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yxapEjwgRbF",
        "outputId": "9f641eef-1818-4dc8-d55e-be84b7f107d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_test\n",
            "train    0.70\n",
            "test     0.15\n",
            "val      0.15\n",
            "Name: proportion, dtype: float64\n",
            "train_test\n",
            "test     0.206667\n",
            "train    0.205714\n",
            "val      0.206667\n",
            "Name: seed_bh, dtype: float64\n",
            "0.206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcruV4hhVdv0",
        "outputId": "a085b8bf-fd76-43ac-d1d3-49b9ba398531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utils_gnn.py', '__pycache__', 'data_gnn.py', 'models_gnn.py']"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.models_gnn.py"
      ],
      "metadata": {
        "id": "f3rv_k0DPAr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "\n",
        "# Install PyG with GPU preference, fallback to CPU\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# device: prefer GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "class GINClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, edge_dim, hidden_dim=128, num_layers=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            input_dim = in_dim if i == 0 else hidden_dim\n",
        "            nn_mlp = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GINEConv(nn=nn_mlp, edge_dim=edge_dim))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, edge_attr)\n",
        "            x = torch.relu(x)\n",
        "            x = nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        out = self.classifier(x).view(-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device):\n",
        "    model.eval()\n",
        "    ys = []\n",
        "    logits = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            ys.append(batch.y.view(-1).cpu().numpy())\n",
        "            logits.append(out.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(ys) if ys else np.array([])\n",
        "    y_logit = np.concatenate(logits) if logits else np.array([])\n",
        "    y_prob = 1 / (1 + np.exp(-y_logit)) if len(y_logit) > 0 else np.array([])\n",
        "\n",
        "    metrics = {}\n",
        "    if len(np.unique(y_true)) >= 2:\n",
        "        metrics[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
        "        metrics[\"pr_auc\"] = average_precision_score(y_true, y_prob)\n",
        "    else:\n",
        "        metrics[\"roc_auc\"] = None\n",
        "        metrics[\"pr_auc\"] = None\n",
        "\n",
        "    y_pred = (y_prob >= 0.5).astype(int) if len(y_prob) > 0 else np.array([])\n",
        "    if len(y_true) > 0:\n",
        "        metrics[\"acc\"] = accuracy_score(y_true, y_pred)\n",
        "        metrics[\"f1\"] = f1_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"precision\"] = precision_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"recall\"] = recall_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"cm\"] = confusion_matrix(y_true, y_pred)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model, train_list, val_list, model_path,\n",
        "    lr=1e-3, batch_size=64, epochs=100, patience=10, device=\"cpu\"\n",
        "):\n",
        "    train_loader = DataLoader(train_list, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_list, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    y_train = torch.tensor([d.y.item() for d in train_list])\n",
        "    n_pos = (y_train == 1).sum().item()\n",
        "    n_neg = (y_train == 0).sum().item()\n",
        "    pos_weight = torch.tensor([n_neg / n_pos], dtype=torch.float).to(device) if n_pos > 0 else None\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_metric = -1\n",
        "    wait = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = criterion(out, batch.y.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device)\n",
        "        val_score = val_metrics[\"roc_auc\"] if val_metrics[\"roc_auc\"] is not None else val_metrics[\"f1\"]\n",
        "        if val_score is None:\n",
        "            val_score = -1\n",
        "\n",
        "        if val_score > best_metric:\n",
        "            best_metric = val_score\n",
        "            wait = 0\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            wait += 1\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Loss {total_loss/len(train_list):.4f} | Val score {val_score:.4f}\")\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    return model_path\n",
        "\n",
        "\n",
        "def predict_smiles(model, data_list, device=\"cpu\", threshold=0.5):\n",
        "    loader = DataLoader(data_list, batch_size=64, shuffle=False)\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            logits = model(batch)\n",
        "            p = torch.sigmoid(logits).cpu().numpy()\n",
        "            probs.extend(p.tolist())\n",
        "    preds = [1 if p >= threshold else 0 for p in probs]\n",
        "    return probs, preds\n",
        "\n",
        "# Usage:\n",
        "# model = GINClassifier(in_dim, edge_dim).to(device)\n",
        "# train_model(model, train_list, val_list, \"best.pt\", device=device)\n",
        "# probs, preds = predict_smiles(model, data_list, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvDNemeRPFn4",
        "outputId": "3ae6e897-1c70-46a5-ab14-78d87802b3e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mUsing device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 写入py文件"
      ],
      "metadata": {
        "id": "1nBiSqj2XZTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "# Install PyG with GPU preference, fallback to CPU\n",
        "# The following lines are commented out as pip installs should ideally be done outside of modules\n",
        "# if torch.cuda.is_available():\n",
        "#     !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "# else:\n",
        "#     !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GINEConv, global_mean_pool\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, average_precision_score,\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# device: prefer GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "class GINClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, edge_dim, hidden_dim=128, num_layers=4, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            input_dim = in_dim if i == 0 else hidden_dim\n",
        "            nn_mlp = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "            )\n",
        "            self.convs.append(GINEConv(nn=nn_mlp, edge_dim=edge_dim))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, edge_attr)\n",
        "            x = torch.relu(x)\n",
        "            x = nn.functional.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        out = self.classifier(x).view(-1)\n",
        "        return out\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device):\n",
        "    model.eval()\n",
        "    ys = []\n",
        "    logits = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            out = model(batch)\n",
        "            ys.append(batch.y.view(-1).cpu().numpy())\n",
        "            logits.append(out.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(ys) if ys else np.array([])\n",
        "    y_logit = np.concatenate(logits) if logits else np.array([])\n",
        "    y_prob = 1 / (1 + np.exp(-y_logit)) if len(y_logit) > 0 else np.array([])\n",
        "\n",
        "    metrics = {}\n",
        "    if len(np.unique(y_true)) >= 2:\n",
        "        metrics[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n",
        "        metrics[\"pr_auc\"] = average_precision_score(y_true, y_prob)\n",
        "    else:\n",
        "        metrics[\"roc_auc\"] = None\n",
        "        metrics[\"pr_auc\"] = None\n",
        "\n",
        "    y_pred = (y_prob >= 0.5).astype(int) if len(y_prob) > 0 else np.array([])\n",
        "    if len(y_true) > 0:\n",
        "        metrics[\"acc\"] = accuracy_score(y_true, y_pred)\n",
        "        metrics[\"f1\"] = f1_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"precision\"] = precision_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"recall\"] = recall_score(y_true, y_pred, zero_division=0)\n",
        "        metrics[\"cm\"] = confusion_matrix(y_true, y_pred)\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model, train_list, val_list, model_path,\n",
        "    lr=1e-3, batch_size=64, epochs=100, patience=10, device=\"cpu\"\n",
        "):\n",
        "    train_loader = DataLoader(train_list, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_list, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    y_train = torch.tensor([d.y.item() for d in train_list])\n",
        "    n_pos = (y_train == 1).sum().item()\n",
        "    n_neg = (y_train == 0).sum().item()\n",
        "    pos_weight = torch.tensor([n_neg / n_pos], dtype=torch.float).to(device) if n_pos > 0 else None\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_metric = -1\n",
        "    wait = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch = batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(batch)\n",
        "            loss = criterion(out, batch.y.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device)\n",
        "        val_score = val_metrics[\"roc_auc\"] if val_metrics[\"roc_auc\"] is not None else val_metrics[\"f1\"]\n",
        "        if val_score is None:\n",
        "            val_score = -1\n",
        "\n",
        "        if val_score > best_metric:\n",
        "            best_metric = val_score\n",
        "            wait = 0\n",
        "            torch.save(model.state_dict(), model_path)\n",
        "        else:\n",
        "            wait += 1\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Loss {total_loss/len(train_list):.4f} | Val score {val_score:.4f}\")\n",
        "        if wait >= patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break\n",
        "\n",
        "    return model_path\n",
        "\n",
        "\n",
        "def predict_smiles(model, data_list, device=\"cpu\", threshold=0.5):\n",
        "    loader = DataLoader(data_list, batch_size=64, shuffle=False)\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            logits = model(batch)\n",
        "            p = torch.sigmoid(logits).cpu().numpy()\n",
        "            probs.extend(p.tolist())\n",
        "    preds = [1 if p >= threshold else 0 for p in probs]\n",
        "    return probs, preds\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"models_gnn.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rEYmNjeGXbLp",
        "outputId": "434a7722-0782-46dd-c58f-de98a88f2175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/Models/models_gnn.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/Models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSYso-NnXmB1",
        "outputId": "dd076735-581e-4905-9762-53a61460a70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['utils_gnn.py', '__pycache__', 'data_gnn.py', 'models_gnn.py']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.run_gnn_pipeline.py"
      ],
      "metadata": {
        "id": "zwZihozEPMy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from utils_gnn import seed_all\n",
        "from data_gnn import load_excel, clean_df, stratified_split, build_pyg_dataset\n",
        "from models_gnn import GINClassifier, train_model, eval_model\n",
        "\n",
        "# =====================\n",
        "# Config\n",
        "# =====================\n",
        "EXCEL_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_1000_smiles.xlsx\"\n",
        "OUT_SPLIT_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_1000_smiles_split.xlsx\"\n",
        "MODEL_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/gnn_best.pt\"\n",
        "\n",
        "TRAIN_RATIO = 0.7\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "EPOCHS = 100\n",
        "PATIENCE = 10\n",
        "HIDDEN_DIM = 128\n",
        "NUM_LAYERS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "# =====================\n",
        "# Run\n",
        "# =====================\n",
        "seed_all(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "df = load_excel(EXCEL_PATH)\n",
        "df = clean_df(df)\n",
        "\n",
        "df_split, train_df, val_df, test_df = stratified_split(\n",
        "    df, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO, test_ratio=TEST_RATIO, seed=SEED\n",
        ")\n",
        "df_split.to_excel(OUT_SPLIT_PATH, index=False)\n",
        "print(f\"Saved split Excel to: {OUT_SPLIT_PATH}\")\n",
        "\n",
        "train_list = build_pyg_dataset(train_df)\n",
        "val_list = build_pyg_dataset(val_df)\n",
        "test_list = build_pyg_dataset(test_df)\n",
        "\n",
        "if len(train_list) == 0:\n",
        "    raise ValueError(\"Train set is empty after cleaning.\")\n",
        "if len(val_list) == 0:\n",
        "    raise ValueError(\"Val set is empty after cleaning.\")\n",
        "if len(test_list) == 0:\n",
        "    raise ValueError(\"Test set is empty after cleaning.\")\n",
        "\n",
        "sample_data = train_list[0]\n",
        "in_dim = sample_data.x.size(1)\n",
        "edge_dim = sample_data.edge_attr.size(1)\n",
        "\n",
        "model = GINClassifier(in_dim, edge_dim, hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, dropout=DROPOUT).to(device)\n",
        "\n",
        "train_model(\n",
        "    model,\n",
        "    train_list,\n",
        "    val_list,\n",
        "    model_path=MODEL_PATH,\n",
        "    lr=LR,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    patience=PATIENCE,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "test_loader = DataLoader(test_list, batch_size=BATCH_SIZE, shuffle=False)\n",
        "metrics = eval_model(model, test_loader, device)\n",
        "\n",
        "print(\"\\nTest metrics:\")\n",
        "print(f\"ROC-AUC: {metrics.get('roc_auc')}\")\n",
        "print(f\"PR-AUC: {metrics.get('pr_auc')}\")\n",
        "print(f\"Accuracy: {metrics.get('acc')}\")\n",
        "print(f\"F1: {metrics.get('f1')}\")\n",
        "print(f\"Precision: {metrics.get('precision')}\")\n",
        "print(f\"Recall: {metrics.get('recall')}\")\n",
        "print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR3Nka8YPO24",
        "outputId": "d54a8ba0-70af-4cd7-e9be-32aad9198fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved split Excel to: /content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_1000_smiles_split.xlsx\n",
            "Epoch 001 | Loss 1.1040 | Val score 0.5310\n",
            "Epoch 002 | Loss 1.1029 | Val score 0.5337\n",
            "Epoch 003 | Loss 1.1030 | Val score 0.5346\n",
            "Epoch 004 | Loss 1.1015 | Val score 0.5310\n",
            "Epoch 005 | Loss 1.1019 | Val score 0.5335\n",
            "Epoch 006 | Loss 1.1046 | Val score 0.5367\n",
            "Epoch 007 | Loss 1.1010 | Val score 0.5346\n",
            "Epoch 008 | Loss 1.1002 | Val score 0.5348\n",
            "Epoch 009 | Loss 1.1003 | Val score 0.5328\n",
            "Epoch 010 | Loss 1.1006 | Val score 0.5337\n",
            "Epoch 011 | Loss 1.1003 | Val score 0.5346\n",
            "Epoch 012 | Loss 1.1012 | Val score 0.5386\n",
            "Epoch 013 | Loss 1.0971 | Val score 0.5370\n",
            "Epoch 014 | Loss 1.0974 | Val score 0.5367\n",
            "Epoch 015 | Loss 1.0961 | Val score 0.5397\n",
            "Epoch 016 | Loss 1.0970 | Val score 0.5405\n",
            "Epoch 017 | Loss 1.0942 | Val score 0.5438\n",
            "Epoch 018 | Loss 1.0936 | Val score 0.5403\n",
            "Epoch 019 | Loss 1.0933 | Val score 0.5454\n",
            "Epoch 020 | Loss 1.0916 | Val score 0.5462\n",
            "Epoch 021 | Loss 1.0949 | Val score 0.5384\n",
            "Epoch 022 | Loss 1.0911 | Val score 0.5454\n",
            "Epoch 023 | Loss 1.0926 | Val score 0.5457\n",
            "Epoch 024 | Loss 1.0877 | Val score 0.5400\n",
            "Epoch 025 | Loss 1.0855 | Val score 0.5381\n",
            "Epoch 026 | Loss 1.0853 | Val score 0.5454\n",
            "Epoch 027 | Loss 1.0891 | Val score 0.5435\n",
            "Epoch 028 | Loss 1.0851 | Val score 0.5459\n",
            "Epoch 029 | Loss 1.0875 | Val score 0.5435\n",
            "Epoch 030 | Loss 1.0831 | Val score 0.5411\n",
            "Early stopping.\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.5627541339116291\n",
            "PR-AUC: 0.22961498012509102\n",
            "Accuracy: 0.49333333333333335\n",
            "F1: 0.3448275862068966\n",
            "Precision: 0.23529411764705882\n",
            "Recall: 0.6451612903225806\n",
            "Confusion matrix:\n",
            "[[54 65]\n",
            " [11 20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.residual features(descriptors)"
      ],
      "metadata": {
        "id": "Hmmu7nuqr2JO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 计算13个descriptors"
      ],
      "metadata": {
        "id": "Gkl_18Sdd2aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "\n",
        "RESIDUE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residual_dictionary.xlsx\"\n",
        "\n",
        "\n",
        "def calc_descriptors(smiles, one_letter):\n",
        "    \"\"\"Parse SMILES and calculate RDKit descriptors; return dict (or NaNs if fail).\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        print(f\"[WARN] Failed to parse SMILES for {one_letter}: {smiles}\")\n",
        "        return {\n",
        "            \"mw\": np.nan,\n",
        "            \"logp\": np.nan,\n",
        "            \"tpsa\": np.nan,\n",
        "            \"hbd\": np.nan,\n",
        "            \"hba\": np.nan,\n",
        "            \"har\": np.nan,\n",
        "            \"aro\": np.nan,\n",
        "            \"aliph\": np.nan,\n",
        "            \"rot\": np.nan,\n",
        "            \"frac_csp3\": np.nan,\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        \"mw\": Descriptors.MolWt(mol),\n",
        "        \"logp\": Descriptors.MolLogP(mol),\n",
        "        \"tpsa\": Descriptors.TPSA(mol),\n",
        "        \"hbd\": Descriptors.NumHDonors(mol),\n",
        "        \"hba\": Descriptors.NumHAcceptors(mol),\n",
        "        \"har\": Descriptors.HeavyAtomCount(mol),\n",
        "        \"aro\": Descriptors.NumAromaticRings(mol),\n",
        "        \"aliph\": Descriptors.NumAliphaticRings(mol),\n",
        "        \"rot\": Descriptors.NumRotatableBonds(mol),\n",
        "        \"frac_csp3\": Descriptors.FractionCSP3(mol),\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Read residue dictionary from Excel\n",
        "    df = pd.read_excel(RESIDUE_excel_PATH)\n",
        "\n",
        "    # Compute descriptors row by row\n",
        "    desc_list = []\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row.get(\"1-Letter\", \"\")).strip()\n",
        "        smiles = row.get(\"SMILES (L-isomer)\", \"\")\n",
        "        desc = calc_descriptors(smiles, one_letter)\n",
        "        desc_list.append(desc)\n",
        "\n",
        "    desc_df = pd.DataFrame(desc_list)\n",
        "\n",
        "    # Add manual features based on 1-letter code\n",
        "    one_letters = df[\"1-Letter\"].astype(str).str.strip()\n",
        "    is_pos = one_letters.isin([\"K\", \"R\", \"H\"]).astype(int)\n",
        "    is_neg = one_letters.isin([\"D\", \"E\"]).astype(int)\n",
        "    is_aro = one_letters.isin([\"F\", \"Y\", \"W\", \"H\"]).astype(int)\n",
        "\n",
        "    # Assemble final DataFrame\n",
        "    out_df = pd.DataFrame({\n",
        "        \"1-Letter\": df.get(\"1-Letter\"),\n",
        "        \"Name\": df.get(\"Name\"),\n",
        "        \"Type\": df.get(\"Type\"),\n",
        "        \"SMILES (L-isomer)\": df.get(\"SMILES (L-isomer)\"),\n",
        "    })\n",
        "    out_df = pd.concat([out_df, desc_df], axis=1)\n",
        "    out_df[\"is_pos\"] = is_pos\n",
        "    out_df[\"is_neg\"] = is_neg\n",
        "    out_df[\"is_aro\"] = is_aro\n",
        "\n",
        "    # Save to Excel (fixed output directory)\n",
        "    out_path = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residual_features.xlsx\"\n",
        "    out_df.to_excel(out_path, index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nXdNEWfrwHf",
        "outputId": "744f5f77-b418-4281-ddad-e24068046236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✅计算66 descriptors，增强的features, correlation map"
      ],
      "metadata": {
        "id": "fSJbf5wWfFCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "RESIDUE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residual_dictionary.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "HEATMAP_PNG = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation.png\"\n",
        "HEATMAP_PNG_FILTERED = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation_filtered.png\"\n",
        "\n",
        "\n",
        "def get_descriptor_functions():\n",
        "    \"\"\"Return list of (name, func) for all RDKit descriptors.\"\"\"\n",
        "    return Descriptors._descList\n",
        "\n",
        "\n",
        "def compute_all_descriptors(smiles, one_letter):\n",
        "    \"\"\"Compute all RDKit descriptors for a SMILES. Return dict or None if fail.\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        print(f\"[WARN] Failed to parse SMILES for {one_letter}: {smiles}\")\n",
        "        return None\n",
        "\n",
        "    desc_values = {}\n",
        "    for name, func in get_descriptor_functions():\n",
        "        try:\n",
        "            desc_values[name] = func(mol)\n",
        "        except Exception:\n",
        "            desc_values[name] = np.nan\n",
        "    return desc_values\n",
        "\n",
        "\n",
        "def remove_nan_and_constant_features(df):\n",
        "    \"\"\"Remove columns containing NaN or constant values.\"\"\"\n",
        "    df_clean = df.dropna(axis=1, how=\"any\")\n",
        "    nunique = df_clean.nunique(axis=0)\n",
        "    df_clean = df_clean.loc[:, nunique > 1]\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "def correlation_filter(df, threshold=0.9):\n",
        "    \"\"\"\n",
        "    Remove redundant features using Pearson correlation.\n",
        "    Keep the first feature and drop others if corr > threshold.\n",
        "    \"\"\"\n",
        "    corr = df.corr(method=\"pearson\").abs()\n",
        "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "    to_drop = [col for col in upper.columns if any(upper[col] > threshold)]\n",
        "    kept = [col for col in df.columns if col not in to_drop]\n",
        "    return kept, to_drop\n",
        "\n",
        "\n",
        "def main():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # 1) Load residue dictionary\n",
        "    df = pd.read_excel(RESIDUE_excel_PATH)\n",
        "\n",
        "    standard_aa = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "    df = df[df[\"1-Letter\"].astype(str).str.strip().isin(standard_aa)].copy()\n",
        "    df[\"1-Letter\"] = df[\"1-Letter\"].astype(str).str.strip()\n",
        "    df = df.drop_duplicates(subset=[\"1-Letter\"], keep=\"first\")\n",
        "\n",
        "\n",
        "    required_cols = [\"1-Letter\", \"SMILES (L-isomer)\"]\n",
        "    for c in required_cols:\n",
        "        if c not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {c}\")\n",
        "\n",
        "    # 2) Compute descriptors for each residue\n",
        "    desc_list = []\n",
        "    aa_codes = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row.get(\"1-Letter\", \"\")).strip()\n",
        "        smiles = row.get(\"SMILES (L-isomer)\", \"\")\n",
        "\n",
        "        desc_values = compute_all_descriptors(smiles, one_letter)\n",
        "        if desc_values is None:\n",
        "            continue\n",
        "\n",
        "        aa_codes.append(one_letter)\n",
        "        desc_list.append(desc_values)\n",
        "\n",
        "    desc_df = pd.DataFrame(desc_list, index=aa_codes)\n",
        "    desc_df.index.name = \"1-Letter\"\n",
        "\n",
        "    # 3) Remove NaN and constant columns\n",
        "    desc_df = remove_nan_and_constant_features(desc_df)\n",
        "\n",
        "    # 4) Standardize features 标准化\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(desc_df.values)\n",
        "    scaled_df = pd.DataFrame(scaled, index=desc_df.index, columns=desc_df.columns)\n",
        "\n",
        "    # 5) Correlation heatmap (before filtering)\n",
        "    corr = scaled_df.corr(method=\"pearson\")\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Descriptor Correlation Heatmap (Before Filtering)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(HEATMAP_PNG, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 6) Correlation-based feature selection\n",
        "    kept, dropped = correlation_filter(scaled_df, threshold=0.9)\n",
        "    selected_df = scaled_df[kept]\n",
        "\n",
        "    # Heatmap after filtering\n",
        "    corr_filtered = selected_df.corr(method=\"pearson\")\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr_filtered, cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Descriptor Correlation Heatmap (After Filtering)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(HEATMAP_PNG_FILTERED, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "    # 7) Assemble final DataFrame (metadata + descriptors) -- use merge to align rows\n",
        "    meta_df = pd.DataFrame({\n",
        "        \"1-Letter\": df.get(\"1-Letter\"),\n",
        "        \"Name\": df.get(\"Name\"),\n",
        "        \"Type\": df.get(\"Type\"),\n",
        "        \"SMILES (L-isomer)\": df.get(\"SMILES (L-isomer)\"),\n",
        "    })\n",
        "\n",
        "    selected_df = selected_df.reset_index()  # 把 1-Letter 变成列\n",
        "    out_df = pd.merge(meta_df, selected_df, on=\"1-Letter\", how=\"inner\")\n",
        "\n",
        "    # 保存\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "    # 8) Print retained descriptor list\n",
        "    print(\"Final retained descriptors (count = %d):\" % len(kept))\n",
        "    print(kept)\n",
        "    print(f\"\\nSaved enhanced feature table to: {OUTPUT_XLSX}\")\n",
        "    print(f\"Saved correlation heatmap to: {HEATMAP_PNG}\")\n",
        "    print(out_df.columns)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UDkEhsRfLww",
        "outputId": "0a4e7293-78e8-43a5-9aac-edf1abd3760f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Final retained descriptors (count = 66):\n",
            "['MaxAbsEStateIndex', 'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MaxPartialCharge', 'MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI', 'BCUT2D_LOGPLOW', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT', 'HallKierAlpha', 'Kappa3', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'EState_VSA1', 'EState_VSA10', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'VSA_EState3', 'VSA_EState5', 'VSA_EState8', 'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticHeterocycles', 'NumAtomStereoCenters', 'NumHAcceptors', 'NumHeterocycles', 'MolLogP', 'fr_Al_OH', 'fr_NH1', 'fr_sulfide', 'fr_unbrch_alkane']\n",
            "\n",
            "Saved enhanced feature table to: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\n",
            "Saved correlation heatmap to: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation.png\n",
            "Index(['1-Letter', 'Name', 'Type', 'SMILES (L-isomer)', 'MaxAbsEStateIndex',\n",
            "       'MinAbsEStateIndex', 'MinEStateIndex', 'qed', 'SPS', 'MaxPartialCharge',\n",
            "       'MinPartialCharge', 'FpDensityMorgan1', 'FpDensityMorgan2',\n",
            "       'FpDensityMorgan3', 'BCUT2D_MWHI', 'BCUT2D_MWLOW', 'BCUT2D_CHGHI',\n",
            "       'BCUT2D_LOGPLOW', 'BCUT2D_MRLOW', 'AvgIpc', 'BalabanJ', 'BertzCT',\n",
            "       'HallKierAlpha', 'Kappa3', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11',\n",
            "       'PEOE_VSA12', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA6',\n",
            "       'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9', 'SMR_VSA1', 'SMR_VSA10',\n",
            "       'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7',\n",
            "       'SlogP_VSA1', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'EState_VSA1',\n",
            "       'EState_VSA10', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4',\n",
            "       'EState_VSA5', 'EState_VSA6', 'EState_VSA7', 'EState_VSA8',\n",
            "       'EState_VSA9', 'VSA_EState3', 'VSA_EState5', 'VSA_EState8',\n",
            "       'FractionCSP3', 'NumAliphaticHeterocycles', 'NumAromaticHeterocycles',\n",
            "       'NumAtomStereoCenters', 'NumHAcceptors', 'NumHeterocycles', 'MolLogP',\n",
            "       'fr_Al_OH', 'fr_NH1', 'fr_sulfide', 'fr_unbrch_alkane'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 66+经典21 descriptors"
      ],
      "metadata": {
        "id": "Egu5C-JJ1Lzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "OLD_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_03.xlsx\"\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\", \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\", \"LabuteASA\", \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "\n",
        "def get_descriptor_map():\n",
        "    \"\"\"Return mapping of descriptor name -> function.\"\"\"\n",
        "    return {name: func for name, func in Descriptors._descList}\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = pd.read_excel(OLD_FEATURE_XLSX)\n",
        "\n",
        "    # Detect key column\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    # Detect SMILES column\n",
        "    if \"SMILES (L-isomer)\" in df.columns:\n",
        "        smiles_col = \"SMILES (L-isomer)\"\n",
        "    elif \"SMILES\" in df.columns:\n",
        "        smiles_col = \"SMILES\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing SMILES column: expected 'SMILES (L-isomer)' or 'SMILES'.\")\n",
        "\n",
        "    # Meta columns present in file\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", smiles_col]\n",
        "    meta_cols = [c for c in meta_candidates if c in df.columns]\n",
        "\n",
        "    # Compute missing classic descriptors\n",
        "    desc_map = get_descriptor_map()\n",
        "    classic_missing = [d for d in CLASSIC_DESC if d not in df.columns]\n",
        "\n",
        "    if classic_missing:\n",
        "        for d in classic_missing:\n",
        "            if d not in desc_map:\n",
        "                raise ValueError(f\"Descriptor '{d}' not found in RDKit Descriptors.\")\n",
        "\n",
        "        computed = {d: [] for d in classic_missing}\n",
        "        for _, row in df.iterrows():\n",
        "            smi = row.get(smiles_col, None)\n",
        "            mol = Chem.MolFromSmiles(smi) if isinstance(smi, str) else None\n",
        "            for d in classic_missing:\n",
        "                if mol is None:\n",
        "                    computed[d].append(np.nan)\n",
        "                else:\n",
        "                    try:\n",
        "                        computed[d].append(desc_map[d](mol))\n",
        "                    except Exception:\n",
        "                        computed[d].append(np.nan)\n",
        "\n",
        "        for d in classic_missing:\n",
        "            df[d] = computed[d]\n",
        "\n",
        "    # Drop rows with NaN in classic descriptors (after compute)\n",
        "    df = df.dropna(subset=CLASSIC_DESC, how=\"any\")\n",
        "\n",
        "    # Feature columns = all non-meta columns\n",
        "    feature_cols = [c for c in df.columns if c not in meta_cols]\n",
        "\n",
        "    # Remove NaN and constant feature columns\n",
        "    feat_df = df[feature_cols].copy()\n",
        "    feat_df = feat_df.dropna(axis=1, how=\"any\")\n",
        "    nunique = feat_df.nunique(axis=0)\n",
        "    feat_df = feat_df.loc[:, nunique > 1]\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(feat_df.values)\n",
        "    scaled_df = pd.DataFrame(scaled, columns=feat_df.columns, index=feat_df.index)\n",
        "\n",
        "    # Assemble output with meta + scaled features\n",
        "    out_df = pd.concat([df[meta_cols].reset_index(drop=True), scaled_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Sanity check for scaled features\n",
        "    stats = scaled_df.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n",
        "    print(\"Sanity check (first 10 features):\")\n",
        "    print(stats.iloc[:, :10])\n",
        "\n",
        "    # Print required info\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"Classic missing in old file:\", classic_missing)\n",
        "    print(\"Final feature count:\", scaled_df.shape[1])\n",
        "    print(\"Output path:\", OUTPUT_XLSX)\n",
        "\n",
        "    # Save\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cntIjokw1Pp4",
        "outputId": "4eb91bba-ccfe-4a6e-e66a-ed4907f5293e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check (first 10 features):\n",
            "      MaxAbsEStateIndex  MinAbsEStateIndex  MinEStateIndex           qed  \\\n",
            "mean      -2.775558e-17       1.110223e-17    1.665335e-17 -1.387779e-17   \n",
            "std        1.025978e+00       1.025978e+00    1.025978e+00  1.025978e+00   \n",
            "min       -2.616928e+00      -1.266428e+00   -2.031500e+00 -2.626475e+00   \n",
            "max        1.872055e+00       2.641208e+00    2.300042e+00  1.709766e+00   \n",
            "\n",
            "               SPS  MaxPartialCharge  MinPartialCharge  FpDensityMorgan1  \\\n",
            "mean  2.116363e-17      2.012279e-17     -2.775558e-18     -1.942890e-17   \n",
            "std   1.025978e+00      1.025978e+00      1.025978e+00      1.025978e+00   \n",
            "min  -1.761074e+00     -3.162808e+00     -4.352092e+00     -1.350959e+00   \n",
            "max   3.695238e+00      2.100473e+00      2.603084e-01      1.747154e+00   \n",
            "\n",
            "      FpDensityMorgan2  FpDensityMorgan3  \n",
            "mean     -1.665335e-17          0.000000  \n",
            "std       1.025978e+00          1.025978  \n",
            "min      -1.311528e+00         -1.283802  \n",
            "max       2.526711e+00          2.400346  \n",
            "Detected key_col: ID\n",
            "Classic missing in old file: ['MolWt', 'ExactMolWt', 'HeavyAtomMolWt', 'HeavyAtomCount', 'NumValenceElectrons', 'TPSA', 'MolMR', 'NumHDonors', 'NHOHCount', 'NOCount', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'NumAliphaticRings', 'LabuteASA']\n",
            "Final feature count: 81\n",
            "Output path: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_03.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 写入data.py"
      ],
      "metadata": {
        "id": "zw0y_20d2Gy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "OLD_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_03.xlsx\"\n",
        "RESIDUAL_FEATURE_XLSX = OUTPUT_XLSX\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\", \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\", \"LabuteASA\", \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "\n",
        "def get_descriptor_map():\n",
        "    \"\"\"Return mapping of descriptor name -> function.\"\"\"\n",
        "    return {name: func for name, func in Descriptors._descList}\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = pd.read_excel(OLD_FEATURE_XLSX)\n",
        "\n",
        "    # Detect key column\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    # Detect SMILES column\n",
        "    if \"SMILES (L-isomer)\" in df.columns:\n",
        "        smiles_col = \"SMILES (L-isomer)\"\n",
        "    elif \"SMILES\" in df.columns:\n",
        "        smiles_col = \"SMILES\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing SMILES column: expected 'SMILES (L-isomer)' or 'SMILES'.\")\n",
        "\n",
        "    # Meta columns present in file\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", smiles_col]\n",
        "    meta_cols = [c for c in meta_candidates if c in df.columns]\n",
        "\n",
        "    # Compute missing classic descriptors\n",
        "    desc_map = get_descriptor_map()\n",
        "    classic_missing = [d for d in CLASSIC_DESC if d not in df.columns]\n",
        "\n",
        "    if classic_missing:\n",
        "        for d in classic_missing:\n",
        "            if d not in desc_map:\n",
        "                raise ValueError(f\"Descriptor '{d}' not found in RDKit Descriptors.\")\n",
        "\n",
        "        computed = {d: [] for d in classic_missing}\n",
        "        for _, row in df.iterrows():\n",
        "            smi = row.get(smiles_col, None)\n",
        "            mol = Chem.MolFromSmiles(smi) if isinstance(smi, str) else None\n",
        "            for d in classic_missing:\n",
        "                if mol is None:\n",
        "                    computed[d].append(np.nan)\n",
        "                else:\n",
        "                    try:\n",
        "                        computed[d].append(desc_map[d](mol))\n",
        "                    except Exception:\n",
        "                        computed[d].append(np.nan)\n",
        "\n",
        "        for d in classic_missing:\n",
        "            df[d] = computed[d]\n",
        "\n",
        "    # Drop rows with NaN in classic descriptors (after compute)\n",
        "    df = df.dropna(subset=CLASSIC_DESC, how=\"any\")\n",
        "\n",
        "    # Feature columns = all non-meta columns\n",
        "    feature_cols = [c for c in df.columns if c not in meta_cols]\n",
        "\n",
        "    # Remove NaN and constant feature columns\n",
        "    feat_df = df[feature_cols].copy()\n",
        "    feat_df = feat_df.dropna(axis=1, how=\"any\")\n",
        "    nunique = feat_df.nunique(axis=0)\n",
        "    feat_df = feat_df.loc[:, nunique > 1]\n",
        "\n",
        "    # Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(feat_df.values)\n",
        "    scaled_df = pd.DataFrame(scaled, columns=feat_df.columns, index=feat_df.index)\n",
        "\n",
        "    # Assemble output with meta + scaled features\n",
        "    out_df = pd.concat([df[meta_cols].reset_index(drop=True), scaled_df.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    # Sanity check for scaled features\n",
        "    stats = scaled_df.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n",
        "    print(\"Sanity check (first 10 features):\")\n",
        "    print(stats.iloc[:, :10])\n",
        "\n",
        "    # Print required info\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"Classic missing in old file:\", classic_missing)\n",
        "    print(\"Final feature count:\", scaled_df.shape[1])\n",
        "    print(\"Output path:\", OUTPUT_XLSX)\n",
        "\n",
        "    # Save\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "c7aT8gNZ2I5j",
        "outputId": "067f2154-4f97-46ee-c906-9d08cb44beff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "OLD_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_03.xlsx\"\n",
        "RESIDUAL_FEATURE_XLSX = OUTPUT_XLSX # Correctly define RESIDUAL_FEATURE_XLSX\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "POS_EMB_DIM = 8\n",
        "MAX_HOP = 2\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\", \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\", \"LabuteASA\", \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "\n",
        "def get_descriptor_map():\n",
        "    \"\"\"Return mapping of descriptor name -> function.\"\"\"\n",
        "    return {name: func for name, func in Descriptors._descList}\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: ID -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"Classic sinusoidal positional encoding.\"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # The main function in data.py is intended for descriptor processing,\n",
        "    # but here we're only defining the module functions/constants for import.\n",
        "    # So, this main() is commented out or removed if not needed for direct execution of data.py.\n",
        "    # For now, let's keep it to satisfy previous notebook logic, but ensure constants are top-level.\n",
        "\n",
        "    # Load residue feature table\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX) # This line will use the RESIDUAL_FEATURE_XLSX defined globally\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing residue key column: expected 'ID' or '1-Letter'\")\n",
        "\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    meta_cols = [c for c in meta_candidates if c in df_feat.columns]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    # These print statements are illustrative and would run if data.py is executed directly\n",
        "    print(df_feat[feature_cols].describe().loc[[\"mean\",\"std\",\"min\",\"max\"]].T.head(10))\n",
        "    absmax = df_feat[feature_cols].abs().max().sort_values(ascending=False)\n",
        "    print(\"\\nTop 10 features by |max|:\")\n",
        "    print(absmax.head(10))\n",
        "    nonzero_cnt = (df_feat[feature_cols].abs() > 1e-12).sum(axis=0).sort_values()\n",
        "    print(\"Non-zero count (smallest 20):\")\n",
        "    print(nonzero_cnt.head(20))\n",
        "    keep_cols = nonzero_cnt[nonzero_cnt >= 3].index.tolist()\n",
        "    print(\"Kept after sparsity filter:\", len(keep_cols))\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"Number of feature_cols:\", len(feature_cols))\n",
        "    print(\"Final node feature dim:\", len(feature_cols) + POS_EMB_DIM)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # feature_cols + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "print(\"Wrote:\", out_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mYJ3Mo6K4rGK",
        "outputId": "97e6840c-2ef5-4fa9-d985-ec717705221d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 21 classic，data.py"
      ],
      "metadata": {
        "id": "qy3QozVS816y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "OLD_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_04.xlsx\"\n",
        "RESIDUAL_FEATURE_XLSX = OUTPUT_XLSX\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "POS_EMB_DIM = 8\n",
        "MAX_HOP = 2\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\", \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\", \"LabuteASA\", \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "\n",
        "def get_descriptor_map():\n",
        "    \"\"\"Return mapping of descriptor name -> function.\"\"\"\n",
        "    return {name: func for name, func in Descriptors._descList}\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: ID -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"Classic sinusoidal positional encoding.\"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = pd.read_excel(OLD_FEATURE_XLSX)\n",
        "\n",
        "    # Detect key column\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    # Detect SMILES column\n",
        "    if \"SMILES (L-isomer)\" in df.columns:\n",
        "        smiles_col = \"SMILES (L-isomer)\"\n",
        "    elif \"SMILES\" in df.columns:\n",
        "        smiles_col = \"SMILES\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing SMILES column: expected 'SMILES (L-isomer)' or 'SMILES'.\")\n",
        "\n",
        "    # Meta columns to keep (only those that exist)\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", smiles_col]\n",
        "    meta_cols = [c for c in meta_candidates if c in df.columns]\n",
        "\n",
        "    # Compute classic descriptors (only if missing)\n",
        "    desc_map = get_descriptor_map()\n",
        "    classic_missing = [d for d in CLASSIC_DESC if d not in df.columns]\n",
        "\n",
        "    for d in classic_missing:\n",
        "        if d not in desc_map:\n",
        "            raise ValueError(f\"Descriptor '{d}' not found in RDKit Descriptors.\")\n",
        "\n",
        "    if classic_missing:\n",
        "        computed = {d: [] for d in classic_missing}\n",
        "        for _, row in df.iterrows():\n",
        "            smi = row.get(smiles_col, None)\n",
        "            mol = Chem.MolFromSmiles(smi) if isinstance(smi, str) else None\n",
        "            for d in classic_missing:\n",
        "                if mol is None:\n",
        "                    computed[d].append(np.nan)\n",
        "                else:\n",
        "                    try:\n",
        "                        computed[d].append(desc_map[d](mol))\n",
        "                    except Exception:\n",
        "                        computed[d].append(np.nan)\n",
        "        for d in classic_missing:\n",
        "            df[d] = computed[d]\n",
        "\n",
        "    # Keep only meta + classic descriptors\n",
        "    keep_cols = meta_cols + CLASSIC_DESC\n",
        "    missing_cols = [c for c in keep_cols if c not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing columns after compute: {missing_cols}\")\n",
        "\n",
        "    df_keep = df[keep_cols].copy()\n",
        "\n",
        "    # Drop rows with NaN in classic descriptors (after compute)\n",
        "    df_keep = df_keep.dropna(subset=CLASSIC_DESC, how=\"any\").reset_index(drop=True)\n",
        "\n",
        "    # Remove constant classic descriptors (rare, but safe)\n",
        "    classic_df = df_keep[CLASSIC_DESC].copy()\n",
        "    nunique = classic_df.nunique(axis=0)\n",
        "    kept_classic = [c for c in CLASSIC_DESC if nunique[c] > 1]\n",
        "\n",
        "    if len(kept_classic) == 0:\n",
        "        raise ValueError(\"All classic descriptors are constant after filtering. Nothing to scale/output.\")\n",
        "\n",
        "    classic_df = df_keep[kept_classic].copy()\n",
        "\n",
        "    # Standardize classic descriptors only\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(classic_df.values)\n",
        "    scaled_df = pd.DataFrame(scaled, columns=kept_classic)\n",
        "\n",
        "    # Assemble output: meta + scaled classic descriptors\n",
        "    out_df = pd.concat([df_keep[meta_cols], scaled_df], axis=1)\n",
        "\n",
        "    # Sanity check\n",
        "    stats = scaled_df.describe().loc[[\"mean\", \"std\", \"min\", \"max\"]]\n",
        "    print(\"Sanity check (scaled classic descriptors, first 10 cols):\")\n",
        "    print(stats.iloc[:, :10])\n",
        "\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"SMILES col:\", smiles_col)\n",
        "    print(\"Classic missing (computed):\", classic_missing)\n",
        "    print(\"Kept classic descriptors:\", len(kept_classic))\n",
        "    print(\"Dropped constant classic descriptors:\", [c for c in CLASSIC_DESC if c not in kept_classic])\n",
        "    print(\"Output path:\", OUTPUT_XLSX)\n",
        "\n",
        "    # Save\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYPasbLoFAcp",
        "outputId": "eb45fccd-cdbb-4496-be52-1ded8bf78c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check (scaled classic descriptors, first 10 cols):\n",
            "             MolWt    ExactMolWt  HeavyAtomMolWt  HeavyAtomCount  \\\n",
            "mean  4.163336e-16 -1.110223e-16    1.387779e-16   -2.720046e-16   \n",
            "std   1.025978e+00  1.025978e+00    1.025978e+00    1.025978e+00   \n",
            "min  -2.004112e+00 -2.004065e+00   -1.956531e+00   -1.865710e+00   \n",
            "max   1.994314e+00  1.994276e+00    2.055425e+00    2.234752e+00   \n",
            "\n",
            "      NumValenceElectrons          TPSA       MolLogP         MolMR  \\\n",
            "mean        -2.775558e-17  4.662937e-16 -4.440892e-17 -2.747802e-16   \n",
            "std          1.025978e+00  1.025978e+00  1.025978e+00  1.025978e+00   \n",
            "min         -2.045336e+00 -1.473122e+00 -1.754830e+00 -1.806483e+00   \n",
            "max          2.208963e+00  2.996839e+00  1.932503e+00  2.267138e+00   \n",
            "\n",
            "        NumHDonors  NumHAcceptors  \n",
            "mean  1.776357e-16  -4.440892e-17  \n",
            "std   1.025978e+00   1.025978e+00  \n",
            "min  -8.626622e-01  -1.093216e+00  \n",
            "max   3.450649e+00   2.030259e+00  \n",
            "Detected key_col: ID\n",
            "SMILES col: SMILES (L-isomer)\n",
            "Classic missing (computed): ['MolWt', 'ExactMolWt', 'HeavyAtomMolWt', 'HeavyAtomCount', 'NumValenceElectrons', 'TPSA', 'MolMR', 'NumHDonors', 'NHOHCount', 'NOCount', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'NumAliphaticRings', 'LabuteASA']\n",
            "Kept classic descriptors: 21\n",
            "Dropped constant classic descriptors: []\n",
            "Output path: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_04.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this one\n",
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, Subset\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "OLD_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_04.xlsx\"\n",
        "RESIDUAL_FEATURE_XLSX = OUTPUT_XLSX\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "POS_EMB_DIM = 8\n",
        "MAX_HOP = 2\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\", \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\", \"LabuteASA\", \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "\n",
        "def get_descriptor_map():\n",
        "    \"\"\"Return mapping of descriptor name -> function.\"\"\"\n",
        "    return {name: func for name, func in Descriptors._descList}\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: ID -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"Classic sinusoidal positional encoding.\"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = pd.read_excel(OLD_FEATURE_XLSX)\n",
        "\n",
        "    # Save\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [c for c in [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"] if c in df_feat.columns]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "print(\"Wrote:\", out_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O37E8gFI-Hwp",
        "outputId": "cc411d31-8ac2-4bb1-8bd9-5a8d89ce7fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote: /content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 计算描述符；80+加入经典descriptors"
      ],
      "metadata": {
        "id": "8N4Cixk0pwqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "RESIDUE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residual_dictionary.xlsx\"\n",
        "OUTPUT_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_02.xlsx\"\n",
        "HEATMAP_PNG = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation_02.png\"\n",
        "HEATMAP_PNG_FILTERED = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation_filtered_02.png\"\n",
        "\n",
        "CLASSIC_DESC = [\n",
        "    \"MolWt\", \"ExactMolWt\", \"HeavyAtomMolWt\", \"HeavyAtomCount\", \"NumValenceElectrons\",\n",
        "    \"TPSA\", \"MolLogP\", \"MolMR\",\n",
        "    \"NumHDonors\", \"NumHAcceptors\", \"NHOHCount\", \"NOCount\",\n",
        "    \"NumRotatableBonds\",\n",
        "    \"RingCount\", \"NumAromaticRings\", \"NumAliphaticRings\",\n",
        "    \"FractionCSP3\",\n",
        "    \"LabuteASA\",\n",
        "    \"BertzCT\", \"BalabanJ\", \"HallKierAlpha\"\n",
        "]\n",
        "\n",
        "TARGET_MIN = 70\n",
        "TARGET_MAX = 100\n",
        "\n",
        "\n",
        "def get_descriptor_functions():\n",
        "    \"\"\"Return list of (name, func) for all RDKit descriptors.\"\"\"\n",
        "    return Descriptors._descList\n",
        "\n",
        "\n",
        "def compute_all_descriptors(smiles, one_letter):\n",
        "    \"\"\"Compute all RDKit descriptors for a SMILES. Return dict or None if fail.\"\"\"\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        print(f\"[WARN] Failed to parse SMILES for {one_letter}: {smiles}\")\n",
        "        return None\n",
        "\n",
        "    desc_values = {}\n",
        "    for name, func in get_descriptor_functions():\n",
        "        try:\n",
        "            desc_values[name] = func(mol)\n",
        "        except Exception:\n",
        "            desc_values[name] = np.nan\n",
        "    return desc_values\n",
        "\n",
        "\n",
        "def remove_nan_and_constant_features(df):\n",
        "    \"\"\"Remove columns containing NaN or constant values.\"\"\"\n",
        "    df_clean = df.dropna(axis=1, how=\"any\")\n",
        "    nunique = df_clean.nunique(axis=0)\n",
        "    df_clean = df_clean.loc[:, nunique > 1]\n",
        "    return df_clean\n",
        "\n",
        "\n",
        "def correlation_filter(df, threshold=0.97, protected=None):\n",
        "    \"\"\"\n",
        "    Remove redundant features using Pearson correlation with protected whitelist.\n",
        "    Returns kept, dropped, warnings_list.\n",
        "    \"\"\"\n",
        "    if protected is None:\n",
        "        protected = set()\n",
        "\n",
        "    corr = df.corr(method=\"pearson\").abs()\n",
        "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
        "\n",
        "    dropped = set()\n",
        "    warnings_list = []\n",
        "\n",
        "    for col in upper.columns:\n",
        "        if col in dropped:\n",
        "            continue\n",
        "        high_corr = upper[col][upper[col] > threshold]\n",
        "        for row in high_corr.index:\n",
        "            if row in dropped:\n",
        "                continue\n",
        "\n",
        "            col_prot = col in protected\n",
        "            row_prot = row in protected\n",
        "\n",
        "            if col_prot and not row_prot:\n",
        "                dropped.add(row)\n",
        "            elif row_prot and not col_prot:\n",
        "                dropped.add(col)\n",
        "                break\n",
        "            elif not col_prot and not row_prot:\n",
        "                dropped.add(col)\n",
        "                break\n",
        "            else:\n",
        "                warnings_list.append((col, row, float(upper.loc[row, col])))\n",
        "\n",
        "    kept = [c for c in df.columns if c not in dropped]\n",
        "    return kept, sorted(list(dropped)), warnings_list\n",
        "\n",
        "\n",
        "def main():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "    # 1) Load residue dictionary\n",
        "    df = pd.read_excel(RESIDUE_excel_PATH)\n",
        "\n",
        "    standard_aa = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "    df = df[df[\"1-Letter\"].astype(str).str.strip().isin(standard_aa)].copy()\n",
        "    df[\"1-Letter\"] = df[\"1-Letter\"].astype(str).str.strip()\n",
        "    df = df.drop_duplicates(subset=[\"1-Letter\"], keep=\"first\")\n",
        "\n",
        "    required_cols = [\"1-Letter\", \"SMILES (L-isomer)\"]\n",
        "    for c in required_cols:\n",
        "        if c not in df.columns:\n",
        "            raise ValueError(f\"Missing required column: {c}\")\n",
        "\n",
        "    # 2) Compute descriptors for each residue\n",
        "    desc_list = []\n",
        "    aa_codes = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row.get(\"1-Letter\", \"\")).strip()\n",
        "        smiles = row.get(\"SMILES (L-isomer)\", \"\")\n",
        "\n",
        "        desc_values = compute_all_descriptors(smiles, one_letter)\n",
        "        if desc_values is None:\n",
        "            continue\n",
        "\n",
        "        aa_codes.append(one_letter)\n",
        "        desc_list.append(desc_values)\n",
        "\n",
        "    desc_df = pd.DataFrame(desc_list, index=aa_codes)\n",
        "    desc_df.index.name = \"1-Letter\"\n",
        "\n",
        "    # 3) Remove NaN and constant columns\n",
        "    desc_df = remove_nan_and_constant_features(desc_df)\n",
        "\n",
        "    # 4) Standardize features\n",
        "    scaler = StandardScaler()\n",
        "    scaled = scaler.fit_transform(desc_df.values)\n",
        "    scaled_df = pd.DataFrame(scaled, index=desc_df.index, columns=desc_df.columns)\n",
        "\n",
        "    # 5) Correlation heatmap (before filtering)\n",
        "    corr = scaled_df.corr(method=\"pearson\")\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    sns.heatmap(corr, cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Descriptor Correlation Heatmap (Before Filtering)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(HEATMAP_PNG, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 6) Auto choose threshold to keep 70-100 descriptors\n",
        "    thresholds = [round(x, 2) for x in np.arange(0.90, 1.00, 0.01)]\n",
        "    chosen_threshold = None\n",
        "    kept = None\n",
        "    dropped = None\n",
        "    warnings_list = None\n",
        "\n",
        "    protected = set(CLASSIC_DESC)\n",
        "    history = []\n",
        "\n",
        "    for t in thresholds:\n",
        "        k, d, w = correlation_filter(scaled_df, threshold=t, protected=protected)\n",
        "        history.append((t, len(k), k, d, w))\n",
        "        if TARGET_MIN <= len(k) <= TARGET_MAX:\n",
        "            chosen_threshold = t\n",
        "            kept, dropped, warnings_list = k, d, w\n",
        "            break\n",
        "\n",
        "    if kept is None:\n",
        "        if all(h[1] < TARGET_MIN for h in history):\n",
        "            chosen_threshold = None\n",
        "            kept = list(scaled_df.columns)\n",
        "            dropped = []\n",
        "            warnings_list = []\n",
        "        else:\n",
        "            t, _, k, d, w = history[0]\n",
        "            chosen_threshold = t\n",
        "            kept, dropped, warnings_list = k, d, w\n",
        "\n",
        "    selected_df = scaled_df[kept]\n",
        "\n",
        "    # Heatmap after filtering\n",
        "    corr_filtered = selected_df.corr(method=\"pearson\")\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(corr_filtered, cmap=\"coolwarm\", center=0)\n",
        "    plt.title(\"Descriptor Correlation Heatmap (After Filtering)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(HEATMAP_PNG_FILTERED, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # 7) Force add back CLASSIC_DESC if missing\n",
        "    missing_classic_early = [d for d in CLASSIC_DESC if d not in scaled_df.columns]\n",
        "    add_back = []\n",
        "    for d in CLASSIC_DESC:\n",
        "        if d in scaled_df.columns and d not in selected_df.columns:\n",
        "            selected_df[d] = scaled_df[d]\n",
        "            add_back.append(d)\n",
        "\n",
        "    # 8) Assemble final DataFrame (metadata + descriptors)\n",
        "    meta_df = pd.DataFrame({\n",
        "        \"ID\": df.get(\"1-Letter\"),\n",
        "        \"Name\": df.get(\"Name\"),\n",
        "        \"Type\": df.get(\"Type\"),\n",
        "        \"SMILES (L-isomer)\": df.get(\"SMILES (L-isomer)\"),\n",
        "    })\n",
        "\n",
        "    selected_df = selected_df.reset_index().rename(columns={\"1-Letter\": \"ID\"})\n",
        "    out_df = pd.merge(meta_df, selected_df, on=\"ID\", how=\"inner\")\n",
        "\n",
        "    # enforce column order\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    desc_cols = [c for c in out_df.columns if c not in meta_cols]\n",
        "    out_df = out_df[meta_cols + desc_cols]\n",
        "\n",
        "    # Save\n",
        "    out_df.to_excel(OUTPUT_XLSX, index=False)\n",
        "\n",
        "    # ---- Output info ----\n",
        "    print(\"Chosen threshold:\", chosen_threshold)\n",
        "    print(\"Final descriptor count:\", selected_df.shape[1])\n",
        "\n",
        "    classic_kept = [d for d in CLASSIC_DESC if d in selected_df.columns]\n",
        "    classic_missing = [d for d in CLASSIC_DESC if d not in selected_df.columns]\n",
        "\n",
        "    print(\"Classic kept:\", classic_kept)\n",
        "    print(\"Classic missing:\", classic_missing)\n",
        "\n",
        "    print(\"Dropped count:\", len(dropped))\n",
        "    print(\"Dropped (first 50):\", dropped[:50])\n",
        "\n",
        "    print(\"Protected-protected warnings:\", len(warnings_list))\n",
        "    if warnings_list:\n",
        "        print(\"Warnings (first 10):\", warnings_list[:10])\n",
        "\n",
        "    if missing_classic_early:\n",
        "        print(\"[WARN] Classic descriptors removed before filtering (NaN/constant):\", missing_classic_early)\n",
        "    if add_back:\n",
        "        print(\"[INFO] Added back classic descriptors:\", add_back)\n",
        "\n",
        "    # Save retained list\n",
        "    txt_path = os.path.join(os.path.dirname(OUTPUT_XLSX), \"retained_descriptors.txt\")\n",
        "    with open(txt_path, \"w\") as f:\n",
        "        f.write(f\"chosen_threshold: {chosen_threshold}\\n\")\n",
        "        f.write(f\"final_count: {selected_df.shape[1]}\\n\\n\")\n",
        "        f.write(\"kept:\\n\" + \"\\n\".join(list(selected_df.columns)) + \"\\n\\n\")\n",
        "        f.write(\"dropped:\\n\" + \"\\n\".join(dropped) + \"\\n\\n\")\n",
        "        f.write(\"classic_kept:\\n\" + \"\\n\".join(classic_kept) + \"\\n\\n\")\n",
        "        f.write(\"classic_missing:\\n\" + \"\\n\".join(classic_missing) + \"\\n\\n\")\n",
        "        f.write(\"warnings_list:\\n\" + \"\\n\".join([str(w) for w in warnings_list]) + \"\\n\")\n",
        "\n",
        "    print(f\"\\nSaved enhanced feature table to: {OUTPUT_XLSX}\")\n",
        "    print(f\"Saved correlation heatmap to: {HEATMAP_PNG}\")\n",
        "    print(f\"Saved filtered heatmap to: {HEATMAP_PNG_FILTERED}\")\n",
        "    print(f\"Saved retained_descriptors.txt to: {txt_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyGXieY6p4x2",
        "outputId": "c2c57570-5bf0-4313-9fbb-db4c06fc15f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.9.4-cp312-cp312-manylinux_2_28_x86_64.whl (36.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.6/36.6 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.4\n",
            "Chosen threshold: 0.9\n",
            "Final descriptor count: 80\n",
            "Classic kept: ['MolWt', 'ExactMolWt', 'HeavyAtomMolWt', 'HeavyAtomCount', 'NumValenceElectrons', 'TPSA', 'MolLogP', 'MolMR', 'NumHDonors', 'NumHAcceptors', 'NHOHCount', 'NOCount', 'NumRotatableBonds', 'RingCount', 'NumAromaticRings', 'NumAliphaticRings', 'FractionCSP3', 'LabuteASA', 'BertzCT', 'BalabanJ', 'HallKierAlpha']\n",
            "Classic missing: []\n",
            "Dropped count: 65\n",
            "Dropped (first 50): ['BCUT2D_CHGLO', 'BCUT2D_LOGPHI', 'BCUT2D_MRHI', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v', 'Ipc', 'Kappa1', 'Kappa2', 'MaxAbsEStateIndex', 'MaxAbsPartialCharge', 'MaxEStateIndex', 'MinAbsPartialCharge', 'NumAliphaticHeterocycles', 'NumAmideBonds', 'NumAromaticCarbocycles', 'NumHeteroatoms', 'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumUnspecifiedAtomStereoCenters', 'PEOE_VSA1', 'PEOE_VSA4', 'Phi', 'SMR_VSA2', 'SMR_VSA7', 'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA5', 'SlogP_VSA6', 'VSA_EState10', 'VSA_EState2', 'VSA_EState4', 'VSA_EState6', 'VSA_EState7', 'fr_Al_COO', 'fr_Al_OH_noTert', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH']\n",
            "Protected-protected warnings: 27\n",
            "Warnings (first 10): [('HeavyAtomMolWt', 'MolWt', 0.9978842824068737), ('ExactMolWt', 'MolWt', 0.9999997394559419), ('ExactMolWt', 'HeavyAtomMolWt', 0.9978837159791137), ('NumValenceElectrons', 'MolWt', 0.9868428558339233), ('NumValenceElectrons', 'HeavyAtomMolWt', 0.978441340297732), ('NumValenceElectrons', 'ExactMolWt', 0.9869355596535623), ('LabuteASA', 'MolWt', 0.9916294629045618), ('LabuteASA', 'HeavyAtomMolWt', 0.9869457168402086), ('LabuteASA', 'ExactMolWt', 0.9916385350581864), ('LabuteASA', 'NumValenceElectrons', 0.9853977900413546)]\n",
            "\n",
            "Saved enhanced feature table to: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_02.xlsx\n",
            "Saved correlation heatmap to: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation_02.png\n",
            "Saved filtered heatmap to: /content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_correlation_filtered_02.png\n",
            "Saved retained_descriptors.txt to: /content/drive/MyDrive/master_thesis/sampled_data_5000/retained_descriptors.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.residuals to peptides sequence, build PyG data, split data"
      ],
      "metadata": {
        "id": "8WG7DaET1UmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 直接跑data.py 文件\n",
        "\n",
        "# === 这部分不写入py文件里 ====\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residual_features.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_1000_splits_train-test-val.xlsx\"\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: 1-letter -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"1-Letter\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"1-Letter\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for aa in seq:\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "        node_features.append(residue_feat_dict[aa])\n",
        "\n",
        "    x = torch.tensor(node_features, dtype=torch.float)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges between adjacent residues (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        for i in range(num_residues - 1):\n",
        "            edge_index_list.append([i, i + 1])\n",
        "            edge_index_list.append([i + 1, i])\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    y = torch.tensor([label], dtype=torch.long)\n",
        "    return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    # Train 70%, temp 30%\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices, labels, test_size=0.30, random_state=seed, stratify=labels\n",
        "    )\n",
        "\n",
        "    # Val 15%, Test 15% (split temp 50/50)\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx, y_temp, test_size=0.50, random_state=seed, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    feature_cols = [\n",
        "        \"mw\", \"logp\", \"tpsa\", \"hbd\", \"hba\",\n",
        "        \"har\", \"aro\", \"aliph\", \"rot\", \"frac_csp3\",\n",
        "        \"is_pos\", \"is_neg\", \"is_aro\",\n",
        "    ]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQWG0almKhul",
        "outputId": "c525fe39-24d7-4d18-bb49-08c9d7f16393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.9.3-cp312-cp312-manylinux_2_28_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.3\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2+pt23cu121 torch-sparse-0.6.18+pt23cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n",
            "  import torch_geometric.typing\n",
            "/tmp/ipython-input-4206543378.py:61: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  x = torch.tensor(node_features, dtype=torch.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of peptides in dataset: 1000\n",
            "Data(x=[20, 13], edge_index=[2, 38], y=[1])\n",
            "num_nodes: 20\n",
            "num_edges: 38\n",
            "feature_dim: 13\n",
            "label: 0\n",
            "Train size: 700\n",
            "Val size: 150\n",
            "Test size: 150\n",
            "Train size ratio: 0.7\n",
            "Val size ratio: 0.15\n",
            "Test size ratio: 0.15\n",
            "Train: total=700, pos=144 (0.206), neg=556 (0.794)\n",
            "Val: total=150, pos=31 (0.207), neg=119 (0.793)\n",
            "Test: total=150, pos=31 (0.207), neg=119 (0.793)\n",
            "Batch x shape: torch.Size([507, 13])\n",
            "Batch num_graphs: 32\n",
            "Batch y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 写入data.py文件/二维one-hot，hop2"
      ],
      "metadata": {
        "id": "vFwIJIwdAH8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: ID -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "# 绝对位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # 66 + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FbqWYgl1AHbQ",
        "outputId": "28bf8fb9-b594-46a7-dd4b-4f23718697af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01 改进 edge_attr：使用真实的序列距离"
      ],
      "metadata": {
        "id": "RE3aaIsWDFS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    df = read_table(residual_feature_path)\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    # 只保留数值特征列\n",
        "    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if not numeric_cols:\n",
        "        raise ValueError(\"No numeric feature columns found after filtering.\")\n",
        "\n",
        "    required_cols = [key_col] + numeric_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[key_col]).strip()\n",
        "        feat_vec = row[numeric_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "\n",
        "# 绝对位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # 修改部分\n",
        "\n",
        "                    # 改进逻辑：\n",
        "                    # 第一维使用 1/hop，代表相互作用的强度（hop越大，值越小，模拟能量衰减）\n",
        "                    # 第二维保留 hop 的原始数值，让模型直接知道跨度\n",
        "                    strength = 1.0 / hop\n",
        "                    dist_info = float(hop)\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "\n",
        "                    #修改部分\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    meta_cols = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # 66 + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    # save split datasets\n",
        "    save_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    torch.save({\"data_list\": [dataset[i] for i in train_dataset.indices]},\n",
        "               os.path.join(save_dir, \"peptide_graphs_train.pt\"))\n",
        "    torch.save({\"data_list\": [dataset[i] for i in val_dataset.indices]},\n",
        "               os.path.join(save_dir, \"peptide_graphs_val.pt\"))\n",
        "    torch.save({\"data_list\": [dataset[i] for i in test_dataset.indices]},\n",
        "               os.path.join(save_dir, \"peptide_graphs_test.pt\"))\n",
        "\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nvk_g7AWDFtN",
        "outputId": "a79045ea-1fdd-4a62-f67d-cceb2d9c9766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ✅01 保存已分好的数据集"
      ],
      "metadata": {
        "id": "jdF2S9weomV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zCFV4yHpvaT",
        "outputId": "c44cf6ee-0640-4ec1-b04a-072c9ab262f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "01_DATA  02_MODEL  data.py  __pycache__  training_records.gsheet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use free aa to calculate the descriptors\n",
        "# task: transform peptide sequence to graph data\n",
        "# all 5000\n",
        "\n",
        "'''\n",
        "这段代码完成了一个完整的数据预处理流水线（Pipeline）：\n",
        "输入：氨基酸特征表 + 带有序列和标签的实验数据表。\n",
        "处理：查表获取特征 - 计算位置编码 - 构建图拓扑结构 - 划分数据集。\n",
        "输出：可直接用于 PyG (PyTorch Geometric) 模型训练的 DataLoader\n",
        "'''\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\" # 66 descriptors\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "############ 1. 基础数据读取与准备 ##########################################################\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "# 从 Excel 中读取预先计算好的氨基酸描述符（如疏水性、电荷、分子量等）。\n",
        "# 将这些特征存储在一个字典里，键是氨基酸的单字母代码（如 'A', 'R'），值是对应的数值向量。\n",
        "# 作用：在后续构建图节点时，通过这个字典快速查找每个氨基酸的“物理化学身份证”。\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols): # 构建“氨基酸-特征”字典\n",
        "    df = read_table(residual_feature_path)\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if not numeric_cols:\n",
        "        raise ValueError(\"No numeric feature columns found after filtering.\")\n",
        "\n",
        "    required_cols = [key_col] + numeric_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[key_col]).strip()\n",
        "        feat_vec = row[numeric_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "############ 2. 特征工程与图构建 ##########################################################\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model): # positional embedding, 生成正弦位置编码;\n",
        "# 意义：在图中，节点本身不包含顺序信息。为了让模型知道某个氨基酸是在序列的开头、中间还是结尾，我们引入了类似 Transformer 的位置编码。\n",
        "# 作用：将位置序号（0, 1, 2...）转换为一个高维向量。\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "# 功能：这是最核心的函数，将一条字符串序列转为一个 torch_geometric.data.Data 图对象\n",
        "# 逻辑：\n",
        "# 节点 (Nodes)：每个氨基酸是一个节点。节点的特征 = 物理化学特征 + 位置编码\n",
        "# 边 (Edges)：根据 MAX_HOP（跳数）连接节点。如果 MAX_HOP=2，则氨基酸 i 不仅与相邻的 i+1 连边，还与 i+2 连边。\n",
        "# 边属性 (Edge Attributes)：记录边的“强度”（距离越远强度越低，即 1/hop）和实际距离。\n",
        "# 意义：它定义了多肽在空间或逻辑上的连接方式\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    strength = 1.0 / hop\n",
        "                    dist_info = float(hop)\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([strength, dist_info]) # 强度，位置距离\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "############ 3. 数据集封装与加载 ##########################################################\n",
        "\n",
        "# 功能：自定义 PyTorch 数据集类\n",
        "# 它是原始 Excel 表格与深度学习模型之间的桥梁。\n",
        "# 在初始化时，它会遍历整个 Excel 表，调用 seq_to_graph_data 把每一条序列转换成图，并存储在 data_list 中。\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "# 功能：数据集切分。\n",
        "# 将总数据按 70% 训练 (Train)、15% 验证 (Val)、15% 测试 (Test) 的比例分开。\n",
        "# 使用 stratify=labels 进行分层抽样，确保三个子集中正负样本的比例与原始数据一致，防止模型因样本分布不均而产生偏差。\n",
        "def split_dataset(dataset, seed=42):\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "# 功能：创建数据加载器（DataLoader）\n",
        "# 将数据集打包成一个个 batch（批次）。在训练时，模型不是一次看一条数据，而是同时看 32 条（batch_size=32），这能加速计算并使梯度下降更稳定。\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# 统计报告。\n",
        "# 打印每个数据集中有多少个样本、多少正样本、多少负样本。这是一个良好的实验习惯，用于检查数据分布是否正常。\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    meta_cols = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "\n",
        "    # 2. 处理多肽序列数据集（加入去重步奏）\n",
        "    df_peptide = read_table(PEPTIDE_excel_PATH)\n",
        "    seq_col = \"aa_seq\" if \"aa_seq\" in df_peptide.columns else \"sequence\"\n",
        "\n",
        "    # --- 去重操作 ---\n",
        "    initial_len = len(df_peptide)\n",
        "    df_peptide = df_peptide.drop_duplicates(subset=[seq_col], keep='first').reset_index(drop=True)\n",
        "    final_len = len(df_peptide)\n",
        "\n",
        "    if initial_len > final_len:\n",
        "        print(f\"✅ 已删除 {initial_len - final_len} 条重复序列，剩余 {final_len} 条。\")\n",
        "    else:\n",
        "        print(f\"✅ 未发现重复序列，共有 {final_len} 条。\")\n",
        "    # ----------------\n",
        "\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    save_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_list = [dataset[i] for i in train_dataset.indices]\n",
        "    val_list = [dataset[i] for i in val_dataset.indices]\n",
        "    test_list = [dataset[i] for i in test_dataset.indices]\n",
        "\n",
        "    torch.save({\"data_list\": train_list}, os.path.join(save_dir, \"peptide_graphs_train.pt\"))\n",
        "    torch.save({\"data_list\": val_list}, os.path.join(save_dir, \"peptide_graphs_val.pt\"))\n",
        "    torch.save({\"data_list\": test_list}, os.path.join(save_dir, \"peptide_graphs_test.pt\"))\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeEdSP1oomGe",
        "outputId": "00d442d5-b068-455c-880f-992df2a38c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
            "Requirement already satisfied: torch==2.3.0+cu121 in /usr/local/lib/python3.12/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.9.86)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "✅ 已删除 4 条重复序列，剩余 4996 条。\n",
            "Number of peptides in dataset: 5000\n",
            "MAX_HOP: 2\n",
            "Data(x=[12, 74], edge_index=[2, 42], edge_attr=[42, 2], y=[1])\n",
            "num_nodes: 12\n",
            "num_edges: 42\n",
            "feature_dim: 74\n",
            "label: 0.0\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "Train size ratio: 0.7\n",
            "Val size ratio: 0.15\n",
            "Test size ratio: 0.15\n",
            "Train: total=3500, pos=723 (0.207), neg=2777 (0.793)\n",
            "Val: total=750, pos=155 (0.207), neg=595 (0.793)\n",
            "Test: total=750, pos=155 (0.207), neg=595 (0.793)\n",
            "Batch x shape: torch.Size([478, 74])\n",
            "Batch num_graphs: 32\n",
            "Batch y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-去重后数据 4996"
      ],
      "metadata": {
        "id": "ipTkHT6TZyx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use free aa to calculate the descriptors\n",
        "# task: transform peptide sequence to graph data\n",
        "\n",
        "\n",
        "'''\n",
        "这段代码完成了一个完整的数据预处理流水线（Pipeline）：\n",
        "输入：氨基酸特征表 + 带有序列和标签的实验数据表。\n",
        "处理：查表获取特征 - 计算位置编码 - 构建图拓扑结构 - 划分数据集。\n",
        "输出：可直接用于 PyG (PyTorch Geometric) 模型训练的 DataLoader\n",
        "'''\n",
        "\n",
        "\n",
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\" # 66 descriptors\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "############ 1. 基础数据读取与准备 ##########################################################\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "# 从 Excel 中读取预先计算好的氨基酸描述符（如疏水性、电荷、分子量等）。\n",
        "# 将这些特征存储在一个字典里，键是氨基酸的单字母代码（如 'A', 'R'），值是对应的数值向量。\n",
        "# 作用：在后续构建图节点时，通过这个字典快速查找每个氨基酸的“物理化学身份证”。\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols): # 构建“氨基酸-特征”字典\n",
        "    df = read_table(residual_feature_path)\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if not numeric_cols:\n",
        "        raise ValueError(\"No numeric feature columns found after filtering.\")\n",
        "\n",
        "    required_cols = [key_col] + numeric_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[key_col]).strip()\n",
        "        feat_vec = row[numeric_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "############ 2. 特征工程与图构建 ##########################################################\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model): # positional embedding, 生成正弦位置编码;\n",
        "# 意义：在图中，节点本身不包含顺序信息。为了让模型知道某个氨基酸是在序列的开头、中间还是结尾，我们引入了类似 Transformer 的位置编码。\n",
        "# 作用：将位置序号（0, 1, 2...）转换为一个高维向量。\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "# 功能：这是最核心的函数，将一条字符串序列转为一个 torch_geometric.data.Data 图对象\n",
        "# 逻辑：\n",
        "# 节点 (Nodes)：每个氨基酸是一个节点。节点的特征 = 物理化学特征 + 位置编码\n",
        "# 边 (Edges)：根据 MAX_HOP（跳数）连接节点。如果 MAX_HOP=2，则氨基酸 i 不仅与相邻的 i+1 连边，还与 i+2 连边。\n",
        "# 边属性 (Edge Attributes)：记录边的“强度”（距离越远强度越低，即 1/hop）和实际距离。\n",
        "# 意义：它定义了多肽在空间或逻辑上的连接方式\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    strength = 1.0 / hop\n",
        "                    dist_info = float(hop)\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([strength, dist_info]) # 强度，位置距离\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "############ 3. 数据集封装与加载 ##########################################################\n",
        "\n",
        "# 功能：自定义 PyTorch 数据集类\n",
        "# 它是原始 Excel 表格与深度学习模型之间的桥梁。\n",
        "# 在初始化时，它会遍历整个 Excel 表，调用 seq_to_graph_data 把每一条序列转换成图，并存储在 data_list 中。\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    # 修改 init，增加一个 dataframe 参数\n",
        "    def __init__(self, peptide_df, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_df = peptide_df  # 直接存储传入的 dataframe\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        # 不再 read_table，而是直接使用 self.peptide_df\n",
        "        df = self.peptide_df\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            # ... 下面的解析逻辑保持不变 ...\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "            # ... 后面转换图数据的代码 ...\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "# 功能：数据集切分。\n",
        "# 将总数据按 70% 训练 (Train)、15% 验证 (Val)、15% 测试 (Test) 的比例分开。\n",
        "# 使用 stratify=labels 进行分层抽样，确保三个子集中正负样本的比例与原始数据一致，防止模型因样本分布不均而产生偏差。\n",
        "def split_dataset(dataset, seed=42):\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "# 功能：创建数据加载器（DataLoader）\n",
        "# 将数据集打包成一个个 batch（批次）。在训练时，模型不是一次看一条数据，而是同时看 32 条（batch_size=32），这能加速计算并使梯度下降更稳定。\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# 统计报告。\n",
        "# 打印每个数据集中有多少个样本、多少正样本、多少负样本。这是一个良好的实验习惯，用于检查数据分布是否正常。\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    meta_cols = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "\n",
        "    # 1. 先读取并去重\n",
        "    df_peptide = read_table(PEPTIDE_excel_PATH)\n",
        "    initial_len = len(df_peptide)\n",
        "    df_peptide = df_peptide.drop_duplicates(subset=[\"aa_seq\"], keep='first').reset_index(drop=True)\n",
        "\n",
        "    print(f\"📊 数据清洗: 原始 {initial_len} 条 -> 去重后 {len(df_peptide)} 条\")\n",
        "\n",
        "    # 2. 传入去重后的 dataframe 而不是文件路径\n",
        "    dataset = PeptideResidueDataset(df_peptide, residue_feat_dict)\n",
        "\n",
        "    # 3. 此时 len(dataset) 应该就会显示 4996 了\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    save_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/Cleaned_data_00\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    train_list = [dataset[i] for i in train_dataset.indices]\n",
        "    val_list = [dataset[i] for i in val_dataset.indices]\n",
        "    test_list = [dataset[i] for i in test_dataset.indices]\n",
        "\n",
        "    torch.save({\"data_list\": train_list}, os.path.join(save_dir, \"cleaned_hop2_train.pt\"))\n",
        "    torch.save({\"data_list\": val_list}, os.path.join(save_dir, \"cleaned_hop2_val.pt\"))\n",
        "    torch.save({\"data_list\": test_list}, os.path.join(save_dir, \"cleaned_hop2_test.pt\"))\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZg452DjZ666",
        "outputId": "8ed5b3a0-e7a1-481e-abdf-2534db940ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 数据清洗: 原始 5000 条 -> 去重后 4996 条\n",
            "Number of peptides in dataset: 4996\n",
            "MAX_HOP: 2\n",
            "Data(x=[12, 74], edge_index=[2, 42], edge_attr=[42, 2], y=[1])\n",
            "num_nodes: 12\n",
            "num_edges: 42\n",
            "feature_dim: 74\n",
            "label: 0.0\n",
            "Train size: 3497\n",
            "Val size: 749\n",
            "Test size: 750\n",
            "Train size ratio: 0.6999599679743795\n",
            "Val size ratio: 0.14991993594875902\n",
            "Test size ratio: 0.1501200960768615\n",
            "Train: total=3497, pos=723 (0.207), neg=2774 (0.793)\n",
            "Val: total=749, pos=155 (0.207), neg=594 (0.793)\n",
            "Test: total=750, pos=155 (0.207), neg=595 (0.793)\n",
            "Batch x shape: torch.Size([526, 74])\n",
            "Batch num_graphs: 32\n",
            "Batch y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "检查数据集pt格式"
      ],
      "metadata": {
        "id": "DEmV-Wj0tuah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "pt_path = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/peptide_graphs_train.pt\"  # 改成你的路径\n",
        "obj = torch.load(pt_path, map_location=\"cpu\")\n",
        "\n",
        "print(\"Type:\", type(obj))\n",
        "\n",
        "# 1) 如果是 dict（最常见：state_dict / dataset cache / split idx）\n",
        "if isinstance(obj, dict):\n",
        "    print(\"Dict keys (top 30):\", list(obj.keys())[:30])\n",
        "\n",
        "    # 1a) 可能是 model state_dict（键像 layer.weight / layer.bias）\n",
        "    sample_keys = list(obj.keys())[:10]\n",
        "    if any(isinstance(k, str) and (\"weight\" in k or \"bias\" in k) for k in sample_keys):\n",
        "        print(\"Looks like: model state_dict\")\n",
        "\n",
        "    # 1b) 可能是 PyG InMemoryDataset cache（常见 keys: 'data', 'slices'）\n",
        "    if \"data\" in obj and \"slices\" in obj:\n",
        "        print(\"Looks like: PyG InMemoryDataset cache (data + slices)\")\n",
        "        print(\"data type:\", type(obj[\"data\"]))\n",
        "        print(\"slices type:\", type(obj[\"slices\"]))\n",
        "\n",
        "# 2) 如果是 list/tuple（常见：list[Data]）\n",
        "elif isinstance(obj, (list, tuple)):\n",
        "    print(\"Length:\", len(obj))\n",
        "    if len(obj) > 0:\n",
        "        print(\"First element type:\", type(obj[0]))\n",
        "        first = obj[0]\n",
        "        # 如果是 PyG Data，通常有 x/edge_index/y 等属性\n",
        "        for attr in [\"x\", \"edge_index\", \"edge_attr\", \"y\", \"batch\"]:\n",
        "            if hasattr(first, attr):\n",
        "                val = getattr(first, attr)\n",
        "                try:\n",
        "                    print(f\"first.{attr}.shape =\", tuple(val.shape))\n",
        "                except Exception:\n",
        "                    print(f\"first.{attr} =\", val)\n",
        "\n",
        "# 3) 其他类型（少见）\n",
        "else:\n",
        "    print(\"Object repr:\", repr(obj)[:500])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76O7yWfrtrLA",
        "outputId": "66db42b1-346a-4eec-d710-352d18c8838b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type: <class 'dict'>\n",
            "Dict keys (top 30): ['data_list']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj = torch.load(pt_path, map_location=\"cpu\")\n",
        "data_list = obj[\"data_list\"]\n",
        "\n",
        "print(type(data_list))\n",
        "print(\"len:\", len(data_list))\n",
        "\n",
        "first = data_list[0]\n",
        "print(\"first type:\", type(first))\n",
        "\n",
        "# 如果是 PyG Data，通常有这些属性\n",
        "for attr in [\"x\", \"edge_index\", \"edge_attr\", \"y\", \"batch\"]:\n",
        "    if hasattr(first, attr):\n",
        "        val = getattr(first, attr)\n",
        "        try:\n",
        "            print(f\"first.{attr}.shape =\", tuple(val.shape))\n",
        "        except Exception:\n",
        "            print(f\"first.{attr} =\", val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3m8ZS6luNSa",
        "outputId": "82ef0b75-a2fa-4588-fd02-4583157094db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "len: 3500\n",
            "first type: <class 'torch_geometric.data.data.Data'>\n",
            "first.x.shape = (20, 74)\n",
            "first.edge_index.shape = (2, 74)\n",
            "first.edge_attr.shape = (74, 2)\n",
            "first.y.shape = (1,)\n",
            "first.batch = None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2KhGxHOBuM-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    df = read_table(residual_feature_path)\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    # 只保留数值特征列\n",
        "    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
        "    if not numeric_cols:\n",
        "        raise ValueError(\"No numeric feature columns found after filtering.\")\n",
        "\n",
        "    required_cols = [key_col] + numeric_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[key_col]).strip()\n",
        "        feat_vec = row[numeric_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "\n",
        "# 绝对位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # 修改部分\n",
        "\n",
        "                    # 改进逻辑：\n",
        "                    # 第一维使用 1/hop，代表相互作用的强度（hop越大，值越小，模拟能量衰减）\n",
        "                    # 第二维保留 hop 的原始数值，让模型直接知道跨度\n",
        "                    strength = 1.0 / hop\n",
        "                    dist_info = float(hop)\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([strength, dist_info])\n",
        "\n",
        "                    #修改部分\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing key column: expected 'ID' or '1-Letter'.\")\n",
        "\n",
        "    meta_cols = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # 66 + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "id": "Ge-D24dzOkv_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "ba2e0024-64ca-4f01-ff59-767bb255917c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-1531775167.py, line 281)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1531775167.py\"\u001b[0;36m, line \u001b[0;32m281\u001b[0m\n\u001b[0;31m    '''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### ✅ 66+8+morgan fp， 5000"
      ],
      "metadata": {
        "id": "A8TJ9ZDBv7oP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "diff --git a//Users/yaoyufan/Library/CloudStorage/GoogleDrive-yufanyao426@gmail.com/My Drive/master_thesis/sampled_data_5000/compute_residue_morgan_fps.py b//Users/yaoyufan/Library/CloudStorage/GoogleDrive-yufanyao426@gmail.com/My Drive/master_thesis/sampled_data_5000/compute_residue_morgan_fps.py\n",
        "new file mode 100644\n",
        "--- /dev/null\n",
        "+++ b//Users/yaoyufan/Library/CloudStorage/GoogleDrive-yufanyao426@gmail.com/My Drive/master_thesis/sampled_data_5000/compute_residue_morgan_fps.py\n",
        "@@ -0,0 +1,113 @@\n",
        "+#!/usr/bin/env python3\n",
        "+# -*- coding: utf-8 -*-\n",
        "+import argparse\n",
        "+import os\n",
        "+import sys\n",
        "+\n",
        "+import numpy as np\n",
        "+import pandas as pd\n",
        "+from rdkit import Chem, DataStructs\n",
        "+from rdkit.Chem import AllChem\n",
        "+\n",
        "+\n",
        "+def morgan_fp_array(smiles, radius=2, nbits=512):\n",
        "+    mol = Chem.MolFromSmiles(smiles)\n",
        "+    if mol is None:\n",
        "+        return np.zeros((nbits,), dtype=int)\n",
        "+    bitvect = AllChem.GetMorganFingerprintAsBitVect(\n",
        "+        mol, radius=radius, nBits=nbits\n",
        "+    )\n",
        "+    arr = np.zeros((nbits,), dtype=int)\n",
        "+    DataStructs.ConvertToNumpyArray(bitvect, arr)\n",
        "+    return arr\n",
        "+\n",
        "+\n",
        "+def build_residue_fp_dict(df, smiles_col, one_letter_col, radius=2, nbits=512):\n",
        "+    residue_fps = {}\n",
        "+    failed = 0\n",
        "+    for idx, row in df.iterrows():\n",
        "+        one_letter = str(row[one_letter_col]).strip()\n",
        "+        smi = row[smiles_col]\n",
        "+        if pd.isna(smi) or str(smi).strip() == \"\":\n",
        "+            fp = np.zeros((nbits,), dtype=int)\n",
        "+            failed += 1\n",
        "+        else:\n",
        "+            fp = morgan_fp_array(str(smi).strip(), radius=radius, nbits=nbits)\n",
        "+            if not fp.any():\n",
        "+                failed += 1\n",
        "+        residue_fps[one_letter] = fp\n",
        "+    return residue_fps, failed\n",
        "+\n",
        "+\n",
        "+def main():\n",
        "+    parser = argparse.ArgumentParser(\n",
        "+        description=\"Compute Morgan fingerprints for residue SMILES.\"\n",
        "+    )\n",
        "+    parser.add_argument(\n",
        "+        \"xlsx_path\",\n",
        "+        help=\"Input Excel file path (residual_dictionary.xlsx)\",\n",
        "+    )\n",
        "+    parser.add_argument(\n",
        "+        \"--smiles-col\",\n",
        "+        default=\"SMILES (L-isomer)\",\n",
        "+        help=\"Column name for SMILES\",\n",
        "+    )\n",
        "+    parser.add_argument(\n",
        "+        \"--one-letter-col\",\n",
        "+        default=\"1-Letter\",\n",
        "+        help=\"Column name for 1-Letter code\",\n",
        "+    )\n",
        "+    parser.add_argument(\"--radius\", type=int, default=2, help=\"Morgan radius\")\n",
        "+    parser.add_argument(\"--nbits\", type=int, default=512, help=\"Fingerprint size\")\n",
        "+    parser.add_argument(\n",
        "+        \"--out-xlsx\",\n",
        "+        default=None,\n",
        "+        help=\"Output Excel path (default adds suffix to input filename)\",\n",
        "+    )\n",
        "+    args = parser.parse_args()\n",
        "+\n",
        "+    xlsx_path = os.path.abspath(args.xlsx_path)\n",
        "+    if not os.path.exists(xlsx_path):\n",
        "+        raise FileNotFoundError(f\"Input file not found: {xlsx_path}\")\n",
        "+\n",
        "+    df = pd.read_excel(xlsx_path)\n",
        "+    for col in (args.smiles_col, args.one_letter_col):\n",
        "+        if col not in df.columns:\n",
        "+            raise ValueError(f\"Missing required column: {col}\")\n",
        "+\n",
        "+    residue_fps, failed = build_residue_fp_dict(\n",
        "+        df,\n",
        "+        smiles_col=args.smiles_col,\n",
        "+        one_letter_col=args.one_letter_col,\n",
        "+        radius=int(args.radius),\n",
        "+        nbits=int(args.nbits),\n",
        "+    )\n",
        "+\n",
        "+    fp_columns = [f\"morgan_r{args.radius}_b{args.nbits}_{i}\" for i in range(args.nbits)]\n",
        "+    fp_rows = [residue_fps[str(code).strip()].tolist() for code in df[args.one_letter_col]]\n",
        "+    fp_df = pd.DataFrame(fp_rows, columns=fp_columns)\n",
        "+    out_df = pd.concat([df.reset_index(drop=True), fp_df], axis=1)\n",
        "+\n",
        "+    if args.out_xlsx:\n",
        "+        out_path = args.out_xlsx\n",
        "+    else:\n",
        "+        base_dir = os.path.dirname(xlsx_path)\n",
        "+        stem, ext = os.path.splitext(os.path.basename(xlsx_path))\n",
        "+        out_path = os.path.join(\n",
        "+            base_dir, f\"{stem}_morgan_r{args.radius}_b{args.nbits}{ext}\"\n",
        "+        )\n",
        "+    out_df.to_excel(out_path, index=False)\n",
        "+\n",
        "+    total_rows = len(df)\n",
        "+    success_rows = total_rows - failed\n",
        "+    print(\n",
        "+        f\"[OK] Wrote output: {out_path}\\n\"\n",
        "+        f\"[INFO] Total rows: {total_rows} | Success: {success_rows} | Failed: {failed}\"\n",
        "+    )\n",
        "+\n",
        "+    # Keep dict in memory for downstream imports if needed.\n",
        "+    return residue_fps\n",
        "+\n",
        "+\n",
        "+if __name__ == \"__main__\":\n",
        "+    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "pAgl4cm3wAZ9",
        "outputId": "d4d8a0bd-5f21-49ba-e57c-bcc762cf9d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: colab_kernel_launcher.py [-h] [--smiles-col SMILES_COL]\n",
            "                                [--one-letter-col ONE_LETTER_COL]\n",
            "                                [--radius RADIUS] [--nbits NBITS]\n",
            "                                [--out-xlsx OUT_XLSX]\n",
            "                                [xlsx_path]\n",
            "colab_kernel_launcher.py: error: unrecognized arguments: -f\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 80descriptors"
      ],
      "metadata": {
        "id": "8eBGVX_9syk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_02.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict using key column (ID or 1-Letter).\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing residue key column: expected 'ID' or '1-Letter'\")\n",
        "\n",
        "    required_cols = [key_col] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        key = str(row[key_col]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[key] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "# 位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    print(df_feat[feature_cols].describe().loc[[\"mean\",\"std\",\"min\",\"max\"]].T.head(10))\n",
        "\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing residue key column: expected 'ID' or '1-Letter'\")\n",
        "\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    meta_cols = [c for c in meta_candidates if c in df_feat.columns]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "    print(df_feat[feature_cols].describe().loc[[\"mean\",\"std\",\"min\",\"max\"]].T.head(10))\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"Number of feature_cols:\", len(feature_cols))\n",
        "    print(\"Final node feature dim:\", len(feature_cols) + POS_EMB_DIM)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # feature_cols + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DwOavwmNs2Us",
        "outputId": "a1495c87-e442-4d26-ba94-c253ef3fda8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced_02.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict using key column (ID or 1-Letter).\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "\n",
        "    if \"ID\" in df.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing residue key column: expected 'ID' or '1-Letter'\")\n",
        "\n",
        "    required_cols = [key_col] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        key = str(row[key_col]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[key] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "# 位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([1.0, 0.0] if hop == 1 else [0.0, 1.0])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "\n",
        "    if \"ID\" in df_feat.columns:\n",
        "        key_col = \"ID\"\n",
        "    elif \"1-Letter\" in df_feat.columns:\n",
        "        key_col = \"1-Letter\"\n",
        "    else:\n",
        "        raise ValueError(\"Missing residue key column: expected 'ID' or '1-Letter'\")\n",
        "\n",
        "    meta_candidates = [key_col, \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    meta_cols = [c for c in meta_candidates if c in df_feat.columns]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "    print(df_feat[feature_cols].describe().loc[[\"mean\",\"std\",\"min\",\"max\"]].T.head(10))\n",
        "    # look for extreme standardized values\n",
        "    absmax = df_feat[feature_cols].abs().max().sort_values(ascending=False)\n",
        "    print(\"\\nTop 10 features by |max|:\")\n",
        "    print(absmax.head(10))\n",
        "\n",
        "    nonzero_cnt = (df_feat[feature_cols].abs() > 1e-12).sum(axis=0).sort_values()\n",
        "    print(\"Non-zero count (smallest 20):\")\n",
        "    print(nonzero_cnt.head(20))\n",
        "\n",
        "    # 例如：过滤非零次数 < 3 的列\n",
        "    keep_cols = nonzero_cnt[nonzero_cnt >= 3].index.tolist()\n",
        "    print(\"Kept after sparsity filter:\", len(keep_cols))\n",
        "\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Detected key_col:\", key_col)\n",
        "    print(\"Number of feature_cols:\", len(feature_cols))\n",
        "    print(\"Final node feature dim:\", len(feature_cols) + POS_EMB_DIM)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # feature_cols + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8fjh1I-xleL",
        "outputId": "8f1859c1-058e-4143-ff70-01cb58cf4372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             mean       std       min       max\n",
            "MinAbsEStateIndex    1.110223e-17  1.025978 -1.266428  2.641208\n",
            "MinEStateIndex       2.486900e-15  1.025978 -2.031500  2.300042\n",
            "qed                 -9.742207e-16  1.025978 -2.626475  1.709766\n",
            "SPS                 -2.345346e-16  1.025978 -1.761074  3.695238\n",
            "MolWt                4.274359e-16  1.025978 -2.004112  1.994314\n",
            "HeavyAtomMolWt       1.387779e-16  1.025978 -1.956531  2.055425\n",
            "ExactMolWt          -8.881784e-17  1.025978 -2.004065  1.994276\n",
            "NumValenceElectrons  1.665335e-17  1.025978 -2.045336  2.208963\n",
            "MaxPartialCharge    -1.729589e-14  1.025978 -3.162808  2.100473\n",
            "MinPartialCharge    -1.234429e-14  1.025978 -4.352092  0.260308\n",
            "\n",
            "Top 10 features by |max|:\n",
            "fr_sulfide           4.358899\n",
            "fr_SH                4.358899\n",
            "fr_unbrch_alkane     4.358899\n",
            "NumAliphaticRings    4.358899\n",
            "PEOE_VSA11           4.358899\n",
            "PEOE_VSA3            4.358899\n",
            "SlogP_VSA8           4.358899\n",
            "MinPartialCharge     4.352092\n",
            "SPS                  3.695238\n",
            "BCUT2D_CHGHI         3.676907\n",
            "dtype: float64\n",
            "Non-zero count (smallest 20):\n",
            "NHOHCount              13\n",
            "NOCount                14\n",
            "MinAbsEStateIndex      20\n",
            "MinEStateIndex         20\n",
            "MolWt                  20\n",
            "HeavyAtomMolWt         20\n",
            "qed                    20\n",
            "SPS                    20\n",
            "MaxPartialCharge       20\n",
            "MinPartialCharge       20\n",
            "FpDensityMorgan1       20\n",
            "FpDensityMorgan2       20\n",
            "FpDensityMorgan3       20\n",
            "BCUT2D_MWHI            20\n",
            "ExactMolWt             20\n",
            "NumValenceElectrons    20\n",
            "BCUT2D_LOGPLOW         20\n",
            "BCUT2D_MRLOW           20\n",
            "AvgIpc                 20\n",
            "BalabanJ               20\n",
            "dtype: int64\n",
            "Kept after sparsity filter: 79\n",
            "Detected key_col: ID\n",
            "Number of feature_cols: 79\n",
            "Final node feature dim: 87\n",
            "Number of peptides in dataset: 5000\n",
            "MAX_HOP: 2\n",
            "Data(x=[12, 87], edge_index=[2, 42], edge_attr=[42, 2], y=[1])\n",
            "num_nodes: 12\n",
            "num_edges: 42\n",
            "feature_dim: 87\n",
            "label: 0.0\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "Train size ratio: 0.7\n",
            "Val size ratio: 0.15\n",
            "Test size ratio: 0.15\n",
            "Train: total=3500, pos=723 (0.207), neg=2777 (0.793)\n",
            "Val: total=750, pos=155 (0.207), neg=595 (0.793)\n",
            "Test: total=750, pos=155 (0.207), neg=595 (0.793)\n",
            "Batch x shape: torch.Size([428, 87])\n",
            "Batch num_graphs: 32\n",
            "Batch y shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### edge-attr标量，data.py，使model性能下降"
      ],
      "metadata": {
        "id": "QESVAyjr2A4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    val = float(hop) / 2.0  # hop=1 -> 0.5, hop=2 -> 1.0\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append([val])\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append([val])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices, labels, test_size=0.30, random_state=seed, stratify=labels\n",
        "    )\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx, y_temp, test_size=0.50, random_state=seed, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # 66 + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tmo41vXg4vFG",
        "outputId": "3f595ba9-a7a5-4eec-9a97-de8031f0e93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### edge-attr，三维，one-hot/auc下降\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dNmlb6To8-uG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 3), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    onehot = [1.0, 0.0] if hop == 1 else [0.0, 1.0]\n",
        "                    hop_scaled = float(hop) / 2.0\n",
        "                    attr = onehot + [hop_scaled]\n",
        "\n",
        "                    edge_index_list.append([i, j])\n",
        "                    edge_attr_list.append(attr)\n",
        "                    edge_index_list.append([j, i])\n",
        "                    edge_attr_list.append(attr)\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices, labels, test_size=0.30, random_state=seed, stratify=labels\n",
        "    )\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx, y_temp, test_size=0.50, random_state=seed, stratify=y_temp\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])  # 66 + POS_EMB_DIM\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tbZ2JjcC9Cm1",
        "outputId": "37dabce8-e6b2-40a4-db3b-67823453777d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### one-hot，弱化hop2/auc降低"
      ],
      "metadata": {
        "id": "4uVsV2eIB0Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from textwrap import dedent\n",
        "\n",
        "out_dir = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "code = r'''\n",
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# ======= Paths =======\n",
        "RESIDUAL_FEATURE_XLSX = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/residue_features_enhanced.xlsx\"\n",
        "PEPTIDE_excel_PATH = \"/content/drive/MyDrive/master_thesis/sampled_data_5000/canya_data_sampled_5000_smiles.xlsx\"\n",
        "\n",
        "# Positional encoding dimension\n",
        "POS_EMB_DIM = 8  # can be 4 or 8\n",
        "\n",
        "# Skip edges (max hop)\n",
        "MAX_HOP = 2  # start with 2, can be set to 3 later\n",
        "\n",
        "# Weakening factor for hop=2 edges\n",
        "ALPHA = 0.5\n",
        "\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Read Excel or CSV based on file extension.\"\"\"\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext in [\".xlsx\", \".xls\"]:\n",
        "        return pd.read_excel(path)\n",
        "    if ext == \".csv\":\n",
        "        return pd.read_csv(path)\n",
        "    raise ValueError(f\"Unsupported file type: {path}\")\n",
        "\n",
        "\n",
        "def build_residue_feat_dict(residual_feature_path, feature_cols):\n",
        "    \"\"\"Load residue feature table and build dict: ID -> feature vector.\"\"\"\n",
        "    df = read_table(residual_feature_path)\n",
        "    required_cols = [\"ID\"] + feature_cols\n",
        "    missing = [c for c in required_cols if c not in df.columns]\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing required columns in residue feature table: {missing}\")\n",
        "\n",
        "    residue_feat_dict = {}\n",
        "    for _, row in df.iterrows():\n",
        "        one_letter = str(row[\"ID\"]).strip()\n",
        "        feat_vec = row[feature_cols].astype(float).to_numpy()\n",
        "        residue_feat_dict[one_letter] = feat_vec\n",
        "    return residue_feat_dict\n",
        "\n",
        "\n",
        "# 位置编码 position encoding\n",
        "def get_sinusoidal_embeddings(pos, d_model):\n",
        "    \"\"\"\n",
        "    Classic sinusoidal positional encoding.\n",
        "    pos: int, residue index (0-based)\n",
        "    d_model: embedding dimension (even/odd allowed)\n",
        "    \"\"\"\n",
        "    pe = torch.zeros(d_model, dtype=torch.float)\n",
        "    position = torch.tensor(pos, dtype=torch.float)\n",
        "    div_term = torch.exp(\n",
        "        torch.arange(0, d_model, 2, dtype=torch.float) * (-np.log(10000.0) / d_model)\n",
        "    )\n",
        "    pe[0::2] = torch.sin(position * div_term)\n",
        "    pe[1::2] = torch.cos(position * div_term)\n",
        "    return pe\n",
        "\n",
        "\n",
        "def seq_to_graph_data(seq, label, residue_feat_dict, pos_dim=POS_EMB_DIM):\n",
        "    \"\"\"Convert peptide sequence + label to PyG Data (residue-level graph).\"\"\"\n",
        "    node_features = []\n",
        "    for i, aa in enumerate(seq):\n",
        "        if aa not in residue_feat_dict:\n",
        "            raise ValueError(f\"Unknown residue '{aa}' in sequence: {seq}\")\n",
        "\n",
        "        base_feat = torch.tensor(residue_feat_dict[aa], dtype=torch.float)\n",
        "        pos_feat = get_sinusoidal_embeddings(i, pos_dim)\n",
        "        feat = torch.cat([base_feat, pos_feat], dim=0)\n",
        "        node_features.append(feat)\n",
        "\n",
        "    x = torch.stack(node_features, dim=0)\n",
        "    num_residues = x.shape[0]\n",
        "\n",
        "    # Build edges with skip connections up to MAX_HOP (undirected).\n",
        "    if num_residues <= 1:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_attr = torch.empty((0, 2), dtype=torch.float)\n",
        "    else:\n",
        "        edge_index_list = []\n",
        "        edge_attr_list = []\n",
        "        for i in range(num_residues):\n",
        "            for hop in range(1, MAX_HOP + 1):\n",
        "                j = i + hop\n",
        "                if j < num_residues:\n",
        "                    # i -> j\n",
        "                    edge_index_list.append([i, j])\n",
        "                    if hop == 1:\n",
        "                        edge_attr_list.append([1.0, 0.0])\n",
        "                    else:\n",
        "                        edge_attr_list.append([0.0, ALPHA])\n",
        "\n",
        "                    # j -> i\n",
        "                    edge_index_list.append([j, i])\n",
        "                    if hop == 1:\n",
        "                        edge_attr_list.append([1.0, 0.0])\n",
        "                    else:\n",
        "                        edge_attr_list.append([0.0, ALPHA])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
        "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
        "\n",
        "    y = torch.tensor([float(label)], dtype=torch.float)\n",
        "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "\n",
        "\n",
        "class PeptideResidueDataset(Dataset):\n",
        "    \"\"\"Dataset that converts peptide sequences to residue graphs, storing them in memory.\"\"\"\n",
        "    def __init__(self, peptide_excel_path, residue_feat_dict, transform=None, pre_transform=None):\n",
        "        self.peptide_excel_path = peptide_excel_path\n",
        "        self.residue_feat_dict = residue_feat_dict\n",
        "        self.transform = transform\n",
        "        self.pre_transform = pre_transform\n",
        "        self.data_list = self._process()\n",
        "\n",
        "    def _process(self):\n",
        "        df = read_table(self.peptide_excel_path)\n",
        "\n",
        "        # Support both naming conventions.\n",
        "        seq_col = \"aa_seq\" if \"aa_seq\" in df.columns else \"sequence\"\n",
        "        label_col = \"seed_bh\" if \"seed_bh\" in df.columns else \"label\"\n",
        "\n",
        "        data_list = []\n",
        "        for _, row in df.iterrows():\n",
        "            seq = row.get(seq_col, None)\n",
        "            label = row.get(label_col, None)\n",
        "\n",
        "            if pd.isna(seq) or seq is None or str(seq).strip() == \"\":\n",
        "                continue\n",
        "            if pd.isna(label):\n",
        "                continue\n",
        "\n",
        "            seq = str(seq).strip()\n",
        "            label = int(label)\n",
        "\n",
        "            try:\n",
        "                data = seq_to_graph_data(seq, label, self.residue_feat_dict, pos_dim=POS_EMB_DIM)\n",
        "                if self.pre_transform is not None:\n",
        "                    data = self.pre_transform(data)\n",
        "                data_list.append(data)\n",
        "            except Exception as e:\n",
        "                print(f\"[WARN] Skip peptide due to error: {e}\")\n",
        "                continue\n",
        "        return data_list\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        data = self.data_list[idx]\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        return data\n",
        "\n",
        "\n",
        "def split_dataset(dataset, seed=42):\n",
        "    \"\"\"Stratified split into train/val/test with 70/15/15 ratio.\"\"\"\n",
        "    labels = [int(data.y.item()) for data in dataset]\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    train_idx, temp_idx, y_train, y_temp = train_test_split(\n",
        "        indices,\n",
        "        labels,\n",
        "        test_size=0.30,\n",
        "        random_state=seed,\n",
        "        stratify=labels,\n",
        "    )\n",
        "\n",
        "    val_idx, test_idx, y_val, y_test = train_test_split(\n",
        "        temp_idx,\n",
        "        y_temp,\n",
        "        test_size=0.50,\n",
        "        random_state=seed,\n",
        "        stratify=y_temp,\n",
        "    )\n",
        "\n",
        "    train_dataset = Subset(dataset, train_idx)\n",
        "    val_dataset = Subset(dataset, val_idx)\n",
        "    test_dataset = Subset(dataset, test_idx)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "def build_loaders(train_dataset, val_dataset, test_dataset, batch_size=32):\n",
        "    \"\"\"Create PyG DataLoaders for each split.\"\"\"\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def report_split_stats(dataset, name):\n",
        "    labels = [int(dataset[i].y.item()) for i in range(len(dataset))]\n",
        "    total = len(labels)\n",
        "    pos = sum(labels)\n",
        "    neg = total - pos\n",
        "    pos_ratio = pos / total if total > 0 else 0.0\n",
        "    neg_ratio = neg / total if total > 0 else 0.0\n",
        "    print(f\"{name}: total={total}, pos={pos} ({pos_ratio:.3f}), neg={neg} ({neg_ratio:.3f})\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Number of peptides in dataset:\", len(dataset))\n",
        "    print(\"MAX_HOP:\", MAX_HOP)\n",
        "\n",
        "    if len(dataset) > 0:\n",
        "        data = dataset[0]\n",
        "        print(data)\n",
        "        print(\"num_nodes:\", data.num_nodes)\n",
        "        print(\"num_edges:\", data.num_edges)\n",
        "        print(\"feature_dim:\", data.x.shape[1])\n",
        "        print(\"label:\", data.y.item())\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    print(\"Train size ratio:\", len(train_dataset) / len(dataset))\n",
        "    print(\"Val size ratio:\", len(val_dataset) / len(dataset))\n",
        "    print(\"Test size ratio:\", len(test_dataset) / len(dataset))\n",
        "\n",
        "    report_split_stats(train_dataset, \"Train\")\n",
        "    report_split_stats(val_dataset, \"Val\")\n",
        "    report_split_stats(test_dataset, \"Test\")\n",
        "\n",
        "    batch = next(iter(train_loader))\n",
        "    print(\"Batch x shape:\", batch.x.shape)\n",
        "    print(\"Batch num_graphs:\", batch.num_graphs)\n",
        "    print(\"Batch y shape:\", batch.y.shape)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "out_path = os.path.join(out_dir, \"data.py\")\n",
        "with open(out_path, \"w\") as f:\n",
        "    f.write(dedent(code).lstrip())\n",
        "\n",
        "out_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-WgqR6fPB5AU",
        "outputId": "d06a9a4d-5ab1-428e-cdc8-69baafca0b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN/data.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.train GNN model"
      ],
      "metadata": {
        "id": "TRXvzgvd9272"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.GCNConv, 5000"
      ],
      "metadata": {
        "id": "Y0R5J-tzXzsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCNConv, 5000\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "\n",
        "!{sys.executable} -m pip install rdkit # install rdkit\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#   !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "#else:\n",
        "#    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import importlib\n",
        "import data # Import the module itself\n",
        "importlib.reload(data) # Reload it to ensure latest changes are picked up\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=64, num_classes=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.dropout = dropout\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=64, num_classes=2, dropout=0.2\n",
        "    ).to(device)\n",
        "\n",
        "    # 给标签 1（有活性）4倍的权重，逼迫模型去重视它\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    max_epochs = 200\n",
        "    patience = 30\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIy0mN7Z95NZ",
        "outputId": "8a4cd12a-8a03-4414-c6f7-e1a9487de1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
            "  import torch_geometric.typing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 74\n",
            "Epoch 001 | train_loss=0.6916 | val_loss=0.6909 | val_acc=0.6800 | val_auc=0.5468\n",
            "Epoch 002 | train_loss=0.6816 | val_loss=0.6827 | val_acc=0.7120 | val_auc=0.5910\n",
            "Epoch 003 | train_loss=0.6677 | val_loss=0.6749 | val_acc=0.6013 | val_auc=0.6063\n",
            "Epoch 004 | train_loss=0.6603 | val_loss=0.6698 | val_acc=0.5827 | val_auc=0.6208\n",
            "Epoch 005 | train_loss=0.6542 | val_loss=0.6745 | val_acc=0.6387 | val_auc=0.6223\n",
            "Epoch 006 | train_loss=0.6553 | val_loss=0.6715 | val_acc=0.5347 | val_auc=0.6218\n",
            "Epoch 007 | train_loss=0.6508 | val_loss=0.6697 | val_acc=0.6493 | val_auc=0.6328\n",
            "Epoch 008 | train_loss=0.6481 | val_loss=0.6680 | val_acc=0.5787 | val_auc=0.6325\n",
            "Epoch 009 | train_loss=0.6470 | val_loss=0.6767 | val_acc=0.4987 | val_auc=0.6249\n",
            "Epoch 010 | train_loss=0.6429 | val_loss=0.6726 | val_acc=0.6453 | val_auc=0.6359\n",
            "Epoch 011 | train_loss=0.6401 | val_loss=0.6867 | val_acc=0.4413 | val_auc=0.6282\n",
            "Epoch 012 | train_loss=0.6377 | val_loss=0.6659 | val_acc=0.5707 | val_auc=0.6434\n",
            "Epoch 013 | train_loss=0.6384 | val_loss=0.6726 | val_acc=0.5013 | val_auc=0.6407\n",
            "Epoch 014 | train_loss=0.6349 | val_loss=0.6686 | val_acc=0.5547 | val_auc=0.6432\n",
            "Epoch 015 | train_loss=0.6334 | val_loss=0.6911 | val_acc=0.7253 | val_auc=0.6460\n",
            "Epoch 016 | train_loss=0.6322 | val_loss=0.6758 | val_acc=0.6120 | val_auc=0.6431\n",
            "Epoch 017 | train_loss=0.6325 | val_loss=0.6686 | val_acc=0.6587 | val_auc=0.6495\n",
            "Epoch 018 | train_loss=0.6281 | val_loss=0.6812 | val_acc=0.6640 | val_auc=0.6368\n",
            "Epoch 019 | train_loss=0.6273 | val_loss=0.6804 | val_acc=0.6960 | val_auc=0.6468\n",
            "Epoch 020 | train_loss=0.6259 | val_loss=0.6774 | val_acc=0.4987 | val_auc=0.6431\n",
            "Epoch 021 | train_loss=0.6245 | val_loss=0.6770 | val_acc=0.5573 | val_auc=0.6328\n",
            "Epoch 022 | train_loss=0.6215 | val_loss=0.6733 | val_acc=0.6213 | val_auc=0.6465\n",
            "Epoch 023 | train_loss=0.6153 | val_loss=0.6764 | val_acc=0.6293 | val_auc=0.6433\n",
            "Epoch 024 | train_loss=0.6148 | val_loss=0.7002 | val_acc=0.7080 | val_auc=0.6400\n",
            "Epoch 025 | train_loss=0.6184 | val_loss=0.6867 | val_acc=0.6307 | val_auc=0.6415\n",
            "Epoch 026 | train_loss=0.6139 | val_loss=0.6863 | val_acc=0.6827 | val_auc=0.6457\n",
            "Epoch 027 | train_loss=0.6142 | val_loss=0.6801 | val_acc=0.6267 | val_auc=0.6461\n",
            "Epoch 028 | train_loss=0.6110 | val_loss=0.6775 | val_acc=0.5507 | val_auc=0.6382\n",
            "Epoch 029 | train_loss=0.6157 | val_loss=0.6879 | val_acc=0.5320 | val_auc=0.6390\n",
            "Epoch 030 | train_loss=0.6083 | val_loss=0.6857 | val_acc=0.6480 | val_auc=0.6417\n",
            "Epoch 031 | train_loss=0.6097 | val_loss=0.6847 | val_acc=0.6360 | val_auc=0.6426\n",
            "Epoch 032 | train_loss=0.6095 | val_loss=0.6738 | val_acc=0.5960 | val_auc=0.6453\n",
            "Epoch 033 | train_loss=0.6066 | val_loss=0.6816 | val_acc=0.5267 | val_auc=0.6365\n",
            "Epoch 034 | train_loss=0.6018 | val_loss=0.6831 | val_acc=0.6213 | val_auc=0.6466\n",
            "Epoch 035 | train_loss=0.6002 | val_loss=0.6909 | val_acc=0.5947 | val_auc=0.6350\n",
            "Epoch 036 | train_loss=0.5976 | val_loss=0.6857 | val_acc=0.5933 | val_auc=0.6441\n",
            "Epoch 037 | train_loss=0.5979 | val_loss=0.6809 | val_acc=0.5600 | val_auc=0.6501\n",
            "Epoch 038 | train_loss=0.5981 | val_loss=0.6955 | val_acc=0.5947 | val_auc=0.6506\n",
            "Epoch 039 | train_loss=0.5991 | val_loss=0.6913 | val_acc=0.6267 | val_auc=0.6386\n",
            "Epoch 040 | train_loss=0.5909 | val_loss=0.6998 | val_acc=0.6187 | val_auc=0.6471\n",
            "Epoch 041 | train_loss=0.5920 | val_loss=0.6870 | val_acc=0.5787 | val_auc=0.6412\n",
            "Epoch 042 | train_loss=0.5951 | val_loss=0.6961 | val_acc=0.6467 | val_auc=0.6376\n",
            "Epoch 043 | train_loss=0.5923 | val_loss=0.6965 | val_acc=0.6147 | val_auc=0.6388\n",
            "Epoch 044 | train_loss=0.5953 | val_loss=0.7068 | val_acc=0.6880 | val_auc=0.6394\n",
            "Epoch 045 | train_loss=0.5885 | val_loss=0.6916 | val_acc=0.5307 | val_auc=0.6403\n",
            "Epoch 046 | train_loss=0.5795 | val_loss=0.6912 | val_acc=0.6480 | val_auc=0.6434\n",
            "Epoch 047 | train_loss=0.5761 | val_loss=0.6979 | val_acc=0.5307 | val_auc=0.6384\n",
            "Epoch 048 | train_loss=0.5787 | val_loss=0.7295 | val_acc=0.7027 | val_auc=0.6417\n",
            "Epoch 049 | train_loss=0.5795 | val_loss=0.7352 | val_acc=0.6893 | val_auc=0.6312\n",
            "Epoch 050 | train_loss=0.5808 | val_loss=0.7061 | val_acc=0.5347 | val_auc=0.6328\n",
            "Epoch 051 | train_loss=0.5831 | val_loss=0.6936 | val_acc=0.5987 | val_auc=0.6383\n",
            "Epoch 052 | train_loss=0.5744 | val_loss=0.6956 | val_acc=0.6160 | val_auc=0.6349\n",
            "Epoch 053 | train_loss=0.5747 | val_loss=0.6917 | val_acc=0.6173 | val_auc=0.6472\n",
            "Epoch 054 | train_loss=0.5710 | val_loss=0.7058 | val_acc=0.5853 | val_auc=0.6403\n",
            "Epoch 055 | train_loss=0.5694 | val_loss=0.7087 | val_acc=0.6133 | val_auc=0.6414\n",
            "Epoch 056 | train_loss=0.5698 | val_loss=0.7131 | val_acc=0.6547 | val_auc=0.6321\n",
            "Epoch 057 | train_loss=0.5595 | val_loss=0.7124 | val_acc=0.6147 | val_auc=0.6392\n",
            "Epoch 058 | train_loss=0.5653 | val_loss=0.7015 | val_acc=0.5813 | val_auc=0.6493\n",
            "Epoch 059 | train_loss=0.5605 | val_loss=0.7130 | val_acc=0.5907 | val_auc=0.6409\n",
            "Epoch 060 | train_loss=0.5629 | val_loss=0.7270 | val_acc=0.6507 | val_auc=0.6242\n",
            "Epoch 061 | train_loss=0.5546 | val_loss=0.7102 | val_acc=0.5627 | val_auc=0.6402\n",
            "Epoch 062 | train_loss=0.5589 | val_loss=0.7182 | val_acc=0.5947 | val_auc=0.6429\n",
            "Epoch 063 | train_loss=0.5584 | val_loss=0.7272 | val_acc=0.6520 | val_auc=0.6430\n",
            "Epoch 064 | train_loss=0.5532 | val_loss=0.7146 | val_acc=0.5613 | val_auc=0.6315\n",
            "Epoch 065 | train_loss=0.5489 | val_loss=0.7300 | val_acc=0.6613 | val_auc=0.6443\n",
            "Epoch 066 | train_loss=0.5460 | val_loss=0.7143 | val_acc=0.5773 | val_auc=0.6417\n",
            "Epoch 067 | train_loss=0.5556 | val_loss=0.7404 | val_acc=0.6760 | val_auc=0.6459\n",
            "Epoch 068 | train_loss=0.5540 | val_loss=0.7111 | val_acc=0.5720 | val_auc=0.6365\n",
            "Early stopping triggered.\n",
            "Test | loss=0.7272 | acc=0.5560 | auc=0.6194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GCNConv，3 layers， 128 hidden channels"
      ],
      "metadata": {
        "id": "dWyQYMxbIIeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GCNConv, 5000\n",
        "# 3 layers，128 hidden channels\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool, GlobalAttention\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "import importlib\n",
        "import data\n",
        "importlib.reload(data);\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=128, num_classes=2, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # 核心改动：定义全局注意池化\n",
        "        # gate_nn 是一个小神经网络，用来给每个氨基酸打分（0-1之间）\n",
        "        self.att_pool = GlobalAttention(gate_nn=nn.Linear(hidden_channels, 1))\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # 特征提取阶段\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = F.relu(self.conv3(x, edge_index))\n",
        "\n",
        "        # 灵魂改动：不再求平均，而是按注意力分数汇总\n",
        "        x = self.att_pool(x, batch)\n",
        "\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=128, num_classes=2, dropout=0.3\n",
        "    ).to(device)\n",
        "\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"max\", factor=0.5, patience=10\n",
        "    )\n",
        "\n",
        "    max_epochs = 300\n",
        "    patience = 50\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_auc if not np.isnan(val_auc) else -1.0)\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2DDuUjsZEj0x",
        "outputId": "889371c0-8d22-4b9d-d671-d2aa86168e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4131507869.py:47: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
            "  self.att_pool = GlobalAttention(gate_nn=nn.Linear(hidden_channels, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_loss=0.6943 | val_loss=0.6881 | val_acc=0.5027 | val_auc=0.5575\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'dtype torch.float32 is not recognized'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_pickle_storage_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_dtype_to_storage_type_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: torch.float32",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4131507869.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-4131507869.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mbest_val_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mepochs_no_improve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mepochs_no_improve\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[name-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0mstorage_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                 \u001b[0mstorage_type_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickle_storage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_type_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mstorage_numel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_pickle_storage_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_dtype_to_storage_type_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dtype {self.dtype} is not recognized\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dtype torch.float32 is not recognized'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.GATConv,5000， 2 layers"
      ],
      "metadata": {
        "id": "FWzoeQe6X5FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GATConv, 5000，2 layers\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import importlib\n",
        "import data\n",
        "importlib.reload(data)\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=64, num_classes=2, dropout=0.2, heads=4):\n",
        "        super().__init__()\n",
        "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n",
        "        self.gat2 = GATConv(hidden_channels * heads, hidden_channels, heads=1, dropout=dropout)\n",
        "        self.dropout = dropout\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = F.elu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=64, num_classes=2, dropout=0.2, heads=4\n",
        "    ).to(device)\n",
        "\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    max_epochs = 200\n",
        "    patience = 30\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75e8QnPXX63e",
        "outputId": "bbadfec0-d314-4994-f2e9-6a39af5becb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 66\n",
            "Epoch 001 | train_loss=0.6955 | val_loss=0.6815 | val_acc=0.6293 | val_auc=0.6053\n",
            "Epoch 002 | train_loss=0.6835 | val_loss=0.6795 | val_acc=0.4707 | val_auc=0.6068\n",
            "Epoch 003 | train_loss=0.6800 | val_loss=0.6832 | val_acc=0.5253 | val_auc=0.5865\n",
            "Epoch 004 | train_loss=0.6786 | val_loss=0.6814 | val_acc=0.5493 | val_auc=0.5902\n",
            "Epoch 005 | train_loss=0.6737 | val_loss=0.6817 | val_acc=0.5213 | val_auc=0.5910\n",
            "Epoch 006 | train_loss=0.6743 | val_loss=0.6786 | val_acc=0.5787 | val_auc=0.6039\n",
            "Epoch 007 | train_loss=0.6734 | val_loss=0.6807 | val_acc=0.5973 | val_auc=0.6042\n",
            "Epoch 008 | train_loss=0.6720 | val_loss=0.6799 | val_acc=0.5707 | val_auc=0.5987\n",
            "Epoch 009 | train_loss=0.6718 | val_loss=0.6837 | val_acc=0.5880 | val_auc=0.5980\n",
            "Epoch 010 | train_loss=0.6679 | val_loss=0.6875 | val_acc=0.5800 | val_auc=0.5944\n",
            "Epoch 011 | train_loss=0.6677 | val_loss=0.6890 | val_acc=0.6320 | val_auc=0.5849\n",
            "Epoch 012 | train_loss=0.6701 | val_loss=0.6806 | val_acc=0.5640 | val_auc=0.5963\n",
            "Epoch 013 | train_loss=0.6658 | val_loss=0.6885 | val_acc=0.6453 | val_auc=0.5894\n",
            "Epoch 014 | train_loss=0.6626 | val_loss=0.6899 | val_acc=0.6133 | val_auc=0.5971\n",
            "Epoch 015 | train_loss=0.6643 | val_loss=0.6915 | val_acc=0.5920 | val_auc=0.6016\n",
            "Epoch 016 | train_loss=0.6645 | val_loss=0.6955 | val_acc=0.6373 | val_auc=0.5779\n",
            "Epoch 017 | train_loss=0.6699 | val_loss=0.6857 | val_acc=0.5547 | val_auc=0.6027\n",
            "Epoch 018 | train_loss=0.6641 | val_loss=0.6830 | val_acc=0.5413 | val_auc=0.5973\n",
            "Epoch 019 | train_loss=0.6676 | val_loss=0.6836 | val_acc=0.6253 | val_auc=0.6038\n",
            "Epoch 020 | train_loss=0.6653 | val_loss=0.6951 | val_acc=0.6040 | val_auc=0.5980\n",
            "Epoch 021 | train_loss=0.6664 | val_loss=0.6861 | val_acc=0.5880 | val_auc=0.5997\n",
            "Epoch 022 | train_loss=0.6650 | val_loss=0.6831 | val_acc=0.4827 | val_auc=0.6035\n",
            "Epoch 023 | train_loss=0.6631 | val_loss=0.6872 | val_acc=0.6240 | val_auc=0.5998\n",
            "Epoch 024 | train_loss=0.6625 | val_loss=0.6862 | val_acc=0.5587 | val_auc=0.5968\n",
            "Epoch 025 | train_loss=0.6642 | val_loss=0.6912 | val_acc=0.6040 | val_auc=0.5969\n",
            "Epoch 026 | train_loss=0.6611 | val_loss=0.6944 | val_acc=0.6627 | val_auc=0.5814\n",
            "Epoch 027 | train_loss=0.6639 | val_loss=0.6929 | val_acc=0.6600 | val_auc=0.5959\n",
            "Epoch 028 | train_loss=0.6652 | val_loss=0.6927 | val_acc=0.5800 | val_auc=0.5879\n",
            "Epoch 029 | train_loss=0.6647 | val_loss=0.6930 | val_acc=0.4413 | val_auc=0.5928\n",
            "Epoch 030 | train_loss=0.6623 | val_loss=0.7035 | val_acc=0.6920 | val_auc=0.5810\n",
            "Epoch 031 | train_loss=0.6636 | val_loss=0.6895 | val_acc=0.5787 | val_auc=0.5889\n",
            "Epoch 032 | train_loss=0.6615 | val_loss=0.6886 | val_acc=0.6173 | val_auc=0.5977\n",
            "Early stopping triggered.\n",
            "Test | loss=0.6850 | acc=0.4493 | auc=0.5969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GATv2Conv, 2 layers, global attention pooling"
      ],
      "metadata": {
        "id": "FgWiLD-PIibw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GATv2Conv, 5000\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATv2Conv, GlobalAttention\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "import importlib\n",
        "import data\n",
        "importlib.reload(data)\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=64, num_classes=2, dropout=0.5, heads=4):\n",
        "        super().__init__()\n",
        "        self.heads = heads\n",
        "        self.hidden_channels = hidden_channels\n",
        "        out_dim = hidden_channels * heads  # concat=True\n",
        "\n",
        "        # GATv2 layers\n",
        "        self.gat1 = GATv2Conv(in_channels, hidden_channels, heads=heads, concat=True)\n",
        "        self.bn1 = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "        self.gat2 = GATv2Conv(out_dim, hidden_channels, heads=heads, concat=True)\n",
        "        self.bn2 = nn.BatchNorm1d(out_dim)\n",
        "\n",
        "        # Residual projection (to match dims)\n",
        "        self.res_proj1 = nn.Linear(in_channels, out_dim)\n",
        "        self.res_proj2 = nn.Linear(out_dim, out_dim)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # GlobalAttention pooling\n",
        "        self.pool = GlobalAttention(gate_nn=nn.Linear(out_dim, 1))\n",
        "\n",
        "        # Classifier\n",
        "        self.fc = nn.Linear(out_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Layer 1 + residual\n",
        "        h1 = self.gat1(x, edge_index)\n",
        "        h1 = h1 + self.res_proj1(x)\n",
        "        h1 = self.bn1(h1)\n",
        "        h1 = F.relu(h1)\n",
        "        h1 = F.dropout(h1, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Layer 2 + residual\n",
        "        h2 = self.gat2(h1, edge_index)\n",
        "        h2 = h2 + self.res_proj2(h1)\n",
        "        h2 = self.bn2(h2)\n",
        "        h2 = F.relu(h2)\n",
        "        h2 = F.dropout(h2, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Pooling + classifier\n",
        "        pooled = self.pool(h2, batch)\n",
        "        logits = self.fc(pooled)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=64, num_classes=2, dropout=0.5, heads=4\n",
        "    ).to(device)\n",
        "\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"max\", factor=0.5, patience=10\n",
        "    )\n",
        "\n",
        "    max_epochs = 300\n",
        "    patience = 50\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_auc if not np.isnan(val_auc) else -1.0)\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VXjYuFDJmcX",
        "outputId": "0704faaf-0463-4d34-8525-5f49e6e1bbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 74\n",
            "Epoch 001 | train_loss=0.6927 | val_loss=0.6713 | val_acc=0.5000 | val_auc=0.6217\n",
            "Epoch 002 | train_loss=0.6804 | val_loss=0.6731 | val_acc=0.6200 | val_auc=0.6062\n",
            "Epoch 003 | train_loss=0.6710 | val_loss=0.6774 | val_acc=0.6227 | val_auc=0.6049\n",
            "Epoch 004 | train_loss=0.6686 | val_loss=0.6737 | val_acc=0.5573 | val_auc=0.6102\n",
            "Epoch 005 | train_loss=0.6620 | val_loss=0.6793 | val_acc=0.6120 | val_auc=0.6106\n",
            "Epoch 006 | train_loss=0.6580 | val_loss=0.6774 | val_acc=0.6027 | val_auc=0.6081\n",
            "Epoch 007 | train_loss=0.6477 | val_loss=0.6719 | val_acc=0.6040 | val_auc=0.6286\n",
            "Epoch 008 | train_loss=0.6501 | val_loss=0.6716 | val_acc=0.6120 | val_auc=0.6282\n",
            "Epoch 009 | train_loss=0.6449 | val_loss=0.6695 | val_acc=0.5747 | val_auc=0.6270\n",
            "Epoch 010 | train_loss=0.6460 | val_loss=0.6830 | val_acc=0.6760 | val_auc=0.6282\n",
            "Epoch 011 | train_loss=0.6398 | val_loss=0.6826 | val_acc=0.6693 | val_auc=0.6344\n",
            "Epoch 012 | train_loss=0.6316 | val_loss=0.6832 | val_acc=0.6000 | val_auc=0.6197\n",
            "Epoch 013 | train_loss=0.6335 | val_loss=0.6781 | val_acc=0.5560 | val_auc=0.6305\n",
            "Epoch 014 | train_loss=0.6226 | val_loss=0.6762 | val_acc=0.6347 | val_auc=0.6320\n",
            "Epoch 015 | train_loss=0.6316 | val_loss=0.6782 | val_acc=0.5747 | val_auc=0.6346\n",
            "Epoch 016 | train_loss=0.6201 | val_loss=0.6830 | val_acc=0.6080 | val_auc=0.6292\n",
            "Epoch 017 | train_loss=0.6266 | val_loss=0.6754 | val_acc=0.6320 | val_auc=0.6444\n",
            "Epoch 018 | train_loss=0.6151 | val_loss=0.6712 | val_acc=0.5760 | val_auc=0.6477\n",
            "Epoch 019 | train_loss=0.6253 | val_loss=0.6809 | val_acc=0.6200 | val_auc=0.6403\n",
            "Epoch 020 | train_loss=0.6099 | val_loss=0.6777 | val_acc=0.5960 | val_auc=0.6490\n",
            "Epoch 021 | train_loss=0.6062 | val_loss=0.6862 | val_acc=0.6453 | val_auc=0.6402\n",
            "Epoch 022 | train_loss=0.6039 | val_loss=0.6814 | val_acc=0.6173 | val_auc=0.6478\n",
            "Epoch 023 | train_loss=0.5994 | val_loss=0.6984 | val_acc=0.6187 | val_auc=0.6387\n",
            "Epoch 024 | train_loss=0.5958 | val_loss=0.7029 | val_acc=0.6827 | val_auc=0.6369\n",
            "Epoch 025 | train_loss=0.5929 | val_loss=0.6910 | val_acc=0.6053 | val_auc=0.6429\n",
            "Epoch 026 | train_loss=0.5938 | val_loss=0.6851 | val_acc=0.6507 | val_auc=0.6556\n",
            "Epoch 027 | train_loss=0.5844 | val_loss=0.7164 | val_acc=0.6627 | val_auc=0.6426\n",
            "Epoch 028 | train_loss=0.5725 | val_loss=0.6938 | val_acc=0.5813 | val_auc=0.6567\n",
            "Epoch 029 | train_loss=0.5748 | val_loss=0.6934 | val_acc=0.6160 | val_auc=0.6529\n",
            "Epoch 030 | train_loss=0.5811 | val_loss=0.6980 | val_acc=0.5653 | val_auc=0.6474\n",
            "Epoch 031 | train_loss=0.5636 | val_loss=0.6938 | val_acc=0.6440 | val_auc=0.6619\n",
            "Epoch 032 | train_loss=0.5698 | val_loss=0.6966 | val_acc=0.6173 | val_auc=0.6528\n",
            "Epoch 033 | train_loss=0.5695 | val_loss=0.7120 | val_acc=0.6360 | val_auc=0.6524\n",
            "Epoch 034 | train_loss=0.5535 | val_loss=0.7066 | val_acc=0.6440 | val_auc=0.6565\n",
            "Epoch 035 | train_loss=0.5666 | val_loss=0.7085 | val_acc=0.6533 | val_auc=0.6588\n",
            "Epoch 036 | train_loss=0.5572 | val_loss=0.7183 | val_acc=0.6253 | val_auc=0.6506\n",
            "Epoch 037 | train_loss=0.5420 | val_loss=0.7235 | val_acc=0.6573 | val_auc=0.6593\n",
            "Epoch 038 | train_loss=0.5515 | val_loss=0.7300 | val_acc=0.6227 | val_auc=0.6417\n",
            "Epoch 039 | train_loss=0.5434 | val_loss=0.7329 | val_acc=0.6120 | val_auc=0.6519\n",
            "Epoch 040 | train_loss=0.5473 | val_loss=0.7418 | val_acc=0.6827 | val_auc=0.6534\n",
            "Epoch 041 | train_loss=0.5367 | val_loss=0.7276 | val_acc=0.6987 | val_auc=0.6703\n",
            "Epoch 042 | train_loss=0.5381 | val_loss=0.7238 | val_acc=0.6000 | val_auc=0.6574\n",
            "Epoch 043 | train_loss=0.5337 | val_loss=0.7350 | val_acc=0.6173 | val_auc=0.6617\n",
            "Epoch 044 | train_loss=0.5259 | val_loss=0.7566 | val_acc=0.6160 | val_auc=0.6528\n",
            "Epoch 045 | train_loss=0.5245 | val_loss=0.7604 | val_acc=0.6600 | val_auc=0.6564\n",
            "Epoch 046 | train_loss=0.5110 | val_loss=0.7548 | val_acc=0.6560 | val_auc=0.6608\n",
            "Epoch 047 | train_loss=0.5178 | val_loss=0.7605 | val_acc=0.5973 | val_auc=0.6474\n",
            "Epoch 048 | train_loss=0.5174 | val_loss=0.7569 | val_acc=0.6480 | val_auc=0.6520\n",
            "Epoch 049 | train_loss=0.5030 | val_loss=0.7748 | val_acc=0.6307 | val_auc=0.6476\n",
            "Epoch 050 | train_loss=0.4971 | val_loss=0.7948 | val_acc=0.6480 | val_auc=0.6456\n",
            "Epoch 051 | train_loss=0.5064 | val_loss=0.8031 | val_acc=0.6947 | val_auc=0.6491\n",
            "Epoch 052 | train_loss=0.4913 | val_loss=0.7660 | val_acc=0.6440 | val_auc=0.6663\n",
            "Epoch 053 | train_loss=0.4648 | val_loss=0.7933 | val_acc=0.6507 | val_auc=0.6648\n",
            "Epoch 054 | train_loss=0.4754 | val_loss=0.8209 | val_acc=0.6520 | val_auc=0.6519\n",
            "Epoch 055 | train_loss=0.4533 | val_loss=0.8062 | val_acc=0.6653 | val_auc=0.6637\n",
            "Epoch 056 | train_loss=0.4639 | val_loss=0.8197 | val_acc=0.6693 | val_auc=0.6596\n",
            "Epoch 057 | train_loss=0.4571 | val_loss=0.8191 | val_acc=0.6560 | val_auc=0.6576\n",
            "Epoch 058 | train_loss=0.4542 | val_loss=0.8409 | val_acc=0.6680 | val_auc=0.6572\n",
            "Epoch 059 | train_loss=0.4615 | val_loss=0.8218 | val_acc=0.6547 | val_auc=0.6620\n",
            "Epoch 060 | train_loss=0.4496 | val_loss=0.8455 | val_acc=0.6747 | val_auc=0.6523\n",
            "Epoch 061 | train_loss=0.4377 | val_loss=0.8400 | val_acc=0.6667 | val_auc=0.6600\n",
            "Epoch 062 | train_loss=0.4409 | val_loss=0.8432 | val_acc=0.6520 | val_auc=0.6593\n",
            "Epoch 063 | train_loss=0.4314 | val_loss=0.8818 | val_acc=0.6800 | val_auc=0.6563\n",
            "Epoch 064 | train_loss=0.4289 | val_loss=0.8755 | val_acc=0.6840 | val_auc=0.6561\n",
            "Epoch 065 | train_loss=0.4160 | val_loss=0.8945 | val_acc=0.6827 | val_auc=0.6532\n",
            "Epoch 066 | train_loss=0.4280 | val_loss=0.8837 | val_acc=0.6720 | val_auc=0.6569\n",
            "Epoch 067 | train_loss=0.4233 | val_loss=0.8825 | val_acc=0.6640 | val_auc=0.6562\n",
            "Epoch 068 | train_loss=0.4132 | val_loss=0.8731 | val_acc=0.6547 | val_auc=0.6586\n",
            "Epoch 069 | train_loss=0.4067 | val_loss=0.8939 | val_acc=0.6733 | val_auc=0.6580\n",
            "Epoch 070 | train_loss=0.4131 | val_loss=0.8942 | val_acc=0.6733 | val_auc=0.6593\n",
            "Epoch 071 | train_loss=0.4143 | val_loss=0.9073 | val_acc=0.6827 | val_auc=0.6603\n",
            "Epoch 072 | train_loss=0.4041 | val_loss=0.9133 | val_acc=0.6867 | val_auc=0.6605\n",
            "Epoch 073 | train_loss=0.4109 | val_loss=0.8971 | val_acc=0.6667 | val_auc=0.6589\n",
            "Epoch 074 | train_loss=0.4028 | val_loss=0.9010 | val_acc=0.6813 | val_auc=0.6606\n",
            "Epoch 075 | train_loss=0.4076 | val_loss=0.9025 | val_acc=0.6760 | val_auc=0.6596\n",
            "Epoch 076 | train_loss=0.3941 | val_loss=0.9022 | val_acc=0.6667 | val_auc=0.6600\n",
            "Epoch 077 | train_loss=0.3847 | val_loss=0.9349 | val_acc=0.6920 | val_auc=0.6614\n",
            "Epoch 078 | train_loss=0.3832 | val_loss=0.9377 | val_acc=0.7000 | val_auc=0.6597\n",
            "Epoch 079 | train_loss=0.3941 | val_loss=0.9470 | val_acc=0.6987 | val_auc=0.6603\n",
            "Epoch 080 | train_loss=0.3819 | val_loss=0.9244 | val_acc=0.6813 | val_auc=0.6609\n",
            "Epoch 081 | train_loss=0.3820 | val_loss=0.9502 | val_acc=0.7000 | val_auc=0.6597\n",
            "Epoch 082 | train_loss=0.3832 | val_loss=0.9435 | val_acc=0.6893 | val_auc=0.6608\n",
            "Epoch 083 | train_loss=0.3829 | val_loss=0.9457 | val_acc=0.6827 | val_auc=0.6595\n",
            "Epoch 084 | train_loss=0.3871 | val_loss=0.9653 | val_acc=0.6933 | val_auc=0.6596\n",
            "Epoch 085 | train_loss=0.3859 | val_loss=0.9571 | val_acc=0.6827 | val_auc=0.6569\n",
            "Epoch 086 | train_loss=0.3930 | val_loss=0.9522 | val_acc=0.6867 | val_auc=0.6579\n",
            "Epoch 087 | train_loss=0.3747 | val_loss=0.9461 | val_acc=0.6827 | val_auc=0.6599\n",
            "Epoch 088 | train_loss=0.3732 | val_loss=0.9514 | val_acc=0.6880 | val_auc=0.6595\n",
            "Epoch 089 | train_loss=0.3803 | val_loss=0.9593 | val_acc=0.6827 | val_auc=0.6589\n",
            "Epoch 090 | train_loss=0.3760 | val_loss=0.9483 | val_acc=0.6813 | val_auc=0.6595\n",
            "Epoch 091 | train_loss=0.3777 | val_loss=0.9482 | val_acc=0.6773 | val_auc=0.6589\n",
            "Early stopping triggered.\n",
            "Test | loss=0.8120 | acc=0.6360 | auc=0.5749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3.SAGEConv"
      ],
      "metadata": {
        "id": "Ji9OGlYyK47V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAGEConv, 5000，hidden channels 48\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, GlobalAttention\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "import importlib\n",
        "import data\n",
        "importlib.reload(data)\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=48, num_classes=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_channels)\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.pool = GlobalAttention(gate_nn=nn.Linear(hidden_channels, 1))\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = self.bn3(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        x = self.pool(x, batch)\n",
        "        logits = self.fc(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=48, num_classes=2, dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    try:\n",
        "        criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)\n",
        "    except TypeError:\n",
        "        criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"max\", factor=0.5, patience=10\n",
        "    )\n",
        "\n",
        "    max_epochs = 300\n",
        "    patience = 50\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_auc if not np.isnan(val_auc) else -1.0)\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KftUBmqaK8M_",
        "outputId": "fca81f8c-61ce-4fe2-feb2-0802b045d191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 74\n",
            "Epoch 001 | train_loss=0.7415 | val_loss=0.7240 | val_acc=0.2453 | val_auc=0.5767\n",
            "Epoch 002 | train_loss=0.7384 | val_loss=0.7235 | val_acc=0.2547 | val_auc=0.5876\n",
            "Epoch 003 | train_loss=0.7320 | val_loss=0.7220 | val_acc=0.2573 | val_auc=0.5948\n",
            "Epoch 004 | train_loss=0.7313 | val_loss=0.7224 | val_acc=0.2547 | val_auc=0.5921\n",
            "Epoch 005 | train_loss=0.7299 | val_loss=0.7207 | val_acc=0.2760 | val_auc=0.5987\n",
            "Epoch 006 | train_loss=0.7252 | val_loss=0.7194 | val_acc=0.2907 | val_auc=0.6014\n",
            "Epoch 007 | train_loss=0.7279 | val_loss=0.7172 | val_acc=0.3027 | val_auc=0.6174\n",
            "Epoch 008 | train_loss=0.7225 | val_loss=0.7154 | val_acc=0.3200 | val_auc=0.6184\n",
            "Epoch 009 | train_loss=0.7184 | val_loss=0.7149 | val_acc=0.3213 | val_auc=0.6222\n",
            "Epoch 010 | train_loss=0.7182 | val_loss=0.7143 | val_acc=0.3213 | val_auc=0.6261\n",
            "Epoch 011 | train_loss=0.7193 | val_loss=0.7133 | val_acc=0.3493 | val_auc=0.6262\n",
            "Epoch 012 | train_loss=0.7148 | val_loss=0.7136 | val_acc=0.3373 | val_auc=0.6288\n",
            "Epoch 013 | train_loss=0.7113 | val_loss=0.7148 | val_acc=0.3467 | val_auc=0.6233\n",
            "Epoch 014 | train_loss=0.7131 | val_loss=0.7141 | val_acc=0.3707 | val_auc=0.6272\n",
            "Epoch 015 | train_loss=0.7108 | val_loss=0.7148 | val_acc=0.3653 | val_auc=0.6268\n",
            "Epoch 016 | train_loss=0.7099 | val_loss=0.7147 | val_acc=0.3787 | val_auc=0.6272\n",
            "Epoch 017 | train_loss=0.7101 | val_loss=0.7132 | val_acc=0.3987 | val_auc=0.6283\n",
            "Epoch 018 | train_loss=0.7120 | val_loss=0.7135 | val_acc=0.4013 | val_auc=0.6252\n",
            "Epoch 019 | train_loss=0.7064 | val_loss=0.7132 | val_acc=0.3907 | val_auc=0.6287\n",
            "Epoch 020 | train_loss=0.7063 | val_loss=0.7141 | val_acc=0.4027 | val_auc=0.6275\n",
            "Epoch 021 | train_loss=0.7073 | val_loss=0.7136 | val_acc=0.3973 | val_auc=0.6299\n",
            "Epoch 022 | train_loss=0.7064 | val_loss=0.7132 | val_acc=0.4093 | val_auc=0.6293\n",
            "Epoch 023 | train_loss=0.7045 | val_loss=0.7112 | val_acc=0.4107 | val_auc=0.6363\n",
            "Epoch 024 | train_loss=0.7049 | val_loss=0.7140 | val_acc=0.4080 | val_auc=0.6296\n",
            "Epoch 025 | train_loss=0.7051 | val_loss=0.7135 | val_acc=0.4053 | val_auc=0.6310\n",
            "Epoch 026 | train_loss=0.7005 | val_loss=0.7126 | val_acc=0.4120 | val_auc=0.6333\n",
            "Epoch 027 | train_loss=0.7011 | val_loss=0.7158 | val_acc=0.4000 | val_auc=0.6272\n",
            "Epoch 028 | train_loss=0.7023 | val_loss=0.7142 | val_acc=0.4200 | val_auc=0.6261\n",
            "Epoch 029 | train_loss=0.7008 | val_loss=0.7134 | val_acc=0.4040 | val_auc=0.6310\n",
            "Epoch 030 | train_loss=0.7032 | val_loss=0.7137 | val_acc=0.4147 | val_auc=0.6283\n",
            "Epoch 031 | train_loss=0.7017 | val_loss=0.7136 | val_acc=0.4093 | val_auc=0.6322\n",
            "Epoch 032 | train_loss=0.7004 | val_loss=0.7123 | val_acc=0.4147 | val_auc=0.6343\n",
            "Epoch 033 | train_loss=0.7005 | val_loss=0.7117 | val_acc=0.4173 | val_auc=0.6357\n",
            "Epoch 034 | train_loss=0.6963 | val_loss=0.7106 | val_acc=0.4293 | val_auc=0.6380\n",
            "Epoch 035 | train_loss=0.6978 | val_loss=0.7111 | val_acc=0.4240 | val_auc=0.6377\n",
            "Epoch 036 | train_loss=0.6960 | val_loss=0.7126 | val_acc=0.4240 | val_auc=0.6342\n",
            "Epoch 037 | train_loss=0.6962 | val_loss=0.7101 | val_acc=0.4440 | val_auc=0.6390\n",
            "Epoch 038 | train_loss=0.6942 | val_loss=0.7126 | val_acc=0.4280 | val_auc=0.6385\n",
            "Epoch 039 | train_loss=0.7012 | val_loss=0.7094 | val_acc=0.4520 | val_auc=0.6411\n",
            "Epoch 040 | train_loss=0.6946 | val_loss=0.7078 | val_acc=0.4653 | val_auc=0.6440\n",
            "Epoch 041 | train_loss=0.6949 | val_loss=0.7094 | val_acc=0.4693 | val_auc=0.6406\n",
            "Epoch 042 | train_loss=0.6901 | val_loss=0.7121 | val_acc=0.4320 | val_auc=0.6363\n",
            "Epoch 043 | train_loss=0.6912 | val_loss=0.7103 | val_acc=0.4520 | val_auc=0.6405\n",
            "Epoch 044 | train_loss=0.6932 | val_loss=0.7092 | val_acc=0.4467 | val_auc=0.6438\n",
            "Epoch 045 | train_loss=0.6931 | val_loss=0.7072 | val_acc=0.4707 | val_auc=0.6432\n",
            "Epoch 046 | train_loss=0.6941 | val_loss=0.7087 | val_acc=0.4600 | val_auc=0.6439\n",
            "Epoch 047 | train_loss=0.6922 | val_loss=0.7067 | val_acc=0.4680 | val_auc=0.6461\n",
            "Epoch 048 | train_loss=0.6960 | val_loss=0.7081 | val_acc=0.4613 | val_auc=0.6453\n",
            "Epoch 049 | train_loss=0.6935 | val_loss=0.7084 | val_acc=0.4560 | val_auc=0.6471\n",
            "Epoch 050 | train_loss=0.6941 | val_loss=0.7067 | val_acc=0.4733 | val_auc=0.6493\n",
            "Epoch 051 | train_loss=0.6919 | val_loss=0.7076 | val_acc=0.4720 | val_auc=0.6449\n",
            "Epoch 052 | train_loss=0.6860 | val_loss=0.7093 | val_acc=0.4573 | val_auc=0.6425\n",
            "Epoch 053 | train_loss=0.6920 | val_loss=0.7076 | val_acc=0.4653 | val_auc=0.6441\n",
            "Epoch 054 | train_loss=0.6892 | val_loss=0.7073 | val_acc=0.4640 | val_auc=0.6462\n",
            "Epoch 055 | train_loss=0.6936 | val_loss=0.7062 | val_acc=0.4787 | val_auc=0.6495\n",
            "Epoch 056 | train_loss=0.6923 | val_loss=0.7068 | val_acc=0.4613 | val_auc=0.6504\n",
            "Epoch 057 | train_loss=0.6924 | val_loss=0.7061 | val_acc=0.4840 | val_auc=0.6501\n",
            "Epoch 058 | train_loss=0.6859 | val_loss=0.7065 | val_acc=0.4640 | val_auc=0.6548\n",
            "Epoch 059 | train_loss=0.6888 | val_loss=0.7077 | val_acc=0.4720 | val_auc=0.6482\n",
            "Epoch 060 | train_loss=0.6865 | val_loss=0.7109 | val_acc=0.4773 | val_auc=0.6451\n",
            "Epoch 061 | train_loss=0.6862 | val_loss=0.7069 | val_acc=0.4987 | val_auc=0.6503\n",
            "Epoch 062 | train_loss=0.6866 | val_loss=0.7080 | val_acc=0.4947 | val_auc=0.6505\n",
            "Epoch 063 | train_loss=0.6878 | val_loss=0.7047 | val_acc=0.5080 | val_auc=0.6540\n",
            "Epoch 064 | train_loss=0.6881 | val_loss=0.7108 | val_acc=0.4707 | val_auc=0.6449\n",
            "Epoch 065 | train_loss=0.6855 | val_loss=0.7102 | val_acc=0.4933 | val_auc=0.6472\n",
            "Epoch 066 | train_loss=0.6815 | val_loss=0.7083 | val_acc=0.4933 | val_auc=0.6498\n",
            "Epoch 067 | train_loss=0.6785 | val_loss=0.7095 | val_acc=0.4907 | val_auc=0.6508\n",
            "Epoch 068 | train_loss=0.6907 | val_loss=0.7086 | val_acc=0.4987 | val_auc=0.6474\n",
            "Epoch 069 | train_loss=0.6870 | val_loss=0.7079 | val_acc=0.5293 | val_auc=0.6498\n",
            "Epoch 070 | train_loss=0.6819 | val_loss=0.7072 | val_acc=0.5133 | val_auc=0.6527\n",
            "Epoch 071 | train_loss=0.6800 | val_loss=0.7079 | val_acc=0.5107 | val_auc=0.6528\n",
            "Epoch 072 | train_loss=0.6817 | val_loss=0.7101 | val_acc=0.4893 | val_auc=0.6532\n",
            "Epoch 073 | train_loss=0.6787 | val_loss=0.7108 | val_acc=0.4827 | val_auc=0.6532\n",
            "Epoch 074 | train_loss=0.6795 | val_loss=0.7080 | val_acc=0.5133 | val_auc=0.6576\n",
            "Epoch 075 | train_loss=0.6914 | val_loss=0.7060 | val_acc=0.5227 | val_auc=0.6575\n",
            "Epoch 076 | train_loss=0.6793 | val_loss=0.7062 | val_acc=0.5213 | val_auc=0.6563\n",
            "Epoch 077 | train_loss=0.6816 | val_loss=0.7102 | val_acc=0.5080 | val_auc=0.6495\n",
            "Epoch 078 | train_loss=0.6782 | val_loss=0.7088 | val_acc=0.5160 | val_auc=0.6512\n",
            "Epoch 079 | train_loss=0.6839 | val_loss=0.7095 | val_acc=0.4880 | val_auc=0.6542\n",
            "Epoch 080 | train_loss=0.6804 | val_loss=0.7088 | val_acc=0.5160 | val_auc=0.6523\n",
            "Epoch 081 | train_loss=0.6754 | val_loss=0.7098 | val_acc=0.5173 | val_auc=0.6498\n",
            "Epoch 082 | train_loss=0.6794 | val_loss=0.7111 | val_acc=0.5227 | val_auc=0.6501\n",
            "Epoch 083 | train_loss=0.6783 | val_loss=0.7117 | val_acc=0.5013 | val_auc=0.6508\n",
            "Epoch 084 | train_loss=0.6842 | val_loss=0.7097 | val_acc=0.5080 | val_auc=0.6520\n",
            "Epoch 085 | train_loss=0.6815 | val_loss=0.7131 | val_acc=0.4587 | val_auc=0.6516\n",
            "Epoch 086 | train_loss=0.6779 | val_loss=0.7100 | val_acc=0.5053 | val_auc=0.6524\n",
            "Epoch 087 | train_loss=0.6792 | val_loss=0.7106 | val_acc=0.4947 | val_auc=0.6512\n",
            "Epoch 088 | train_loss=0.6676 | val_loss=0.7107 | val_acc=0.5160 | val_auc=0.6524\n",
            "Epoch 089 | train_loss=0.6798 | val_loss=0.7112 | val_acc=0.5267 | val_auc=0.6492\n",
            "Epoch 090 | train_loss=0.6737 | val_loss=0.7124 | val_acc=0.5093 | val_auc=0.6484\n",
            "Epoch 091 | train_loss=0.6755 | val_loss=0.7116 | val_acc=0.5067 | val_auc=0.6526\n",
            "Epoch 092 | train_loss=0.6736 | val_loss=0.7120 | val_acc=0.4973 | val_auc=0.6524\n",
            "Epoch 093 | train_loss=0.6780 | val_loss=0.7099 | val_acc=0.5253 | val_auc=0.6527\n",
            "Epoch 094 | train_loss=0.6727 | val_loss=0.7122 | val_acc=0.4973 | val_auc=0.6503\n",
            "Epoch 095 | train_loss=0.6697 | val_loss=0.7120 | val_acc=0.5120 | val_auc=0.6509\n",
            "Epoch 096 | train_loss=0.6727 | val_loss=0.7099 | val_acc=0.5200 | val_auc=0.6516\n",
            "Epoch 097 | train_loss=0.6797 | val_loss=0.7111 | val_acc=0.5053 | val_auc=0.6516\n",
            "Epoch 098 | train_loss=0.6699 | val_loss=0.7109 | val_acc=0.5160 | val_auc=0.6514\n",
            "Epoch 099 | train_loss=0.6718 | val_loss=0.7105 | val_acc=0.5227 | val_auc=0.6517\n",
            "Epoch 100 | train_loss=0.6684 | val_loss=0.7106 | val_acc=0.5240 | val_auc=0.6521\n",
            "Epoch 101 | train_loss=0.6763 | val_loss=0.7130 | val_acc=0.5013 | val_auc=0.6512\n",
            "Epoch 102 | train_loss=0.6741 | val_loss=0.7121 | val_acc=0.5133 | val_auc=0.6507\n",
            "Epoch 103 | train_loss=0.6745 | val_loss=0.7133 | val_acc=0.4960 | val_auc=0.6492\n",
            "Epoch 104 | train_loss=0.6718 | val_loss=0.7112 | val_acc=0.5347 | val_auc=0.6496\n",
            "Epoch 105 | train_loss=0.6707 | val_loss=0.7120 | val_acc=0.5147 | val_auc=0.6516\n",
            "Epoch 106 | train_loss=0.6770 | val_loss=0.7127 | val_acc=0.5080 | val_auc=0.6512\n",
            "Epoch 107 | train_loss=0.6737 | val_loss=0.7119 | val_acc=0.5053 | val_auc=0.6505\n",
            "Epoch 108 | train_loss=0.6717 | val_loss=0.7114 | val_acc=0.5253 | val_auc=0.6508\n",
            "Epoch 109 | train_loss=0.6782 | val_loss=0.7121 | val_acc=0.5227 | val_auc=0.6514\n",
            "Epoch 110 | train_loss=0.6686 | val_loss=0.7120 | val_acc=0.5253 | val_auc=0.6501\n",
            "Epoch 111 | train_loss=0.6700 | val_loss=0.7117 | val_acc=0.5160 | val_auc=0.6521\n",
            "Epoch 112 | train_loss=0.6693 | val_loss=0.7138 | val_acc=0.5040 | val_auc=0.6498\n",
            "Epoch 113 | train_loss=0.6701 | val_loss=0.7129 | val_acc=0.5053 | val_auc=0.6499\n",
            "Epoch 114 | train_loss=0.6711 | val_loss=0.7123 | val_acc=0.5160 | val_auc=0.6499\n",
            "Epoch 115 | train_loss=0.6665 | val_loss=0.7124 | val_acc=0.5213 | val_auc=0.6509\n",
            "Epoch 116 | train_loss=0.6707 | val_loss=0.7115 | val_acc=0.5133 | val_auc=0.6514\n",
            "Epoch 117 | train_loss=0.6726 | val_loss=0.7122 | val_acc=0.5160 | val_auc=0.6516\n",
            "Epoch 118 | train_loss=0.6729 | val_loss=0.7127 | val_acc=0.5120 | val_auc=0.6508\n",
            "Epoch 119 | train_loss=0.6749 | val_loss=0.7128 | val_acc=0.5187 | val_auc=0.6521\n",
            "Epoch 120 | train_loss=0.6750 | val_loss=0.7129 | val_acc=0.4960 | val_auc=0.6515\n",
            "Epoch 121 | train_loss=0.6686 | val_loss=0.7115 | val_acc=0.5267 | val_auc=0.6509\n",
            "Epoch 122 | train_loss=0.6746 | val_loss=0.7109 | val_acc=0.5267 | val_auc=0.6517\n",
            "Epoch 123 | train_loss=0.6723 | val_loss=0.7121 | val_acc=0.5320 | val_auc=0.6501\n",
            "Epoch 124 | train_loss=0.6723 | val_loss=0.7134 | val_acc=0.5013 | val_auc=0.6522\n",
            "Early stopping triggered.\n",
            "Test | loss=0.7167 | acc=0.4853 | auc=0.6380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GraphSAGE + Residual + GlobalAttention, 5000，hidden channels 128\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv, GlobalAttention\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import numpy as np\n",
        "\n",
        "import importlib\n",
        "import data\n",
        "importlib.reload(data)\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "class ResidueGNNClassifier(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=128, num_classes=2, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.res1 = nn.Linear(in_channels, hidden_channels)\n",
        "\n",
        "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.res2 = nn.Identity()\n",
        "\n",
        "        self.conv3 = SAGEConv(hidden_channels, hidden_channels)\n",
        "        self.bn3 = nn.BatchNorm1d(hidden_channels)\n",
        "        self.res3 = nn.Identity()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.pool = GlobalAttention(gate_nn=nn.Linear(hidden_channels, 1))\n",
        "        self.fc = nn.Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        h = self.conv1(x, edge_index) + self.res1(x)\n",
        "        h = self.bn1(h)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        h = self.conv2(h, edge_index) + self.res2(h)\n",
        "        h = self.bn2(h)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        h = self.conv3(h, edge_index) + self.res3(h)\n",
        "        h = self.bn3(h)\n",
        "        h = F.relu(h)\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "\n",
        "        h = self.pool(h, batch)\n",
        "        logits = self.fc(h)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(data)\n",
        "        y = data.y.view(-1).long()\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * data.num_graphs\n",
        "        total_graphs += data.num_graphs\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_graphs = 0\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).long()\n",
        "            loss = criterion(logits, y)\n",
        "\n",
        "            probs = torch.softmax(logits, dim=1)[:, 1].detach().cpu()\n",
        "            labels = y.detach().cpu()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            total_graphs += data.num_graphs\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    avg_loss = total_loss / max(total_graphs, 1)\n",
        "\n",
        "    all_probs = torch.cat(all_probs) if all_probs else torch.tensor([])\n",
        "    all_labels = torch.cat(all_labels) if all_labels else torch.tensor([])\n",
        "\n",
        "    if all_probs.numel() == 0:\n",
        "        return avg_loss, float(\"nan\"), float(\"nan\")\n",
        "\n",
        "    preds = (all_probs >= 0.5).long()\n",
        "    acc = (preds == all_labels).float().mean().item()\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels.numpy(), all_probs.numpy())\n",
        "    except Exception:\n",
        "        auc = float(\"nan\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 读取残基特征表\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "\n",
        "    meta_cols = [\"1-Letter\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    print(\"Total peptides in dataset:\", len(dataset))\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    print(\"Train size:\", len(train_dataset))\n",
        "    print(\"Val size:\", len(val_dataset))\n",
        "    print(\"Test size:\", len(test_dataset))\n",
        "\n",
        "    in_channels = dataset[0].x.shape[1]\n",
        "    print(\"In channels:\", in_channels)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model = ResidueGNNClassifier(\n",
        "        in_channels, hidden_channels=128, num_classes=2, dropout=0.5\n",
        "    ).to(device)\n",
        "\n",
        "    weights = torch.tensor([1.0, 4.0]).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode=\"max\", factor=0.5, patience=10\n",
        "    )\n",
        "\n",
        "    max_epochs = 300\n",
        "    patience = 50\n",
        "    best_val_auc = -1.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_path = \"best_residue_gnn.pt\"\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_auc if not np.isnan(val_auc) else -1.0)\n",
        "\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
        "    test_loss, test_acc, test_auc = evaluate(model, test_loader, criterion, device)\n",
        "    print(f\"Test | loss={test_loss:.4f} | acc={test_acc:.4f} | auc={test_auc:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QHjRY-ZYMjuW",
        "outputId": "77472b7b-52e0-4e45-bad2-eb87b702bbf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Total peptides in dataset: 5000\n",
            "Train size: 3500\n",
            "Val size: 750\n",
            "Test size: 750\n",
            "In channels: 74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1808841299.py:53: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
            "  self.pool = GlobalAttention(gate_nn=nn.Linear(hidden_channels, 1))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_loss=0.6949 | val_loss=0.6868 | val_acc=0.5147 | val_auc=0.5690\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'dtype torch.float32 is not recognized'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_pickle_storage_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_dtype_to_storage_type_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: torch.float32",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1808841299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1808841299.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mbest_val_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mepochs_no_improve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mepochs_no_improve\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             _save(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m   1208\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[name-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1210\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_id\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_untyped_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m                 \u001b[0mstorage_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m                 \u001b[0mstorage_type_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pickle_storage_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_type_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mstorage_numel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_pickle_storage_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1236\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_dtype_to_storage_type_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dtype {self.dtype} is not recognized\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dtype torch.float32 is not recognized'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.GIN"
      ],
      "metadata": {
        "id": "_XljNtwfYXy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, global_add_pool, global_mean_pool\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "############################################\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        # BatchNorm for each GIN layer\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "############################################\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    in_dim = dataset[0].x.shape[1]\n",
        "    model = GINVirtualNodeClassifier(in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device=device,\n",
        "        lr=1e-3,\n",
        "        epochs=200,\n",
        "        patience=20,\n",
        "        model_path=\"best_gin_vn.pt\",\n",
        "    )\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    model.load_state_dict(torch.load(\"best_gin_vn.pt\", map_location=device))\n",
        "\n",
        "    # Find best threshold on validation set\n",
        "    val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "    best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "    print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "    # Evaluate on test with best threshold\n",
        "    metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "    print(\"\\nTest metrics:\")\n",
        "    print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "    print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "    print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "    print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "    print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "    print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "    print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6qs_bISfzyD",
        "outputId": "1dacdc87-f97c-40b3-f7d6-a51355d399c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.4-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.9.4-cp312-cp312-manylinux_2_28_x86_64.whl (36.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.6/36.6 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.4\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2+pt23cu121 torch-sparse-0.6.18+pt23cu121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n",
            "  import torch_geometric.typing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_loss=1.0825 | val_loss=1.0824 | val_auc=0.6068853347790729 | val_f1=0.3747\n",
            "Epoch 002 | train_loss=1.0547 | val_loss=1.0682 | val_auc=0.6394361615613988 | val_f1=0.3843\n",
            "Epoch 003 | train_loss=1.0525 | val_loss=1.0610 | val_auc=0.6114719436161562 | val_f1=0.3475\n",
            "Epoch 004 | train_loss=1.0302 | val_loss=1.0911 | val_auc=0.6159934941718623 | val_f1=0.2727\n",
            "Epoch 005 | train_loss=1.0424 | val_loss=1.0661 | val_auc=0.648847926267281 | val_f1=0.3377\n",
            "Epoch 006 | train_loss=1.0321 | val_loss=1.0556 | val_auc=0.6579018704255897 | val_f1=0.3883\n",
            "Epoch 007 | train_loss=1.0255 | val_loss=1.0576 | val_auc=0.6514827866630524 | val_f1=0.3815\n",
            "Epoch 008 | train_loss=1.0225 | val_loss=1.0411 | val_auc=0.6629222011385199 | val_f1=0.4056\n",
            "Epoch 009 | train_loss=1.0125 | val_loss=1.0283 | val_auc=0.6739929520195175 | val_f1=0.3652\n",
            "Epoch 010 | train_loss=1.0048 | val_loss=1.0235 | val_auc=0.6578910273786935 | val_f1=0.3966\n",
            "Epoch 011 | train_loss=1.0012 | val_loss=1.0267 | val_auc=0.6635836269991867 | val_f1=0.3535\n",
            "Epoch 012 | train_loss=1.0023 | val_loss=1.0483 | val_auc=0.6650365952832745 | val_f1=0.3926\n",
            "Epoch 013 | train_loss=0.9882 | val_loss=1.1938 | val_auc=0.6631282190295473 | val_f1=0.3737\n",
            "Epoch 014 | train_loss=0.9932 | val_loss=1.0405 | val_auc=0.6688858769314177 | val_f1=0.3657\n",
            "Epoch 015 | train_loss=0.9865 | val_loss=1.1118 | val_auc=0.6533477907291949 | val_f1=0.3898\n",
            "Epoch 016 | train_loss=0.9870 | val_loss=1.0574 | val_auc=0.6360314448359989 | val_f1=0.3799\n",
            "Epoch 017 | train_loss=0.9813 | val_loss=1.0341 | val_auc=0.6702737869341286 | val_f1=0.3610\n",
            "Epoch 018 | train_loss=0.9833 | val_loss=1.0487 | val_auc=0.6681377066955814 | val_f1=0.4053\n",
            "Epoch 019 | train_loss=0.9644 | val_loss=1.0440 | val_auc=0.6685605855245325 | val_f1=0.3823\n",
            "Epoch 020 | train_loss=0.9691 | val_loss=1.0622 | val_auc=0.6617077798861479 | val_f1=0.3435\n",
            "Epoch 021 | train_loss=0.9622 | val_loss=1.0541 | val_auc=0.6664570344266738 | val_f1=0.4000\n",
            "Epoch 022 | train_loss=0.9640 | val_loss=1.0730 | val_auc=0.6504743833017077 | val_f1=0.3716\n",
            "Epoch 023 | train_loss=0.9539 | val_loss=1.0884 | val_auc=0.6518731363513147 | val_f1=0.3929\n",
            "Epoch 024 | train_loss=0.9528 | val_loss=1.0781 | val_auc=0.6586283545676335 | val_f1=0.3158\n",
            "Epoch 025 | train_loss=0.9483 | val_loss=1.0544 | val_auc=0.6638763892653835 | val_f1=0.3951\n",
            "Epoch 026 | train_loss=0.9459 | val_loss=1.1282 | val_auc=0.6729194903767959 | val_f1=0.3980\n",
            "Epoch 027 | train_loss=0.9507 | val_loss=1.0642 | val_auc=0.6529032258064517 | val_f1=0.3597\n",
            "Epoch 028 | train_loss=0.9253 | val_loss=1.0471 | val_auc=0.6773326104635403 | val_f1=0.3758\n",
            "Epoch 029 | train_loss=0.9178 | val_loss=1.1017 | val_auc=0.6380048793711032 | val_f1=0.3246\n",
            "Epoch 030 | train_loss=0.9243 | val_loss=1.0357 | val_auc=0.6734399566278124 | val_f1=0.3966\n",
            "Epoch 031 | train_loss=0.9031 | val_loss=1.0921 | val_auc=0.6381458389807535 | val_f1=0.3935\n",
            "Epoch 032 | train_loss=0.9027 | val_loss=1.0574 | val_auc=0.6738845215505558 | val_f1=0.4167\n",
            "Epoch 033 | train_loss=0.9240 | val_loss=1.0733 | val_auc=0.6683762537272974 | val_f1=0.3952\n",
            "Epoch 034 | train_loss=0.9014 | val_loss=1.0782 | val_auc=0.6338628354567634 | val_f1=0.3750\n",
            "Epoch 035 | train_loss=0.8999 | val_loss=1.0989 | val_auc=0.6573055028462998 | val_f1=0.3876\n",
            "Epoch 036 | train_loss=0.8809 | val_loss=1.1509 | val_auc=0.6496503117375982 | val_f1=0.3887\n",
            "Epoch 037 | train_loss=0.8633 | val_loss=1.0741 | val_auc=0.6727026294388724 | val_f1=0.4200\n",
            "Epoch 038 | train_loss=0.8729 | val_loss=1.1000 | val_auc=0.661339116291678 | val_f1=0.4000\n",
            "Epoch 039 | train_loss=0.8698 | val_loss=1.0843 | val_auc=0.6673678503659529 | val_f1=0.4111\n",
            "Epoch 040 | train_loss=0.8579 | val_loss=1.1614 | val_auc=0.6183898075359175 | val_f1=0.3527\n",
            "Epoch 041 | train_loss=0.8594 | val_loss=1.1452 | val_auc=0.661653564651667 | val_f1=0.4047\n",
            "Epoch 042 | train_loss=0.8321 | val_loss=1.1527 | val_auc=0.6433179723502304 | val_f1=0.3768\n",
            "Epoch 043 | train_loss=0.8313 | val_loss=1.1565 | val_auc=0.6548766603415561 | val_f1=0.4147\n",
            "Epoch 044 | train_loss=0.8322 | val_loss=1.2007 | val_auc=0.6417565735971807 | val_f1=0.3834\n",
            "Epoch 045 | train_loss=0.8347 | val_loss=1.1759 | val_auc=0.6406831119544592 | val_f1=0.3791\n",
            "Epoch 046 | train_loss=0.8003 | val_loss=1.2124 | val_auc=0.6448685280563837 | val_f1=0.3596\n",
            "Epoch 047 | train_loss=0.8024 | val_loss=1.1786 | val_auc=0.6263486039577121 | val_f1=0.3538\n",
            "Epoch 048 | train_loss=0.7970 | val_loss=1.2212 | val_auc=0.6301978856058552 | val_f1=0.3649\n",
            "Best threshold on VAL: t=0.39 | F1=0.4308 | Precision=0.3322 | Recall=0.6129\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6571\n",
            "PR-AUC: 0.3761\n",
            "Accuracy: 0.6307\n",
            "F1: 0.3939\n",
            "Precision: 0.2980\n",
            "Recall: 0.5806\n",
            "Confusion matrix:\n",
            "[[383 212]\n",
            " [ 65  90]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 加 weight_decay + 学习率调度（ReduceLROnPlateau）"
      ],
      "metadata": {
        "id": "yYFiG82lnOhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, global_add_pool, global_mean_pool\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        "    build_loaders,\n",
        ")\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "        # verbose=True, # Removed 'verbose' argument as it's deprecated\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=42)\n",
        "    train_loader, val_loader, test_loader = build_loaders(\n",
        "        train_dataset, val_dataset, test_dataset, batch_size=32\n",
        "    )\n",
        "\n",
        "    in_dim = dataset[0].x.shape[1]\n",
        "    model = GINVirtualNodeClassifier(in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        device=device,\n",
        "        lr=1e-3,\n",
        "        weight_decay=1e-4,\n",
        "        epochs=200,\n",
        "        patience=20,\n",
        "        model_path=\"best_gin_vn.pt\",\n",
        "    )\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    model.load_state_dict(torch.load(\"best_gin_vn.pt\", map_location=device))\n",
        "\n",
        "    val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "    best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "    print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "    metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "    print(\n",
        "        \"\\nTest metrics:\"\n",
        "    )\n",
        "    print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "    print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "    print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "    print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "    print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "    print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "    print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SYTPu0inOAy",
        "outputId": "dfe92a7f-d9dc-4301-fc40-1ade083d0c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0802 | val_loss=1.1814 | val_auc=0.5703767958796422 | val_f1=0.1058\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0537 | val_loss=1.1481 | val_auc=0.6124044456492274 | val_f1=0.3509\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0537 | val_loss=1.1216 | val_auc=0.6316725399837353 | val_f1=0.3756\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0361 | val_loss=1.0394 | val_auc=0.6592572512876118 | val_f1=0.3936\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0442 | val_loss=1.0570 | val_auc=0.6353591759284359 | val_f1=0.3800\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0348 | val_loss=1.0498 | val_auc=0.6634047167254 | val_f1=0.3747\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0204 | val_loss=1.0634 | val_auc=0.6424396855516399 | val_f1=0.3354\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0261 | val_loss=1.0280 | val_auc=0.6711087015451341 | val_f1=0.4000\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0119 | val_loss=1.0415 | val_auc=0.6551802656546489 | val_f1=0.3925\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0166 | val_loss=1.0444 | val_auc=0.6539875304960694 | val_f1=0.3775\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0079 | val_loss=1.0560 | val_auc=0.6549742477636216 | val_f1=0.3913\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0067 | val_loss=1.0361 | val_auc=0.6778422336676605 | val_f1=0.4081\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0043 | val_loss=1.1030 | val_auc=0.6508213608023854 | val_f1=0.3788\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.9984 | val_loss=1.0623 | val_auc=0.6417674166440769 | val_f1=0.3540\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9711 | val_loss=1.0470 | val_auc=0.6662835456763351 | val_f1=0.3992\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9675 | val_loss=1.0481 | val_auc=0.6699701816210355 | val_f1=0.4041\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9611 | val_loss=1.0501 | val_auc=0.663475196530225 | val_f1=0.3957\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9606 | val_loss=1.0628 | val_auc=0.6602548116020601 | val_f1=0.3733\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9617 | val_loss=1.0483 | val_auc=0.657619951206289 | val_f1=0.3951\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9510 | val_loss=1.0482 | val_auc=0.6609596096503118 | val_f1=0.3739\n",
            "Epoch 021 | lr=0.000250 | train_loss=0.9245 | val_loss=1.0558 | val_auc=0.6671076172404447 | val_f1=0.3820\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9208 | val_loss=1.0552 | val_auc=0.6624993223095691 | val_f1=0.3800\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9113 | val_loss=1.0590 | val_auc=0.660916237462727 | val_f1=0.3939\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9145 | val_loss=1.0735 | val_auc=0.6529465979940363 | val_f1=0.3756\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9063 | val_loss=1.1335 | val_auc=0.6493575494714015 | val_f1=0.3789\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8942 | val_loss=1.0935 | val_auc=0.6578801843317973 | val_f1=0.3747\n",
            "Epoch 027 | lr=0.000125 | train_loss=0.8724 | val_loss=1.0946 | val_auc=0.651211710490648 | val_f1=0.3717\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8514 | val_loss=1.1228 | val_auc=0.6609596096503118 | val_f1=0.3946\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8684 | val_loss=1.0929 | val_auc=0.6536947682298726 | val_f1=0.3839\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8411 | val_loss=1.1399 | val_auc=0.6492708050962319 | val_f1=0.3725\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8409 | val_loss=1.1545 | val_auc=0.6340905394415831 | val_f1=0.3616\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8394 | val_loss=1.1312 | val_auc=0.6478937381404175 | val_f1=0.3828\n",
            "Best threshold on VAL: t=0.49 | F1=0.4195 | Precision=0.3373 | Recall=0.5548\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6591\n",
            "PR-AUC: 0.3879\n",
            "Accuracy: 0.6773\n",
            "F1: 0.4265\n",
            "Precision: 0.3371\n",
            "Recall: 0.5806\n",
            "Confusion matrix:\n",
            "[[418 177]\n",
            " [ 65  90]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### set seed for running models"
      ],
      "metadata": {
        "id": "cbiA3XROvdPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWS1C7vyyvG5",
        "outputId": "20130d58-403b-4146-9d78-2d8214939c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_scatter/_version_cuda.so\n",
            "  import torch_geometric.typing\n",
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py:4: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: Could not load this library: /usr/local/lib/python3.12/dist-packages/torch_sparse/_version_cuda.so\n",
            "  import torch_geometric.typing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0917 | val_loss=1.0681 | val_auc=0.6587638926538358 | val_f1=0.3901\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0655 | val_loss=1.0684 | val_auc=0.6289997289238276 | val_f1=0.3524\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0515 | val_loss=1.0678 | val_auc=0.606218487394958 | val_f1=0.3573\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0450 | val_loss=1.0478 | val_auc=0.6584928164814313 | val_f1=0.4000\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0278 | val_loss=1.0520 | val_auc=0.6472919490376796 | val_f1=0.3862\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0239 | val_loss=1.0834 | val_auc=0.6691623746272702 | val_f1=0.3993\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0228 | val_loss=1.0483 | val_auc=0.6545459474112225 | val_f1=0.3967\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0159 | val_loss=1.0590 | val_auc=0.647931688804554 | val_f1=0.3795\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0069 | val_loss=1.1211 | val_auc=0.6709406343182436 | val_f1=0.4056\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0125 | val_loss=1.0711 | val_auc=0.6482461371645432 | val_f1=0.3306\n",
            "Epoch 011 | lr=0.000500 | train_loss=0.9903 | val_loss=1.0394 | val_auc=0.6697912713472487 | val_f1=0.4199\n",
            "Epoch 012 | lr=0.000500 | train_loss=0.9733 | val_loss=1.0472 | val_auc=0.676405529953917 | val_f1=0.3953\n",
            "Epoch 013 | lr=0.000500 | train_loss=0.9639 | val_loss=1.0590 | val_auc=0.6731526158850636 | val_f1=0.3976\n",
            "Epoch 014 | lr=0.000500 | train_loss=0.9706 | val_loss=1.0551 | val_auc=0.6633396584440228 | val_f1=0.3852\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9576 | val_loss=1.0495 | val_auc=0.6717430197885605 | val_f1=0.4305\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9495 | val_loss=1.0944 | val_auc=0.641339116291678 | val_f1=0.4026\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9371 | val_loss=1.0723 | val_auc=0.662005963675793 | val_f1=0.3853\n",
            "Epoch 018 | lr=0.000250 | train_loss=0.9220 | val_loss=1.0879 | val_auc=0.6535158579560858 | val_f1=0.3852\n",
            "Epoch 019 | lr=0.000250 | train_loss=0.9096 | val_loss=1.0951 | val_auc=0.6536513960422878 | val_f1=0.3807\n",
            "Epoch 020 | lr=0.000250 | train_loss=0.9019 | val_loss=1.0950 | val_auc=0.6657901870425589 | val_f1=0.4147\n",
            "Epoch 021 | lr=0.000250 | train_loss=0.8828 | val_loss=1.1029 | val_auc=0.6537001897533206 | val_f1=0.3848\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.8891 | val_loss=1.0640 | val_auc=0.6782054757386826 | val_f1=0.4067\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.8821 | val_loss=1.1436 | val_auc=0.6385524532393602 | val_f1=0.3695\n",
            "Epoch 024 | lr=0.000125 | train_loss=0.8644 | val_loss=1.1364 | val_auc=0.6515586879913255 | val_f1=0.3807\n",
            "Epoch 025 | lr=0.000125 | train_loss=0.8362 | val_loss=1.1598 | val_auc=0.6515424234209813 | val_f1=0.3750\n",
            "Epoch 026 | lr=0.000125 | train_loss=0.8326 | val_loss=1.1748 | val_auc=0.6527568446733532 | val_f1=0.3812\n",
            "Epoch 027 | lr=0.000125 | train_loss=0.8372 | val_loss=1.1718 | val_auc=0.6468690702087285 | val_f1=0.3618\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8219 | val_loss=1.1886 | val_auc=0.6458444022770399 | val_f1=0.3702\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8266 | val_loss=1.1848 | val_auc=0.6490214150176199 | val_f1=0.3618\n",
            "Epoch 030 | lr=0.000063 | train_loss=0.7972 | val_loss=1.1732 | val_auc=0.6470967741935485 | val_f1=0.3837\n",
            "Epoch 031 | lr=0.000063 | train_loss=0.7911 | val_loss=1.2273 | val_auc=0.6423800487937111 | val_f1=0.3775\n",
            "Epoch 032 | lr=0.000063 | train_loss=0.7976 | val_loss=1.2345 | val_auc=0.6409867172675522 | val_f1=0.3684\n",
            "Epoch 033 | lr=0.000063 | train_loss=0.7955 | val_loss=1.2541 | val_auc=0.6237029005150447 | val_f1=0.3297\n",
            "Epoch 034 | lr=0.000063 | train_loss=0.7820 | val_loss=1.2468 | val_auc=0.626462455950122 | val_f1=0.3402\n",
            "Epoch 035 | lr=0.000063 | train_loss=0.7981 | val_loss=1.2087 | val_auc=0.6426511249661156 | val_f1=0.3726\n",
            "Epoch 036 | lr=0.000031 | train_loss=0.7555 | val_loss=1.2335 | val_auc=0.6417565735971806 | val_f1=0.3660\n",
            "Epoch 037 | lr=0.000031 | train_loss=0.7673 | val_loss=1.2561 | val_auc=0.6262022228246137 | val_f1=0.3396\n",
            "Epoch 038 | lr=0.000031 | train_loss=0.7536 | val_loss=1.2211 | val_auc=0.6395391705069123 | val_f1=0.3789\n",
            "Epoch 039 | lr=0.000031 | train_loss=0.7488 | val_loss=1.3196 | val_auc=0.6160531309297913 | val_f1=0.3367\n",
            "Epoch 040 | lr=0.000031 | train_loss=0.7612 | val_loss=1.3122 | val_auc=0.6179777717538628 | val_f1=0.3351\n",
            "Epoch 041 | lr=0.000031 | train_loss=0.7400 | val_loss=1.2852 | val_auc=0.6239360260233124 | val_f1=0.3469\n",
            "Epoch 042 | lr=0.000016 | train_loss=0.7621 | val_loss=1.2928 | val_auc=0.6222824613716456 | val_f1=0.3308\n",
            "Best threshold on VAL: t=0.42 | F1=0.4262 | Precision=0.3123 | Recall=0.6710\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6489\n",
            "PR-AUC: 0.3817\n",
            "Accuracy: 0.5827\n",
            "F1: 0.3826\n",
            "Precision: 0.2756\n",
            "Recall: 0.6258\n",
            "Confusion matrix:\n",
            "[[340 255]\n",
            " [ 58  97]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0949 | val_loss=1.0630 | val_auc=0.6176958525345622 | val_f1=0.3282\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0648 | val_loss=1.0727 | val_auc=0.620428300352399 | val_f1=0.3758\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0543 | val_loss=1.0463 | val_auc=0.6358037408511792 | val_f1=0.3784\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0482 | val_loss=1.0326 | val_auc=0.6462781241528869 | val_f1=0.3553\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0437 | val_loss=1.0530 | val_auc=0.6349688262401735 | val_f1=0.3504\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0344 | val_loss=1.0367 | val_auc=0.6719327731092436 | val_f1=0.3292\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0319 | val_loss=1.0528 | val_auc=0.6458444022770398 | val_f1=0.3578\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0336 | val_loss=1.0210 | val_auc=0.6756194090539442 | val_f1=0.3934\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0268 | val_loss=1.0285 | val_auc=0.6709135267010029 | val_f1=0.4000\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0355 | val_loss=1.0152 | val_auc=0.6879371103280021 | val_f1=0.3856\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0048 | val_loss=0.9945 | val_auc=0.696036866359447 | val_f1=0.3959\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0004 | val_loss=1.0243 | val_auc=0.6812577934399565 | val_f1=0.3885\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0086 | val_loss=1.0385 | val_auc=0.6733206831119545 | val_f1=0.3978\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0132 | val_loss=1.0423 | val_auc=0.6508972621306586 | val_f1=0.3590\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9962 | val_loss=1.0398 | val_auc=0.6465058281377067 | val_f1=0.3719\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0054 | val_loss=1.0072 | val_auc=0.6971862293304418 | val_f1=0.3799\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9918 | val_loss=1.0333 | val_auc=0.6455407969639468 | val_f1=0.3649\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9737 | val_loss=1.0715 | val_auc=0.6381458389807537 | val_f1=0.3678\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9664 | val_loss=1.0674 | val_auc=0.6535754947140147 | val_f1=0.3673\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9597 | val_loss=1.0315 | val_auc=0.6698509081051776 | val_f1=0.3687\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9500 | val_loss=1.0222 | val_auc=0.6704472756844673 | val_f1=0.3905\n",
            "Epoch 022 | lr=0.000500 | train_loss=0.9395 | val_loss=1.0420 | val_auc=0.6537923556519383 | val_f1=0.3696\n",
            "Epoch 023 | lr=0.000500 | train_loss=0.9354 | val_loss=1.0424 | val_auc=0.6495418812686365 | val_f1=0.3765\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9173 | val_loss=1.0804 | val_auc=0.6428300352399025 | val_f1=0.3518\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9019 | val_loss=1.0682 | val_auc=0.6494226077527785 | val_f1=0.3540\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8660 | val_loss=1.1031 | val_auc=0.6422607752778531 | val_f1=0.3772\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.8746 | val_loss=1.1047 | val_auc=0.6588777446462455 | val_f1=0.3714\n",
            "Epoch 028 | lr=0.000250 | train_loss=0.8547 | val_loss=1.2094 | val_auc=0.6160802385470318 | val_f1=0.3370\n",
            "Epoch 029 | lr=0.000250 | train_loss=0.8499 | val_loss=1.2185 | val_auc=0.6066684738411492 | val_f1=0.3561\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8221 | val_loss=1.2040 | val_auc=0.6140417457305503 | val_f1=0.3550\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8143 | val_loss=1.2117 | val_auc=0.6213065871509894 | val_f1=0.3667\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8014 | val_loss=1.2012 | val_auc=0.6289943074003794 | val_f1=0.3694\n",
            "Epoch 033 | lr=0.000125 | train_loss=0.7985 | val_loss=1.2355 | val_auc=0.619387367850366 | val_f1=0.3583\n",
            "Epoch 034 | lr=0.000125 | train_loss=0.7777 | val_loss=1.2527 | val_auc=0.6273244781783681 | val_f1=0.3628\n",
            "Epoch 035 | lr=0.000125 | train_loss=0.7767 | val_loss=1.3199 | val_auc=0.6202114394144754 | val_f1=0.3778\n",
            "Epoch 036 | lr=0.000063 | train_loss=0.7559 | val_loss=1.3458 | val_auc=0.6210897262130659 | val_f1=0.3622\n",
            "Best threshold on VAL: t=0.44 | F1=0.4190 | Precision=0.2973 | Recall=0.7097\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6904\n",
            "PR-AUC: 0.3879\n",
            "Accuracy: 0.5920\n",
            "F1: 0.4205\n",
            "Precision: 0.2976\n",
            "Recall: 0.7161\n",
            "Confusion matrix:\n",
            "[[333 262]\n",
            " [ 44 111]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0892 | val_loss=1.0468 | val_auc=0.6465817294659799 | val_f1=0.3556\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0656 | val_loss=1.0615 | val_auc=0.6222390891840607 | val_f1=0.3453\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0580 | val_loss=1.0540 | val_auc=0.6409433450799674 | val_f1=0.3071\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0598 | val_loss=1.0421 | val_auc=0.6645486581729465 | val_f1=0.4032\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0464 | val_loss=1.0402 | val_auc=0.666825698021144 | val_f1=0.3418\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0340 | val_loss=1.0626 | val_auc=0.6652317701274058 | val_f1=0.3833\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0299 | val_loss=1.0210 | val_auc=0.6738194632691786 | val_f1=0.3696\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0217 | val_loss=1.0191 | val_auc=0.6774952561669829 | val_f1=0.4059\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0236 | val_loss=1.0187 | val_auc=0.67512062889672 | val_f1=0.3877\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0074 | val_loss=1.0672 | val_auc=0.6395337489834644 | val_f1=0.3214\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0218 | val_loss=1.0428 | val_auc=0.6361398753049605 | val_f1=0.3712\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0143 | val_loss=1.0255 | val_auc=0.6842396313364055 | val_f1=0.4274\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0173 | val_loss=1.0254 | val_auc=0.7007102195716997 | val_f1=0.4223\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.9961 | val_loss=1.0421 | val_auc=0.6538682569802113 | val_f1=0.3916\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9976 | val_loss=1.0091 | val_auc=0.6978368121442124 | val_f1=0.4235\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9998 | val_loss=1.0371 | val_auc=0.6576741664407699 | val_f1=0.3950\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9925 | val_loss=1.0231 | val_auc=0.6757278395229059 | val_f1=0.3955\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.9886 | val_loss=1.0522 | val_auc=0.6679587964217946 | val_f1=0.3855\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.9889 | val_loss=1.0051 | val_auc=0.6994415830848468 | val_f1=0.4268\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.9972 | val_loss=1.0291 | val_auc=0.6835456763350503 | val_f1=0.3883\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9888 | val_loss=1.0596 | val_auc=0.6400216860937924 | val_f1=0.3780\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.9774 | val_loss=1.0093 | val_auc=0.6883166169693684 | val_f1=0.4027\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9656 | val_loss=1.0257 | val_auc=0.6682027649769584 | val_f1=0.4066\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9690 | val_loss=1.0196 | val_auc=0.6786229330441854 | val_f1=0.4270\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9597 | val_loss=1.0549 | val_auc=0.6695906749796693 | val_f1=0.3980\n",
            "Epoch 026 | lr=0.000500 | train_loss=0.9307 | val_loss=1.0656 | val_auc=0.6634643534833289 | val_f1=0.4009\n",
            "Epoch 027 | lr=0.000500 | train_loss=0.9037 | val_loss=1.0963 | val_auc=0.6503225806451614 | val_f1=0.4029\n",
            "Epoch 028 | lr=0.000500 | train_loss=0.9072 | val_loss=1.0510 | val_auc=0.6600487937110329 | val_f1=0.3901\n",
            "Epoch 029 | lr=0.000500 | train_loss=0.8969 | val_loss=1.1117 | val_auc=0.630902683654107 | val_f1=0.3791\n",
            "Epoch 030 | lr=0.000500 | train_loss=0.8813 | val_loss=1.1573 | val_auc=0.6138248847926266 | val_f1=0.3773\n",
            "Epoch 031 | lr=0.000500 | train_loss=0.8799 | val_loss=1.1538 | val_auc=0.6434264028191923 | val_f1=0.3750\n",
            "Epoch 032 | lr=0.000250 | train_loss=0.8651 | val_loss=1.1817 | val_auc=0.6314556790458118 | val_f1=0.3910\n",
            "Epoch 033 | lr=0.000250 | train_loss=0.8363 | val_loss=1.1817 | val_auc=0.6325508267823259 | val_f1=0.3828\n",
            "Best threshold on VAL: t=0.56 | F1=0.4329 | Precision=0.3407 | Recall=0.5935\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6727\n",
            "PR-AUC: 0.4144\n",
            "Accuracy: 0.6640\n",
            "F1: 0.4167\n",
            "Precision: 0.3249\n",
            "Recall: 0.5806\n",
            "Confusion matrix:\n",
            "[[408 187]\n",
            " [ 65  90]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6707 ± 0.0170\n",
            "PR-AUC:  0.3947 ± 0.0142\n",
            "F1:      0.4066 ± 0.0170\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### GINEConv + edge_attr"
      ],
      "metadata": {
        "id": "N3d0gU1r2eiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GINEConv\n",
        "\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!{sys.executable} -m pip install rdkit  # install rdkit\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "else:\n",
        "    !{sys.executable} -m pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cpu.html\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la5d4Tff2fjT",
        "outputId": "8ce74a6e-efbc-437b-b415-9c29c03fd4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit in /usr/local/lib/python3.12/dist-packages (2025.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0998 | val_loss=1.0714 | val_auc=0.6447167253998374 | val_f1=0.3916\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0724 | val_loss=1.0458 | val_auc=0.6482515586879912 | val_f1=0.3901\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0553 | val_loss=1.0617 | val_auc=0.6221198156682027 | val_f1=0.3775\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0507 | val_loss=1.0492 | val_auc=0.6444239631336406 | val_f1=0.3761\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0340 | val_loss=1.0479 | val_auc=0.6686907020872864 | val_f1=0.3407\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0297 | val_loss=1.0340 | val_auc=0.6750447275684467 | val_f1=0.4013\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0286 | val_loss=1.0858 | val_auc=0.6126538357278395 | val_f1=0.3613\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0245 | val_loss=1.0630 | val_auc=0.6485009487666035 | val_f1=0.3873\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0119 | val_loss=1.0444 | val_auc=0.6535754947140147 | val_f1=0.4048\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0031 | val_loss=1.0539 | val_auc=0.6532610463540254 | val_f1=0.3371\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0157 | val_loss=1.0370 | val_auc=0.6517538628354567 | val_f1=0.3858\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0005 | val_loss=1.0355 | val_auc=0.6489888858769315 | val_f1=0.4392\n",
            "Epoch 013 | lr=0.000500 | train_loss=0.9858 | val_loss=1.0388 | val_auc=0.6744917321767416 | val_f1=0.3846\n",
            "Epoch 014 | lr=0.000500 | train_loss=0.9772 | val_loss=1.0235 | val_auc=0.6758037408511792 | val_f1=0.4223\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9742 | val_loss=1.0182 | val_auc=0.6828517213336947 | val_f1=0.4012\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9676 | val_loss=1.0453 | val_auc=0.6685063702900516 | val_f1=0.4245\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9606 | val_loss=1.0258 | val_auc=0.6764976958525346 | val_f1=0.4129\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9700 | val_loss=1.0483 | val_auc=0.6525237191650853 | val_f1=0.3932\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9629 | val_loss=1.0302 | val_auc=0.6721496340471673 | val_f1=0.4011\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9481 | val_loss=1.0981 | val_auc=0.6540525887774464 | val_f1=0.4029\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9428 | val_loss=1.0461 | val_auc=0.6709894280292763 | val_f1=0.3780\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9420 | val_loss=1.0185 | val_auc=0.6818650040661425 | val_f1=0.4235\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9311 | val_loss=1.0362 | val_auc=0.6729953917050691 | val_f1=0.4165\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9209 | val_loss=1.0826 | val_auc=0.6612306858227162 | val_f1=0.4165\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9114 | val_loss=1.0711 | val_auc=0.6608837083220385 | val_f1=0.3918\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8983 | val_loss=1.0803 | val_auc=0.658964489021415 | val_f1=0.4020\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.9011 | val_loss=1.0775 | val_auc=0.6665763079425318 | val_f1=0.3938\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8831 | val_loss=1.0868 | val_auc=0.6549308755760368 | val_f1=0.4039\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8759 | val_loss=1.0724 | val_auc=0.6743399295201952 | val_f1=0.4104\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8663 | val_loss=1.0702 | val_auc=0.667920845757658 | val_f1=0.4201\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8538 | val_loss=1.1380 | val_auc=0.6555706153429115 | val_f1=0.4108\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8545 | val_loss=1.1103 | val_auc=0.6679750609921387 | val_f1=0.4122\n",
            "Epoch 033 | lr=0.000125 | train_loss=0.8373 | val_loss=1.1957 | val_auc=0.6322905936568175 | val_f1=0.3896\n",
            "Epoch 034 | lr=0.000063 | train_loss=0.8197 | val_loss=1.1291 | val_auc=0.6577609108159393 | val_f1=0.4049\n",
            "Epoch 035 | lr=0.000063 | train_loss=0.8332 | val_loss=1.1475 | val_auc=0.6428408782867985 | val_f1=0.4133\n",
            "Best threshold on VAL: t=0.43 | F1=0.4496 | Precision=0.3529 | Recall=0.6194\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6960\n",
            "PR-AUC: 0.4117\n",
            "Accuracy: 0.6627\n",
            "F1: 0.4289\n",
            "Precision: 0.3299\n",
            "Recall: 0.6129\n",
            "Confusion matrix:\n",
            "[[402 193]\n",
            " [ 60  95]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0841 | val_loss=1.0598 | val_auc=0.6451721333694768 | val_f1=0.4016\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0740 | val_loss=1.0478 | val_auc=0.6483057739224722 | val_f1=0.3684\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0550 | val_loss=1.0249 | val_auc=0.6811493629709948 | val_f1=0.3972\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0487 | val_loss=1.0391 | val_auc=0.6520683111954458 | val_f1=0.4129\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0435 | val_loss=1.0230 | val_auc=0.6631607481702358 | val_f1=0.3688\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0304 | val_loss=1.0178 | val_auc=0.6912984548658172 | val_f1=0.3333\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0344 | val_loss=1.0203 | val_auc=0.6716942260775278 | val_f1=0.3848\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0288 | val_loss=1.1794 | val_auc=0.6985199240986718 | val_f1=0.4253\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0248 | val_loss=1.0285 | val_auc=0.6612089997289239 | val_f1=0.4000\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0273 | val_loss=1.0242 | val_auc=0.6733315261588506 | val_f1=0.3593\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0165 | val_loss=1.0319 | val_auc=0.6862672811059908 | val_f1=0.3581\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0160 | val_loss=1.0632 | val_auc=0.6805204662510165 | val_f1=0.3768\n",
            "Epoch 013 | lr=0.000500 | train_loss=1.0130 | val_loss=0.9852 | val_auc=0.7032474925454052 | val_f1=0.4189\n",
            "Epoch 014 | lr=0.000500 | train_loss=1.0052 | val_loss=1.0018 | val_auc=0.6982813770669558 | val_f1=0.4396\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9851 | val_loss=1.0043 | val_auc=0.6829926809433451 | val_f1=0.3949\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9937 | val_loss=1.0062 | val_auc=0.6801951748441311 | val_f1=0.3973\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9962 | val_loss=1.0051 | val_auc=0.6906478720520466 | val_f1=0.4317\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9819 | val_loss=1.0102 | val_auc=0.6743290864732989 | val_f1=0.3946\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9903 | val_loss=0.9904 | val_auc=0.7024451070750881 | val_f1=0.4154\n",
            "Epoch 020 | lr=0.000250 | train_loss=0.9679 | val_loss=1.0088 | val_auc=0.6756194090539441 | val_f1=0.4251\n",
            "Epoch 021 | lr=0.000250 | train_loss=0.9477 | val_loss=1.0123 | val_auc=0.6623041474654378 | val_f1=0.4000\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9544 | val_loss=1.0268 | val_auc=0.6586825698021144 | val_f1=0.3792\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9344 | val_loss=1.0454 | val_auc=0.6589536459745189 | val_f1=0.3929\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9445 | val_loss=1.0288 | val_auc=0.6602331255082678 | val_f1=0.4078\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9312 | val_loss=1.0396 | val_auc=0.6596259148820818 | val_f1=0.3936\n",
            "Epoch 026 | lr=0.000125 | train_loss=0.9047 | val_loss=1.0373 | val_auc=0.6525128761181893 | val_f1=0.4065\n",
            "Epoch 027 | lr=0.000125 | train_loss=0.9046 | val_loss=1.0512 | val_auc=0.6625101653564651 | val_f1=0.4022\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8911 | val_loss=1.0779 | val_auc=0.64524803469775 | val_f1=0.3934\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8923 | val_loss=1.0699 | val_auc=0.6502358362699918 | val_f1=0.3990\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8870 | val_loss=1.0861 | val_auc=0.6467010029818379 | val_f1=0.3902\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8918 | val_loss=1.0904 | val_auc=0.6413879100027107 | val_f1=0.3929\n",
            "Epoch 032 | lr=0.000063 | train_loss=0.8775 | val_loss=1.0688 | val_auc=0.6552561669829221 | val_f1=0.3905\n",
            "Epoch 033 | lr=0.000063 | train_loss=0.8510 | val_loss=1.0790 | val_auc=0.6532827324478179 | val_f1=0.4093\n",
            "Best threshold on VAL: t=0.48 | F1=0.4444 | Precision=0.3651 | Recall=0.5677\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.7106\n",
            "PR-AUC: 0.4350\n",
            "Accuracy: 0.6907\n",
            "F1: 0.4286\n",
            "Precision: 0.3466\n",
            "Recall: 0.5613\n",
            "Confusion matrix:\n",
            "[[431 164]\n",
            " [ 68  87]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0881 | val_loss=1.0807 | val_auc=0.6090431011114122 | val_f1=0.3498\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0768 | val_loss=1.0603 | val_auc=0.6333640552995392 | val_f1=0.3892\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0665 | val_loss=1.0587 | val_auc=0.6274871238818108 | val_f1=0.3619\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0482 | val_loss=1.1160 | val_auc=0.6451287611818921 | val_f1=0.3859\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0417 | val_loss=1.0395 | val_auc=0.6458444022770399 | val_f1=0.3553\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0336 | val_loss=1.0240 | val_auc=0.6766169693683926 | val_f1=0.4087\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0319 | val_loss=1.0276 | val_auc=0.6805638384386012 | val_f1=0.4130\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0224 | val_loss=1.0179 | val_auc=0.6768013011656276 | val_f1=0.4195\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0195 | val_loss=1.0595 | val_auc=0.6480238547031716 | val_f1=0.3636\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0134 | val_loss=1.0443 | val_auc=0.6380590946055842 | val_f1=0.3604\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0199 | val_loss=1.0269 | val_auc=0.6679208457576579 | val_f1=0.4123\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0029 | val_loss=1.0053 | val_auc=0.696947682298726 | val_f1=0.4253\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0062 | val_loss=1.0406 | val_auc=0.6868094334507997 | val_f1=0.4234\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0019 | val_loss=1.0545 | val_auc=0.6760639739766874 | val_f1=0.2569\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9951 | val_loss=1.0265 | val_auc=0.6864407698563297 | val_f1=0.3948\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9945 | val_loss=1.0338 | val_auc=0.6711629167796151 | val_f1=0.3876\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9831 | val_loss=1.0413 | val_auc=0.6769531038221741 | val_f1=0.4258\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.9885 | val_loss=1.0367 | val_auc=0.67341827053402 | val_f1=0.4169\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9717 | val_loss=1.0359 | val_auc=0.6608403361344537 | val_f1=0.3940\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9664 | val_loss=1.0390 | val_auc=0.6635402548116021 | val_f1=0.4034\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9558 | val_loss=1.0540 | val_auc=0.6555597722960151 | val_f1=0.4059\n",
            "Epoch 022 | lr=0.000500 | train_loss=0.9406 | val_loss=1.0637 | val_auc=0.642201138519924 | val_f1=0.3848\n",
            "Epoch 023 | lr=0.000500 | train_loss=0.9378 | val_loss=1.0575 | val_auc=0.6552886961236106 | val_f1=0.4000\n",
            "Epoch 024 | lr=0.000500 | train_loss=0.9393 | val_loss=1.0878 | val_auc=0.6285388994307399 | val_f1=0.3851\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9220 | val_loss=1.0718 | val_auc=0.6436432637571158 | val_f1=0.4042\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8943 | val_loss=1.0945 | val_auc=0.6444564922743291 | val_f1=0.4019\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.8915 | val_loss=1.1198 | val_auc=0.626164272160477 | val_f1=0.3760\n",
            "Epoch 028 | lr=0.000250 | train_loss=0.8777 | val_loss=1.1319 | val_auc=0.6179560856600704 | val_f1=0.3533\n",
            "Epoch 029 | lr=0.000250 | train_loss=0.8984 | val_loss=1.1152 | val_auc=0.6212306858227162 | val_f1=0.3388\n",
            "Epoch 030 | lr=0.000250 | train_loss=0.8614 | val_loss=1.1283 | val_auc=0.6270642450528598 | val_f1=0.3730\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8536 | val_loss=1.1645 | val_auc=0.6163296286256439 | val_f1=0.3696\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8530 | val_loss=1.1853 | val_auc=0.6155706153429112 | val_f1=0.3702\n",
            "Best threshold on VAL: t=0.50 | F1=0.4253 | Precision=0.3500 | Recall=0.5419\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6712\n",
            "PR-AUC: 0.4158\n",
            "Accuracy: 0.6867\n",
            "F1: 0.4169\n",
            "Precision: 0.3387\n",
            "Recall: 0.5419\n",
            "Confusion matrix:\n",
            "[[431 164]\n",
            " [ 71  84]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6926 ± 0.0163\n",
            "PR-AUC:  0.4208 ± 0.0101\n",
            "F1:      0.4248 ± 0.0056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azqfJpXHyLc_",
        "outputId": "b0303623-1a3a-48b1-8e6d-82b677924371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 修复环境，torch 降级到 2.3.0+cu121/成功/训练时间6min"
      ],
      "metadata": {
        "id": "zuSyZXvYy6WD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "用一句话总结你的模型架构\n",
        "\n",
        "InputProj(in_dim→128) + EdgeEncoder(2→128) → [ (VirtualNode add) + GINEConv(MLP) + BN+ReLU+Dropout ] × 4，且 VN 用 add_pool + vn_mlp 在前 3 层迭代更新 → global mean pooling → MLP classifier(128→128→1)"
      ],
      "metadata": {
        "id": "WGX1qlC5VbEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEsxIkKnyxf9",
        "outputId": "2d03641c-9264-4172-d7da-88e04a095f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.3.0+cu121\n",
            "Uninstalling torch-2.3.0+cu121:\n",
            "  Successfully uninstalled torch-2.3.0+cu121\n",
            "Found existing installation: torchvision 0.18.0+cu121\n",
            "Uninstalling torchvision-0.18.0+cu121:\n",
            "  Successfully uninstalled torchvision-0.18.0+cu121\n",
            "Found existing installation: torchaudio 2.3.0+cu121\n",
            "Uninstalling torchaudio-2.3.0+cu121:\n",
            "  Successfully uninstalled torchaudio-2.3.0+cu121\n",
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
            "Collecting torch==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m253.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m241.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0998 | val_loss=1.0714 | val_auc=0.6447167253998374 | val_f1=0.3916\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0724 | val_loss=1.0458 | val_auc=0.6482515586879912 | val_f1=0.3901\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0553 | val_loss=1.0617 | val_auc=0.6221198156682027 | val_f1=0.3775\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0507 | val_loss=1.0492 | val_auc=0.6444239631336406 | val_f1=0.3761\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0340 | val_loss=1.0479 | val_auc=0.6686907020872864 | val_f1=0.3407\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0297 | val_loss=1.0340 | val_auc=0.6750447275684467 | val_f1=0.4013\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0286 | val_loss=1.0858 | val_auc=0.6126538357278395 | val_f1=0.3613\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0245 | val_loss=1.0630 | val_auc=0.6485009487666035 | val_f1=0.3873\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0119 | val_loss=1.0444 | val_auc=0.6535754947140147 | val_f1=0.4048\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0031 | val_loss=1.0539 | val_auc=0.6532610463540254 | val_f1=0.3371\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0157 | val_loss=1.0370 | val_auc=0.6517538628354567 | val_f1=0.3858\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0005 | val_loss=1.0355 | val_auc=0.6489888858769315 | val_f1=0.4392\n",
            "Epoch 013 | lr=0.000500 | train_loss=0.9858 | val_loss=1.0388 | val_auc=0.6744917321767416 | val_f1=0.3846\n",
            "Epoch 014 | lr=0.000500 | train_loss=0.9772 | val_loss=1.0235 | val_auc=0.6758037408511792 | val_f1=0.4223\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9742 | val_loss=1.0182 | val_auc=0.6828517213336947 | val_f1=0.4012\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9676 | val_loss=1.0453 | val_auc=0.6685063702900516 | val_f1=0.4245\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9606 | val_loss=1.0258 | val_auc=0.6764976958525346 | val_f1=0.4129\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9700 | val_loss=1.0483 | val_auc=0.6525237191650853 | val_f1=0.3932\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9629 | val_loss=1.0302 | val_auc=0.6721496340471673 | val_f1=0.4011\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9481 | val_loss=1.0981 | val_auc=0.6540525887774464 | val_f1=0.4029\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9428 | val_loss=1.0461 | val_auc=0.6709894280292763 | val_f1=0.3780\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9420 | val_loss=1.0185 | val_auc=0.6818650040661425 | val_f1=0.4235\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9311 | val_loss=1.0362 | val_auc=0.6729953917050691 | val_f1=0.4165\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9209 | val_loss=1.0826 | val_auc=0.6612306858227162 | val_f1=0.4165\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9114 | val_loss=1.0711 | val_auc=0.6608837083220385 | val_f1=0.3918\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8983 | val_loss=1.0803 | val_auc=0.658964489021415 | val_f1=0.4020\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.9011 | val_loss=1.0775 | val_auc=0.6665763079425318 | val_f1=0.3938\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8831 | val_loss=1.0868 | val_auc=0.6549308755760368 | val_f1=0.4039\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8759 | val_loss=1.0724 | val_auc=0.6743399295201952 | val_f1=0.4104\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8663 | val_loss=1.0702 | val_auc=0.667920845757658 | val_f1=0.4201\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8538 | val_loss=1.1380 | val_auc=0.6555706153429115 | val_f1=0.4108\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8545 | val_loss=1.1103 | val_auc=0.6679750609921387 | val_f1=0.4122\n",
            "Epoch 033 | lr=0.000125 | train_loss=0.8373 | val_loss=1.1957 | val_auc=0.6322905936568175 | val_f1=0.3896\n",
            "Epoch 034 | lr=0.000063 | train_loss=0.8197 | val_loss=1.1291 | val_auc=0.6577609108159393 | val_f1=0.4049\n",
            "Epoch 035 | lr=0.000063 | train_loss=0.8332 | val_loss=1.1475 | val_auc=0.6428408782867985 | val_f1=0.4133\n",
            "Best threshold on VAL: t=0.43 | F1=0.4496 | Precision=0.3529 | Recall=0.6194\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6960\n",
            "PR-AUC: 0.4117\n",
            "Accuracy: 0.6627\n",
            "F1: 0.4289\n",
            "Precision: 0.3299\n",
            "Recall: 0.6129\n",
            "Confusion matrix:\n",
            "[[402 193]\n",
            " [ 60  95]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0841 | val_loss=1.0598 | val_auc=0.6451721333694768 | val_f1=0.4016\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0740 | val_loss=1.0478 | val_auc=0.6483057739224722 | val_f1=0.3684\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0550 | val_loss=1.0249 | val_auc=0.6811493629709948 | val_f1=0.3972\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0487 | val_loss=1.0391 | val_auc=0.6520683111954458 | val_f1=0.4129\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0435 | val_loss=1.0230 | val_auc=0.6631607481702358 | val_f1=0.3688\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0304 | val_loss=1.0178 | val_auc=0.6912984548658172 | val_f1=0.3333\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0344 | val_loss=1.0203 | val_auc=0.6716942260775278 | val_f1=0.3848\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0288 | val_loss=1.1794 | val_auc=0.6985199240986718 | val_f1=0.4253\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0248 | val_loss=1.0285 | val_auc=0.6612089997289239 | val_f1=0.4000\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0273 | val_loss=1.0242 | val_auc=0.6733315261588506 | val_f1=0.3593\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0165 | val_loss=1.0319 | val_auc=0.6862672811059908 | val_f1=0.3581\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0160 | val_loss=1.0632 | val_auc=0.6805204662510165 | val_f1=0.3768\n",
            "Epoch 013 | lr=0.000500 | train_loss=1.0130 | val_loss=0.9852 | val_auc=0.7032474925454052 | val_f1=0.4189\n",
            "Epoch 014 | lr=0.000500 | train_loss=1.0052 | val_loss=1.0018 | val_auc=0.6982813770669558 | val_f1=0.4396\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9851 | val_loss=1.0043 | val_auc=0.6829926809433451 | val_f1=0.3949\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9937 | val_loss=1.0062 | val_auc=0.6801951748441311 | val_f1=0.3973\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9962 | val_loss=1.0051 | val_auc=0.6906478720520466 | val_f1=0.4317\n",
            "Epoch 018 | lr=0.000500 | train_loss=0.9819 | val_loss=1.0102 | val_auc=0.6743290864732989 | val_f1=0.3946\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9903 | val_loss=0.9904 | val_auc=0.7024451070750881 | val_f1=0.4154\n",
            "Epoch 020 | lr=0.000250 | train_loss=0.9679 | val_loss=1.0088 | val_auc=0.6756194090539441 | val_f1=0.4251\n",
            "Epoch 021 | lr=0.000250 | train_loss=0.9477 | val_loss=1.0123 | val_auc=0.6623041474654378 | val_f1=0.4000\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9544 | val_loss=1.0268 | val_auc=0.6586825698021144 | val_f1=0.3792\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9344 | val_loss=1.0454 | val_auc=0.6589536459745189 | val_f1=0.3929\n",
            "Epoch 024 | lr=0.000250 | train_loss=0.9445 | val_loss=1.0288 | val_auc=0.6602331255082678 | val_f1=0.4078\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9312 | val_loss=1.0396 | val_auc=0.6596259148820818 | val_f1=0.3936\n",
            "Epoch 026 | lr=0.000125 | train_loss=0.9047 | val_loss=1.0373 | val_auc=0.6525128761181893 | val_f1=0.4065\n",
            "Epoch 027 | lr=0.000125 | train_loss=0.9046 | val_loss=1.0512 | val_auc=0.6625101653564651 | val_f1=0.4022\n",
            "Epoch 028 | lr=0.000125 | train_loss=0.8911 | val_loss=1.0779 | val_auc=0.64524803469775 | val_f1=0.3934\n",
            "Epoch 029 | lr=0.000125 | train_loss=0.8923 | val_loss=1.0699 | val_auc=0.6502358362699918 | val_f1=0.3990\n",
            "Epoch 030 | lr=0.000125 | train_loss=0.8870 | val_loss=1.0861 | val_auc=0.6467010029818379 | val_f1=0.3902\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8918 | val_loss=1.0904 | val_auc=0.6413879100027107 | val_f1=0.3929\n",
            "Epoch 032 | lr=0.000063 | train_loss=0.8775 | val_loss=1.0688 | val_auc=0.6552561669829221 | val_f1=0.3905\n",
            "Epoch 033 | lr=0.000063 | train_loss=0.8510 | val_loss=1.0790 | val_auc=0.6532827324478179 | val_f1=0.4093\n",
            "Best threshold on VAL: t=0.48 | F1=0.4444 | Precision=0.3651 | Recall=0.5677\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.7106\n",
            "PR-AUC: 0.4350\n",
            "Accuracy: 0.6907\n",
            "F1: 0.4286\n",
            "Precision: 0.3466\n",
            "Recall: 0.5613\n",
            "Confusion matrix:\n",
            "[[431 164]\n",
            " [ 68  87]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0881 | val_loss=1.0807 | val_auc=0.6090431011114122 | val_f1=0.3498\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0768 | val_loss=1.0603 | val_auc=0.6333640552995392 | val_f1=0.3892\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0665 | val_loss=1.0587 | val_auc=0.6274871238818108 | val_f1=0.3619\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0482 | val_loss=1.1160 | val_auc=0.6451287611818921 | val_f1=0.3859\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0417 | val_loss=1.0395 | val_auc=0.6458444022770399 | val_f1=0.3553\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0336 | val_loss=1.0240 | val_auc=0.6766169693683926 | val_f1=0.4087\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0319 | val_loss=1.0276 | val_auc=0.6805638384386012 | val_f1=0.4130\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0224 | val_loss=1.0179 | val_auc=0.6768013011656276 | val_f1=0.4195\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0195 | val_loss=1.0595 | val_auc=0.6480238547031716 | val_f1=0.3636\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0134 | val_loss=1.0443 | val_auc=0.6380590946055842 | val_f1=0.3604\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0199 | val_loss=1.0269 | val_auc=0.6679208457576579 | val_f1=0.4123\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0029 | val_loss=1.0053 | val_auc=0.696947682298726 | val_f1=0.4253\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0062 | val_loss=1.0406 | val_auc=0.6868094334507997 | val_f1=0.4234\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0019 | val_loss=1.0545 | val_auc=0.6760639739766874 | val_f1=0.2569\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9951 | val_loss=1.0265 | val_auc=0.6864407698563297 | val_f1=0.3948\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9945 | val_loss=1.0338 | val_auc=0.6711629167796151 | val_f1=0.3876\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9831 | val_loss=1.0413 | val_auc=0.6769531038221741 | val_f1=0.4258\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.9885 | val_loss=1.0367 | val_auc=0.67341827053402 | val_f1=0.4169\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9717 | val_loss=1.0359 | val_auc=0.6608403361344537 | val_f1=0.3940\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9664 | val_loss=1.0390 | val_auc=0.6635402548116021 | val_f1=0.4034\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9558 | val_loss=1.0540 | val_auc=0.6555597722960151 | val_f1=0.4059\n",
            "Epoch 022 | lr=0.000500 | train_loss=0.9406 | val_loss=1.0637 | val_auc=0.642201138519924 | val_f1=0.3848\n",
            "Epoch 023 | lr=0.000500 | train_loss=0.9378 | val_loss=1.0575 | val_auc=0.6552886961236106 | val_f1=0.4000\n",
            "Epoch 024 | lr=0.000500 | train_loss=0.9393 | val_loss=1.0878 | val_auc=0.6285388994307399 | val_f1=0.3851\n",
            "Epoch 025 | lr=0.000250 | train_loss=0.9220 | val_loss=1.0718 | val_auc=0.6436432637571158 | val_f1=0.4042\n",
            "Epoch 026 | lr=0.000250 | train_loss=0.8943 | val_loss=1.0945 | val_auc=0.6444564922743291 | val_f1=0.4019\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.8915 | val_loss=1.1198 | val_auc=0.626164272160477 | val_f1=0.3760\n",
            "Epoch 028 | lr=0.000250 | train_loss=0.8777 | val_loss=1.1319 | val_auc=0.6179560856600704 | val_f1=0.3533\n",
            "Epoch 029 | lr=0.000250 | train_loss=0.8984 | val_loss=1.1152 | val_auc=0.6212306858227162 | val_f1=0.3388\n",
            "Epoch 030 | lr=0.000250 | train_loss=0.8614 | val_loss=1.1283 | val_auc=0.6270642450528598 | val_f1=0.3730\n",
            "Epoch 031 | lr=0.000125 | train_loss=0.8536 | val_loss=1.1645 | val_auc=0.6163296286256439 | val_f1=0.3696\n",
            "Epoch 032 | lr=0.000125 | train_loss=0.8530 | val_loss=1.1853 | val_auc=0.6155706153429112 | val_f1=0.3702\n",
            "Best threshold on VAL: t=0.50 | F1=0.4253 | Precision=0.3500 | Recall=0.5419\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6712\n",
            "PR-AUC: 0.4158\n",
            "Accuracy: 0.6867\n",
            "F1: 0.4169\n",
            "Precision: 0.3387\n",
            "Recall: 0.5419\n",
            "Confusion matrix:\n",
            "[[431 164]\n",
            " [ 71  84]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6926 ± 0.0163\n",
            "PR-AUC:  0.4208 ± 0.0101\n",
            "F1:      0.4248 ± 0.0056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01"
      ],
      "metadata": {
        "id": "C5rc8dfiL0xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "#############################################\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "#############################################\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"max\",\n",
        "        factor=0.5, #改\n",
        "        patience=5, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc is not None:\n",
        "          scheduler.step(val_auc)\n",
        "        else:\n",
        "          scheduler.step(-val_loss)  # mode=\"max\" 下用 -loss 兜底\n",
        "\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else (-val_loss)\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "#############################################\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "#############################################\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3, # 改\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c93b261-e2e4-4e4e-fffc-ff0aeb8b5e66",
        "id": "ng1kt5glL2x6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.9.0+cpu\n",
            "Uninstalling torch-2.9.0+cpu:\n",
            "  Successfully uninstalled torch-2.9.0+cpu\n",
            "Found existing installation: torchvision 0.24.0+cpu\n",
            "Uninstalling torchvision-0.24.0+cpu:\n",
            "  Successfully uninstalled torchvision-0.24.0+cpu\n",
            "Found existing installation: torchaudio 2.9.0+cpu\n",
            "Uninstalling torchaudio-2.9.0+cpu:\n",
            "  Successfully uninstalled torchaudio-2.9.0+cpu\n",
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
            "Collecting torch==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m142.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0+cu121)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
            "Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m250.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m201.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m235.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m359.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m247.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m266.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m268.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m192.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m259.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m346.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.9.86-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.7/39.7 MB\u001b[0m \u001b[31m176.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.29.2\n",
            "    Uninstalling nvidia-nccl-cu12-2.29.2:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.29.2\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.9.86 nvidia-nvtx-cu12-12.1.105 torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_scatter-2.1.2%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m155.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.3.0%2Bcu121/torch_sparse-0.6.18%2Bpt23cu121-cp312-cp312-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter, torch-sparse, torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0 torch-scatter-2.1.2+pt23cu121 torch-sparse-0.6.18+pt23cu121\n",
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0904 | val_loss=1.0669 | val_auc=0.635066413662239 | val_f1=0.3262\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0688 | val_loss=1.0466 | val_auc=0.6547899159663866 | val_f1=0.3850\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0409 | val_loss=1.2993 | val_auc=0.5374356194090539 | val_f1=0.3291\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0482 | val_loss=1.0937 | val_auc=0.6416047709406344 | val_f1=0.2264\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0212 | val_loss=1.0848 | val_auc=0.6341447546760639 | val_f1=0.3736\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0214 | val_loss=1.0595 | val_auc=0.6568392518297643 | val_f1=0.3955\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0267 | val_loss=1.0624 | val_auc=0.659810246679317 | val_f1=0.3816\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0217 | val_loss=1.0426 | val_auc=0.6658172946597993 | val_f1=0.3464\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0006 | val_loss=1.0946 | val_auc=0.6254811602060178 | val_f1=0.3169\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0172 | val_loss=1.0472 | val_auc=0.6632691786391978 | val_f1=0.3333\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0086 | val_loss=1.1001 | val_auc=0.649639468690702 | val_f1=0.2871\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.9939 | val_loss=1.0233 | val_auc=0.6768772024939008 | val_f1=0.3830\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.9979 | val_loss=1.0627 | val_auc=0.6445866088370832 | val_f1=0.3459\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.9984 | val_loss=1.0457 | val_auc=0.6617728381675249 | val_f1=0.4057\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9936 | val_loss=1.0181 | val_auc=0.6729682840878286 | val_f1=0.4175\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9896 | val_loss=1.1016 | val_auc=0.6266847384114936 | val_f1=0.3963\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9903 | val_loss=1.0303 | val_auc=0.6685931146652211 | val_f1=0.3810\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0014 | val_loss=1.0255 | val_auc=0.6747302792084575 | val_f1=0.4198\n",
            "Epoch 019 | lr=0.000500 | train_loss=0.9781 | val_loss=1.0200 | val_auc=0.6844781783681215 | val_f1=0.4046\n",
            "Epoch 020 | lr=0.000500 | train_loss=0.9657 | val_loss=1.0175 | val_auc=0.6880672268907564 | val_f1=0.4126\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9604 | val_loss=1.0149 | val_auc=0.6856925996204933 | val_f1=0.4187\n",
            "Epoch 022 | lr=0.000500 | train_loss=0.9571 | val_loss=1.0230 | val_auc=0.6808349146110056 | val_f1=0.4244\n",
            "Epoch 023 | lr=0.000500 | train_loss=0.9494 | val_loss=1.0830 | val_auc=0.6376795879642179 | val_f1=0.3982\n",
            "Epoch 024 | lr=0.000500 | train_loss=0.9574 | val_loss=1.0914 | val_auc=0.6420818650040663 | val_f1=0.4187\n",
            "Epoch 025 | lr=0.000500 | train_loss=0.9509 | val_loss=1.0745 | val_auc=0.6478178368121443 | val_f1=0.3819\n",
            "Epoch 026 | lr=0.000500 | train_loss=0.9464 | val_loss=1.0626 | val_auc=0.6588777446462456 | val_f1=0.4165\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.9257 | val_loss=1.0559 | val_auc=0.6744049878015721 | val_f1=0.3743\n",
            "Epoch 028 | lr=0.000250 | train_loss=0.9127 | val_loss=1.0783 | val_auc=0.6472973705611277 | val_f1=0.3753\n",
            "Epoch 029 | lr=0.000250 | train_loss=0.9214 | val_loss=1.0478 | val_auc=0.6710436432637571 | val_f1=0.4101\n",
            "Epoch 030 | lr=0.000250 | train_loss=0.9117 | val_loss=1.0630 | val_auc=0.657739224722147 | val_f1=0.3981\n",
            "Epoch 031 | lr=0.000250 | train_loss=0.9029 | val_loss=1.0866 | val_auc=0.6701653564651667 | val_f1=0.4069\n",
            "Epoch 032 | lr=0.000250 | train_loss=0.9187 | val_loss=1.0738 | val_auc=0.6615559772296015 | val_f1=0.3812\n",
            "Epoch 033 | lr=0.000125 | train_loss=0.8923 | val_loss=1.0745 | val_auc=0.6688316616969368 | val_f1=0.3874\n",
            "Epoch 034 | lr=0.000125 | train_loss=0.8743 | val_loss=1.0837 | val_auc=0.6697641637300081 | val_f1=0.3920\n",
            "Epoch 035 | lr=0.000125 | train_loss=0.8908 | val_loss=1.1037 | val_auc=0.6567416644076985 | val_f1=0.3777\n",
            "Epoch 036 | lr=0.000125 | train_loss=0.8594 | val_loss=1.0784 | val_auc=0.6699268094334507 | val_f1=0.3776\n",
            "Epoch 037 | lr=0.000125 | train_loss=0.8608 | val_loss=1.1346 | val_auc=0.651591217132014 | val_f1=0.3636\n",
            "Epoch 038 | lr=0.000125 | train_loss=0.8665 | val_loss=1.1048 | val_auc=0.6619680130116563 | val_f1=0.3725\n",
            "Epoch 039 | lr=0.000063 | train_loss=0.8423 | val_loss=1.1283 | val_auc=0.6544320954188126 | val_f1=0.3722\n",
            "Epoch 040 | lr=0.000063 | train_loss=0.8465 | val_loss=1.1293 | val_auc=0.6559392789373814 | val_f1=0.3562\n",
            "Best threshold on VAL: t=0.62 | F1=0.4400 | Precision=0.3949 | Recall=0.4968\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6783\n",
            "PR-AUC: 0.4070\n",
            "Accuracy: 0.7387\n",
            "F1: 0.4167\n",
            "Precision: 0.3867\n",
            "Recall: 0.4516\n",
            "Confusion matrix:\n",
            "[[484 111]\n",
            " [ 85  70]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0945 | val_loss=1.0614 | val_auc=0.6254161019246407 | val_f1=0.3633\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0713 | val_loss=1.0673 | val_auc=0.609270805096232 | val_f1=0.2720\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0621 | val_loss=1.0709 | val_auc=0.6561452968284088 | val_f1=0.4015\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0506 | val_loss=1.0468 | val_auc=0.647134724857685 | val_f1=0.3556\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0470 | val_loss=1.0320 | val_auc=0.6567850365952832 | val_f1=0.4123\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0428 | val_loss=1.0285 | val_auc=0.6453998373542965 | val_f1=0.3931\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0367 | val_loss=1.0574 | val_auc=0.6292328544320953 | val_f1=0.3577\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0412 | val_loss=1.0336 | val_auc=0.6680618053673082 | val_f1=0.4171\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0320 | val_loss=1.0435 | val_auc=0.6538140417457305 | val_f1=0.3678\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0366 | val_loss=1.0232 | val_auc=0.6722580645161289 | val_f1=0.4289\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0261 | val_loss=1.0640 | val_auc=0.6382651124966117 | val_f1=0.2719\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0282 | val_loss=1.0233 | val_auc=0.6785687178097046 | val_f1=0.3968\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0251 | val_loss=1.0682 | val_auc=0.6381458389807535 | val_f1=0.3684\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0378 | val_loss=1.0221 | val_auc=0.6881105990783409 | val_f1=0.3993\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0268 | val_loss=1.0544 | val_auc=0.638351856871781 | val_f1=0.3565\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0258 | val_loss=1.0564 | val_auc=0.6464516129032257 | val_f1=0.3039\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0244 | val_loss=1.0313 | val_auc=0.6761832474925453 | val_f1=0.3985\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0246 | val_loss=1.0442 | val_auc=0.6553862835456763 | val_f1=0.3677\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0191 | val_loss=1.0147 | val_auc=0.6748061805367308 | val_f1=0.4099\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0223 | val_loss=1.0026 | val_auc=0.6873624288425048 | val_f1=0.4267\n",
            "Epoch 021 | lr=0.000500 | train_loss=0.9962 | val_loss=1.0201 | val_auc=0.6692220113851992 | val_f1=0.4119\n",
            "Epoch 022 | lr=0.000500 | train_loss=1.0067 | val_loss=1.0319 | val_auc=0.6452914068853348 | val_f1=0.3726\n",
            "Epoch 023 | lr=0.000500 | train_loss=1.0042 | val_loss=1.0251 | val_auc=0.6612523719165087 | val_f1=0.3966\n",
            "Epoch 024 | lr=0.000500 | train_loss=1.0004 | val_loss=1.0099 | val_auc=0.6819625914882081 | val_f1=0.4267\n",
            "Epoch 025 | lr=0.000500 | train_loss=0.9901 | val_loss=1.0495 | val_auc=0.6417186229330443 | val_f1=0.3796\n",
            "Epoch 026 | lr=0.000500 | train_loss=0.9855 | val_loss=1.0117 | val_auc=0.674090539441583 | val_f1=0.3992\n",
            "Epoch 027 | lr=0.000250 | train_loss=0.9751 | val_loss=1.0112 | val_auc=0.6818650040661425 | val_f1=0.4063\n",
            "Epoch 028 | lr=0.000250 | train_loss=0.9699 | val_loss=1.0106 | val_auc=0.6794253185145025 | val_f1=0.4080\n",
            "Epoch 029 | lr=0.000250 | train_loss=0.9706 | val_loss=1.0285 | val_auc=0.6672268907563026 | val_f1=0.4041\n",
            "Epoch 030 | lr=0.000250 | train_loss=0.9624 | val_loss=1.0307 | val_auc=0.6576199512062889 | val_f1=0.4167\n",
            "Epoch 031 | lr=0.000250 | train_loss=0.9722 | val_loss=1.0208 | val_auc=0.6683437245866088 | val_f1=0.4062\n",
            "Epoch 032 | lr=0.000250 | train_loss=0.9632 | val_loss=1.0397 | val_auc=0.6496719978313905 | val_f1=0.4080\n",
            "Epoch 033 | lr=0.000125 | train_loss=0.9451 | val_loss=1.0463 | val_auc=0.6479371103280022 | val_f1=0.4099\n",
            "Epoch 034 | lr=0.000125 | train_loss=0.9459 | val_loss=1.0399 | val_auc=0.6631499051233396 | val_f1=0.4126\n",
            "Best threshold on VAL: t=0.53 | F1=0.4353 | Precision=0.4000 | Recall=0.4774\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6673\n",
            "PR-AUC: 0.3425\n",
            "Accuracy: 0.7107\n",
            "F1: 0.3853\n",
            "Precision: 0.3434\n",
            "Recall: 0.4387\n",
            "Confusion matrix:\n",
            "[[465 130]\n",
            " [ 87  68]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0861 | val_loss=1.0698 | val_auc=0.6118948224451072 | val_f1=0.3236\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0586 | val_loss=1.0613 | val_auc=0.655733261046354 | val_f1=0.3365\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0402 | val_loss=1.3603 | val_auc=0.689400921658986 | val_f1=0.4034\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0468 | val_loss=1.5624 | val_auc=0.6786879913255625 | val_f1=0.3703\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0446 | val_loss=0.9993 | val_auc=0.6973380319869884 | val_f1=0.4457\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0221 | val_loss=1.0165 | val_auc=0.6908105177554894 | val_f1=0.4125\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0247 | val_loss=1.0624 | val_auc=0.6652534562211981 | val_f1=0.2771\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0275 | val_loss=1.2342 | val_auc=0.6886419083762537 | val_f1=0.3900\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0149 | val_loss=1.0395 | val_auc=0.679208457576579 | val_f1=0.4233\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0204 | val_loss=1.0725 | val_auc=0.6557766332339386 | val_f1=0.2062\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0169 | val_loss=1.0290 | val_auc=0.6783301707779885 | val_f1=0.4112\n",
            "Epoch 012 | lr=0.000500 | train_loss=0.9937 | val_loss=1.0020 | val_auc=0.6960693955001356 | val_f1=0.4196\n",
            "Epoch 013 | lr=0.000500 | train_loss=0.9969 | val_loss=1.0349 | val_auc=0.6719219300623475 | val_f1=0.3824\n",
            "Epoch 014 | lr=0.000500 | train_loss=0.9855 | val_loss=1.0100 | val_auc=0.6830468961778259 | val_f1=0.4177\n",
            "Epoch 015 | lr=0.000500 | train_loss=0.9831 | val_loss=1.0031 | val_auc=0.6938899430740039 | val_f1=0.4267\n",
            "Epoch 016 | lr=0.000500 | train_loss=0.9795 | val_loss=1.0144 | val_auc=0.6816047709406343 | val_f1=0.4067\n",
            "Epoch 017 | lr=0.000500 | train_loss=0.9782 | val_loss=1.0227 | val_auc=0.6878286798590404 | val_f1=0.4116\n",
            "Epoch 018 | lr=0.000250 | train_loss=0.9634 | val_loss=1.0216 | val_auc=0.6807806993765247 | val_f1=0.4274\n",
            "Epoch 019 | lr=0.000250 | train_loss=0.9700 | val_loss=1.0104 | val_auc=0.6896611547844944 | val_f1=0.4011\n",
            "Epoch 020 | lr=0.000250 | train_loss=0.9668 | val_loss=1.0235 | val_auc=0.6793060449986446 | val_f1=0.4416\n",
            "Epoch 021 | lr=0.000250 | train_loss=0.9508 | val_loss=1.0357 | val_auc=0.6656546489563567 | val_f1=0.4011\n",
            "Epoch 022 | lr=0.000250 | train_loss=0.9508 | val_loss=1.0197 | val_auc=0.6788289509352128 | val_f1=0.4091\n",
            "Epoch 023 | lr=0.000250 | train_loss=0.9441 | val_loss=1.0131 | val_auc=0.685551640010843 | val_f1=0.4132\n",
            "Epoch 024 | lr=0.000125 | train_loss=0.9389 | val_loss=1.0366 | val_auc=0.6715641095147736 | val_f1=0.4133\n",
            "Epoch 025 | lr=0.000125 | train_loss=0.9237 | val_loss=1.0298 | val_auc=0.6751640010843045 | val_f1=0.4409\n",
            "Best threshold on VAL: t=0.51 | F1=0.4485 | Precision=0.4229 | Recall=0.4774\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6570\n",
            "PR-AUC: 0.3900\n",
            "Accuracy: 0.7347\n",
            "F1: 0.4232\n",
            "Precision: 0.3842\n",
            "Recall: 0.4710\n",
            "Confusion matrix:\n",
            "[[478 117]\n",
            " [ 82  73]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6675 ± 0.0087\n",
            "PR-AUC:  0.3798 ± 0.0273\n",
            "F1:      0.4084 ± 0.0166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-01"
      ],
      "metadata": {
        "id": "F6jaMMx9FsFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.4, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.4, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4, # 改\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "7hki3DjPFsXU",
        "outputId": "aadbb53b-d7f7-451b-ce9d-fa302d751ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch_geometric'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1206785288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGINEConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_add_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m from sklearn.metrics import (\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-02"
      ],
      "metadata": {
        "id": "5p0_08SVeRMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "         # 关键修改：分类器的输入维度要从 hidden_dim 变成 hidden_dim * 2\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2, hidden_dim), # 因为拼接了 mean 和 max，所以是 * 2\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        # 注意：确保你的脚本开头或者这里导入了 global_max_pool\n",
        "        from torch_geometric.nn import global_max_pool\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 送入分类器\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4, # 改\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cigzSBwAeRjj",
        "outputId": "18132b0e-e896-4e16-9214-1e4cb6751d40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0960 | val_loss=1.0602 | val_auc=0.6399457847655191 | val_f1=0.3850\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0687 | val_loss=1.0486 | val_auc=0.6508647329899702 | val_f1=0.3680\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0505 | val_loss=1.0587 | val_auc=0.6318460287340744 | val_f1=0.3690\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0355 | val_loss=1.1212 | val_auc=0.6013445378151261 | val_f1=0.2277\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0253 | val_loss=1.0418 | val_auc=0.6545296828408783 | val_f1=0.4083\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0262 | val_loss=1.0074 | val_auc=0.7015017619951205 | val_f1=0.4219\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0269 | val_loss=1.0490 | val_auc=0.6607644348061805 | val_f1=0.4208\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0119 | val_loss=1.0418 | val_auc=0.6547899159663865 | val_f1=0.3505\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0093 | val_loss=1.0613 | val_auc=0.6392735158579561 | val_f1=0.3629\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0100 | val_loss=1.0477 | val_auc=0.6689400921658988 | val_f1=0.3070\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0220 | val_loss=1.0434 | val_auc=0.660786120899973 | val_f1=0.4228\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0025 | val_loss=1.0177 | val_auc=0.6737977771753862 | val_f1=0.4070\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.9969 | val_loss=1.1106 | val_auc=0.6232691786391975 | val_f1=0.2178\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0030 | val_loss=1.0037 | val_auc=0.6910924369747898 | val_f1=0.4055\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.9958 | val_loss=1.0194 | val_auc=0.6851612903225806 | val_f1=0.4397\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9924 | val_loss=1.0461 | val_auc=0.6538248847926267 | val_f1=0.3927\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9826 | val_loss=1.0438 | val_auc=0.6569259962049335 | val_f1=0.4115\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.9975 | val_loss=1.0415 | val_auc=0.6547140146381134 | val_f1=0.4035\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.9851 | val_loss=1.0180 | val_auc=0.6886093792355652 | val_f1=0.4409\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.9884 | val_loss=0.9959 | val_auc=0.6989753320683112 | val_f1=0.4310\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9899 | val_loss=1.0296 | val_auc=0.6906478720520466 | val_f1=0.4213\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.9765 | val_loss=1.0015 | val_auc=0.6945622119815668 | val_f1=0.4191\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9951 | val_loss=1.0152 | val_auc=0.677994036324207 | val_f1=0.4126\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9911 | val_loss=1.0384 | val_auc=0.6493467064245053 | val_f1=0.3896\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9641 | val_loss=1.0592 | val_auc=0.6560043372187584 | val_f1=0.3960\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9624 | val_loss=1.0840 | val_auc=0.646776904310111 | val_f1=0.3951\n",
            "Best threshold on VAL: t=0.56 | F1=0.4505 | Precision=0.3923 | Recall=0.5290\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6641\n",
            "PR-AUC: 0.3853\n",
            "Accuracy: 0.6987\n",
            "F1: 0.3722\n",
            "Precision: 0.3268\n",
            "Recall: 0.4323\n",
            "Confusion matrix:\n",
            "[[457 138]\n",
            " [ 88  67]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1133 | val_loss=1.0661 | val_auc=0.6277798861480076 | val_f1=0.3842\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0782 | val_loss=1.0628 | val_auc=0.6414312821902955 | val_f1=0.3761\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0639 | val_loss=1.0258 | val_auc=0.6687232312279751 | val_f1=0.4086\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0526 | val_loss=1.0659 | val_auc=0.6223366766061262 | val_f1=0.3385\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0475 | val_loss=1.0457 | val_auc=0.6474274871238819 | val_f1=0.4017\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0405 | val_loss=1.0292 | val_auc=0.6658172946597993 | val_f1=0.4224\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0353 | val_loss=1.0370 | val_auc=0.6448902141501762 | val_f1=0.3812\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0442 | val_loss=1.0497 | val_auc=0.6542586066684739 | val_f1=0.4112\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0338 | val_loss=1.0344 | val_auc=0.6714990512333967 | val_f1=0.3755\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0332 | val_loss=1.0349 | val_auc=0.6656980211439415 | val_f1=0.3738\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0232 | val_loss=1.0357 | val_auc=0.6643860124695039 | val_f1=0.3643\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0243 | val_loss=1.0107 | val_auc=0.6866251016535646 | val_f1=0.4091\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0230 | val_loss=1.0764 | val_auc=0.6030794253185146 | val_f1=0.2857\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0292 | val_loss=1.0315 | val_auc=0.6791976145296829 | val_f1=0.4216\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0127 | val_loss=1.0174 | val_auc=0.6802927622661968 | val_f1=0.4154\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0130 | val_loss=1.0500 | val_auc=0.6660666847384116 | val_f1=0.3318\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0149 | val_loss=1.0260 | val_auc=0.6878828950935213 | val_f1=0.4104\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0067 | val_loss=1.0066 | val_auc=0.6867552182163188 | val_f1=0.4218\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0134 | val_loss=1.0345 | val_auc=0.6620005421523447 | val_f1=0.3507\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0131 | val_loss=1.0433 | val_auc=0.6325399837354297 | val_f1=0.3532\n",
            "Epoch 021 | lr=0.001000 | train_loss=1.0008 | val_loss=1.0256 | val_auc=0.6909189482244511 | val_f1=0.4132\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0065 | val_loss=1.0219 | val_auc=0.6791000271076172 | val_f1=0.4174\n",
            "Epoch 023 | lr=0.001000 | train_loss=1.0053 | val_loss=1.0223 | val_auc=0.6997777175386284 | val_f1=0.4283\n",
            "Epoch 024 | lr=0.001000 | train_loss=1.0020 | val_loss=1.0375 | val_auc=0.6721821631878558 | val_f1=0.3561\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9937 | val_loss=1.0231 | val_auc=0.6556248305773922 | val_f1=0.4035\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9822 | val_loss=1.0183 | val_auc=0.6627595554350771 | val_f1=0.3866\n",
            "Epoch 027 | lr=0.001000 | train_loss=0.9929 | val_loss=1.0086 | val_auc=0.6910490647872052 | val_f1=0.4000\n",
            "Epoch 028 | lr=0.001000 | train_loss=0.9839 | val_loss=1.0202 | val_auc=0.6761724044456492 | val_f1=0.4211\n",
            "Epoch 029 | lr=0.001000 | train_loss=0.9813 | val_loss=1.0175 | val_auc=0.6814095960965031 | val_f1=0.4186\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.9671 | val_loss=1.0244 | val_auc=0.6661859582542694 | val_f1=0.3859\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.9602 | val_loss=1.0308 | val_auc=0.6634643534833289 | val_f1=0.3815\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.9627 | val_loss=1.0427 | val_auc=0.6686690159934943 | val_f1=0.4043\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.9421 | val_loss=1.0670 | val_auc=0.628235294117647 | val_f1=0.3776\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.9582 | val_loss=1.0844 | val_auc=0.6203740851179181 | val_f1=0.3478\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.9521 | val_loss=1.0523 | val_auc=0.655906749796693 | val_f1=0.4009\n",
            "Epoch 036 | lr=0.000800 | train_loss=0.9450 | val_loss=1.0410 | val_auc=0.6482190295473027 | val_f1=0.3653\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.9428 | val_loss=1.0337 | val_auc=0.678351856871781 | val_f1=0.4262\n",
            "Epoch 038 | lr=0.000800 | train_loss=0.9385 | val_loss=1.0272 | val_auc=0.6618053673082136 | val_f1=0.3858\n",
            "Epoch 039 | lr=0.000800 | train_loss=0.9300 | val_loss=1.0780 | val_auc=0.622130658715099 | val_f1=0.3640\n",
            "Epoch 040 | lr=0.000800 | train_loss=0.9209 | val_loss=1.0803 | val_auc=0.6561452968284088 | val_f1=0.3961\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.8862 | val_loss=1.1016 | val_auc=0.6462564380590945 | val_f1=0.3850\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.9182 | val_loss=1.0618 | val_auc=0.6552344808891299 | val_f1=0.3965\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.9093 | val_loss=1.1150 | val_auc=0.6472756844673352 | val_f1=0.3947\n",
            "Best threshold on VAL: t=0.52 | F1=0.4323 | Precision=0.3906 | Recall=0.4839\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.7063\n",
            "PR-AUC: 0.4303\n",
            "Accuracy: 0.7440\n",
            "F1: 0.4386\n",
            "Precision: 0.4011\n",
            "Recall: 0.4839\n",
            "Confusion matrix:\n",
            "[[483 112]\n",
            " [ 80  75]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0935 | val_loss=1.0921 | val_auc=0.582629438872323 | val_f1=0.3576\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0759 | val_loss=1.0423 | val_auc=0.651949037679588 | val_f1=0.3793\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0585 | val_loss=1.0541 | val_auc=0.6349146110056927 | val_f1=0.3465\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0591 | val_loss=1.0633 | val_auc=0.6720845757657902 | val_f1=0.4097\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0488 | val_loss=1.0357 | val_auc=0.6763675792897803 | val_f1=0.3898\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0378 | val_loss=1.0188 | val_auc=0.6709243697478992 | val_f1=0.4140\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0317 | val_loss=1.0334 | val_auc=0.6727351585795609 | val_f1=0.4252\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0302 | val_loss=1.0510 | val_auc=0.6919815668202765 | val_f1=0.4216\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0183 | val_loss=1.0319 | val_auc=0.6662401734887503 | val_f1=0.3980\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0153 | val_loss=1.0356 | val_auc=0.6549525616698293 | val_f1=0.3816\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0185 | val_loss=1.0336 | val_auc=0.6638330170777988 | val_f1=0.3719\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0023 | val_loss=1.0221 | val_auc=0.6925996204933588 | val_f1=0.3966\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0073 | val_loss=1.0613 | val_auc=0.6891732176741665 | val_f1=0.4050\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0067 | val_loss=1.0395 | val_auc=0.6799999999999998 | val_f1=0.3978\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0007 | val_loss=1.0125 | val_auc=0.6849119002439686 | val_f1=0.4216\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9927 | val_loss=1.0182 | val_auc=0.6810084033613445 | val_f1=0.4098\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9976 | val_loss=1.0396 | val_auc=0.6594632691786391 | val_f1=0.4155\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.9987 | val_loss=1.0443 | val_auc=0.6551585795608565 | val_f1=0.3881\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.9936 | val_loss=1.0160 | val_auc=0.680975874220656 | val_f1=0.4050\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.9967 | val_loss=1.0299 | val_auc=0.6696232041203577 | val_f1=0.4219\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9826 | val_loss=1.0174 | val_auc=0.6798481973434536 | val_f1=0.4264\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.9826 | val_loss=1.0364 | val_auc=0.6683870967741934 | val_f1=0.4098\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9827 | val_loss=1.0279 | val_auc=0.6626294388723231 | val_f1=0.3747\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9655 | val_loss=1.0444 | val_auc=0.6526863648685282 | val_f1=0.3982\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9743 | val_loss=1.0130 | val_auc=0.6896503117375984 | val_f1=0.4041\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9713 | val_loss=1.0403 | val_auc=0.6718134995933857 | val_f1=0.3979\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.9507 | val_loss=1.0302 | val_auc=0.6758254269449716 | val_f1=0.4208\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.9597 | val_loss=1.0262 | val_auc=0.6785904039034969 | val_f1=0.4165\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.9663 | val_loss=1.0557 | val_auc=0.6423095689888859 | val_f1=0.3757\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.9286 | val_loss=1.0878 | val_auc=0.616589861751152 | val_f1=0.3659\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.9376 | val_loss=1.0815 | val_auc=0.6101924640824072 | val_f1=0.3546\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.9322 | val_loss=1.0435 | val_auc=0.6547140146381133 | val_f1=0.3945\n",
            "Best threshold on VAL: t=0.45 | F1=0.4407 | Precision=0.3281 | Recall=0.6710\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6788\n",
            "PR-AUC: 0.4073\n",
            "Accuracy: 0.6333\n",
            "F1: 0.4161\n",
            "Precision: 0.3101\n",
            "Recall: 0.6323\n",
            "Confusion matrix:\n",
            "[[377 218]\n",
            " [ 57  98]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6831 ± 0.0175\n",
            "PR-AUC:  0.4076 ± 0.0183\n",
            "F1:      0.4090 ± 0.0276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-03"
      ],
      "metadata": {
        "id": "dcrp2PxJs0J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        # 注意：确保你的脚本开头或者这里导入了 global_max_pool\n",
        "        from torch_geometric.nn import global_max_pool\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6109e3b-e50b-48f3-a94f-4abe4e26612c",
        "id": "Jc52Xq-Ns1oQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1086 | val_loss=1.0712 | val_auc=0.6286148007590133 | val_f1=0.3804\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0732 | val_loss=1.0826 | val_auc=0.6345567904581187 | val_f1=0.3743\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0547 | val_loss=1.1087 | val_auc=0.5452968284087829 | val_f1=0.3103\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0504 | val_loss=1.0611 | val_auc=0.6584982380048794 | val_f1=0.2980\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0485 | val_loss=1.0543 | val_auc=0.633407427487124 | val_f1=0.3679\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0336 | val_loss=1.0427 | val_auc=0.6551694226077528 | val_f1=0.3943\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0305 | val_loss=1.0594 | val_auc=0.6639522905936568 | val_f1=0.3558\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0266 | val_loss=1.0601 | val_auc=0.6761073461642723 | val_f1=0.3206\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0247 | val_loss=1.0243 | val_auc=0.6848685280563838 | val_f1=0.3902\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0311 | val_loss=1.0340 | val_auc=0.6664245052859854 | val_f1=0.3919\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0162 | val_loss=1.0465 | val_auc=0.6557874762808349 | val_f1=0.3666\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0217 | val_loss=1.0404 | val_auc=0.6588885876931417 | val_f1=0.3810\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.9994 | val_loss=1.1690 | val_auc=0.53878015722418 | val_f1=0.2824\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0183 | val_loss=1.0169 | val_auc=0.6836107346164273 | val_f1=0.4225\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0191 | val_loss=1.0363 | val_auc=0.6724098671726754 | val_f1=0.4065\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9985 | val_loss=1.0618 | val_auc=0.6349362970994851 | val_f1=0.3695\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9960 | val_loss=1.0470 | val_auc=0.6441095147736513 | val_f1=0.3932\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0070 | val_loss=1.0319 | val_auc=0.6711520737327188 | val_f1=0.3963\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0133 | val_loss=1.0160 | val_auc=0.6874817023583627 | val_f1=0.4160\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.9972 | val_loss=1.0238 | val_auc=0.6911466522092709 | val_f1=0.4045\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9998 | val_loss=1.0179 | val_auc=0.6866251016535646 | val_f1=0.4221\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0056 | val_loss=1.0294 | val_auc=0.6728110599078342 | val_f1=0.3978\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9929 | val_loss=1.0521 | val_auc=0.6374844131200867 | val_f1=0.4075\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9962 | val_loss=1.0630 | val_auc=0.6318134995933858 | val_f1=0.3807\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9893 | val_loss=1.0573 | val_auc=0.6417348875033885 | val_f1=0.3743\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9816 | val_loss=1.0800 | val_auc=0.6250149091894823 | val_f1=0.3714\n",
            "Epoch 027 | lr=0.001000 | train_loss=0.9892 | val_loss=1.0193 | val_auc=0.6774627270262943 | val_f1=0.4000\n",
            "Epoch 028 | lr=0.001000 | train_loss=0.9790 | val_loss=1.0290 | val_auc=0.6676497695852535 | val_f1=0.3921\n",
            "Epoch 029 | lr=0.001000 | train_loss=0.9804 | val_loss=1.0428 | val_auc=0.6601897533206831 | val_f1=0.4045\n",
            "Epoch 030 | lr=0.001000 | train_loss=0.9916 | val_loss=1.0304 | val_auc=0.6723990241257793 | val_f1=0.3918\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.9752 | val_loss=1.0346 | val_auc=0.6622716183247492 | val_f1=0.4088\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.9734 | val_loss=1.0101 | val_auc=0.6911249661154784 | val_f1=0.4185\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.9673 | val_loss=1.0195 | val_auc=0.6828625643805909 | val_f1=0.4234\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.9643 | val_loss=1.0485 | val_auc=0.6611222553537544 | val_f1=0.3565\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.9729 | val_loss=1.0228 | val_auc=0.6710653293575495 | val_f1=0.4224\n",
            "Epoch 036 | lr=0.000800 | train_loss=0.9517 | val_loss=1.0302 | val_auc=0.6682895093521278 | val_f1=0.3990\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.9664 | val_loss=1.0529 | val_auc=0.6597777175386283 | val_f1=0.3895\n",
            "Epoch 038 | lr=0.000800 | train_loss=0.9519 | val_loss=1.0530 | val_auc=0.6462239089184061 | val_f1=0.3648\n",
            "Epoch 039 | lr=0.000800 | train_loss=0.9636 | val_loss=1.0131 | val_auc=0.6814421252371916 | val_f1=0.4323\n",
            "Epoch 040 | lr=0.000800 | train_loss=0.9574 | val_loss=1.0578 | val_auc=0.6345025752236378 | val_f1=0.3979\n",
            "Best threshold on VAL: t=0.64 | F1=0.4479 | Precision=0.3755 | Recall=0.5548\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6805\n",
            "PR-AUC: 0.3931\n",
            "Accuracy: 0.7053\n",
            "F1: 0.3912\n",
            "Precision: 0.3413\n",
            "Recall: 0.4581\n",
            "Confusion matrix:\n",
            "[[458 137]\n",
            " [ 84  71]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1140 | val_loss=1.0725 | val_auc=0.6330496069395501 | val_f1=0.3742\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0781 | val_loss=1.0736 | val_auc=0.6356519381946326 | val_f1=0.3149\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0689 | val_loss=1.0478 | val_auc=0.6707400379506642 | val_f1=0.4064\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0598 | val_loss=1.0351 | val_auc=0.6617728381675251 | val_f1=0.4028\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0439 | val_loss=1.0335 | val_auc=0.6683762537272975 | val_f1=0.3934\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0381 | val_loss=1.0363 | val_auc=0.6485334779072919 | val_f1=0.3886\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0431 | val_loss=1.0433 | val_auc=0.6428517213336947 | val_f1=0.3785\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0347 | val_loss=1.0328 | val_auc=0.6690810517755489 | val_f1=0.3881\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0385 | val_loss=1.0528 | val_auc=0.6679371103280022 | val_f1=0.3874\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0414 | val_loss=1.0271 | val_auc=0.6821686093792356 | val_f1=0.4133\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0286 | val_loss=1.0502 | val_auc=0.6484467335321225 | val_f1=0.3713\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0262 | val_loss=1.0245 | val_auc=0.6777554892924912 | val_f1=0.3780\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0358 | val_loss=1.0348 | val_auc=0.6497370561127678 | val_f1=0.3887\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0383 | val_loss=1.0379 | val_auc=0.6557766332339388 | val_f1=0.3863\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0264 | val_loss=1.0228 | val_auc=0.6770181621035511 | val_f1=0.4037\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0320 | val_loss=1.0487 | val_auc=0.6358145838980753 | val_f1=0.3578\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0263 | val_loss=1.0272 | val_auc=0.6871564109514774 | val_f1=0.4315\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0209 | val_loss=1.0504 | val_auc=0.6544754676063974 | val_f1=0.3950\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0300 | val_loss=1.0307 | val_auc=0.6809433450799676 | val_f1=0.3879\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0222 | val_loss=1.0095 | val_auc=0.6904635402548116 | val_f1=0.4314\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9955 | val_loss=1.0890 | val_auc=0.6736676606126322 | val_f1=0.3872\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0202 | val_loss=1.0432 | val_auc=0.6485660070479804 | val_f1=0.3687\n",
            "Epoch 023 | lr=0.001000 | train_loss=1.0131 | val_loss=1.0139 | val_auc=0.7011981566820277 | val_f1=0.4349\n",
            "Epoch 024 | lr=0.001000 | train_loss=1.0163 | val_loss=1.0491 | val_auc=0.6443589048522634 | val_f1=0.3711\n",
            "Epoch 025 | lr=0.001000 | train_loss=1.0074 | val_loss=1.0333 | val_auc=0.6715641095147737 | val_f1=0.4036\n",
            "Epoch 026 | lr=0.001000 | train_loss=1.0023 | val_loss=1.0123 | val_auc=0.6910056925996204 | val_f1=0.4203\n",
            "Epoch 027 | lr=0.001000 | train_loss=1.0009 | val_loss=1.0132 | val_auc=0.6785687178097045 | val_f1=0.4033\n",
            "Epoch 028 | lr=0.001000 | train_loss=1.0074 | val_loss=1.0556 | val_auc=0.6315641095147736 | val_f1=0.3536\n",
            "Epoch 029 | lr=0.001000 | train_loss=1.0061 | val_loss=1.0145 | val_auc=0.6894334507996749 | val_f1=0.3908\n",
            "Epoch 030 | lr=0.001000 | train_loss=0.9882 | val_loss=1.0090 | val_auc=0.6879804825155869 | val_f1=0.4123\n",
            "Epoch 031 | lr=0.001000 | train_loss=1.0034 | val_loss=1.0368 | val_auc=0.6635727839522906 | val_f1=0.3866\n",
            "Epoch 032 | lr=0.001000 | train_loss=0.9936 | val_loss=1.0173 | val_auc=0.6705557061534291 | val_f1=0.4145\n",
            "Epoch 033 | lr=0.001000 | train_loss=0.9928 | val_loss=1.0213 | val_auc=0.6676822987259421 | val_f1=0.3973\n",
            "Epoch 034 | lr=0.001000 | train_loss=0.9894 | val_loss=1.0345 | val_auc=0.664505285985362 | val_f1=0.4253\n",
            "Epoch 035 | lr=0.001000 | train_loss=0.9920 | val_loss=1.0188 | val_auc=0.6732014095960966 | val_f1=0.4078\n",
            "Epoch 036 | lr=0.001000 | train_loss=0.9884 | val_loss=1.0001 | val_auc=0.7013174301978856 | val_f1=0.4361\n",
            "Epoch 037 | lr=0.001000 | train_loss=0.9908 | val_loss=1.0217 | val_auc=0.6707508809975604 | val_f1=0.4111\n",
            "Epoch 038 | lr=0.001000 | train_loss=0.9916 | val_loss=1.0169 | val_auc=0.671152073732719 | val_f1=0.3577\n",
            "Epoch 039 | lr=0.001000 | train_loss=0.9745 | val_loss=1.0271 | val_auc=0.6604391433992951 | val_f1=0.3860\n",
            "Epoch 040 | lr=0.001000 | train_loss=0.9871 | val_loss=1.0050 | val_auc=0.6910707508809977 | val_f1=0.4133\n",
            "Epoch 041 | lr=0.001000 | train_loss=0.9735 | val_loss=1.0269 | val_auc=0.665741393331526 | val_f1=0.4127\n",
            "Epoch 042 | lr=0.001000 | train_loss=0.9877 | val_loss=1.0291 | val_auc=0.6587150989428029 | val_f1=0.3905\n",
            "Epoch 043 | lr=0.001000 | train_loss=0.9822 | val_loss=1.0436 | val_auc=0.6312171320140958 | val_f1=0.3573\n",
            "Epoch 044 | lr=0.001000 | train_loss=0.9732 | val_loss=1.0227 | val_auc=0.672865275142315 | val_f1=0.4272\n",
            "Epoch 045 | lr=0.001000 | train_loss=0.9692 | val_loss=1.0410 | val_auc=0.6474925454052589 | val_f1=0.3856\n",
            "Epoch 046 | lr=0.001000 | train_loss=0.9701 | val_loss=1.0283 | val_auc=0.648110599078341 | val_f1=0.3636\n",
            "Epoch 047 | lr=0.001000 | train_loss=0.9709 | val_loss=1.0508 | val_auc=0.6311846028734074 | val_f1=0.3675\n",
            "Epoch 048 | lr=0.000800 | train_loss=0.9618 | val_loss=1.0394 | val_auc=0.6375928435890484 | val_f1=0.3612\n",
            "Epoch 049 | lr=0.000800 | train_loss=0.9453 | val_loss=1.0480 | val_auc=0.6364001084304689 | val_f1=0.3777\n",
            "Epoch 050 | lr=0.000800 | train_loss=0.9552 | val_loss=1.0888 | val_auc=0.6031661696936839 | val_f1=0.3475\n",
            "Epoch 051 | lr=0.000800 | train_loss=0.9526 | val_loss=1.0428 | val_auc=0.6404554079696395 | val_f1=0.3824\n",
            "Epoch 052 | lr=0.000800 | train_loss=0.9520 | val_loss=1.0297 | val_auc=0.6597560314448361 | val_f1=0.4198\n",
            "Epoch 053 | lr=0.000800 | train_loss=0.9379 | val_loss=1.0705 | val_auc=0.6204174573055028 | val_f1=0.3546\n",
            "Epoch 054 | lr=0.000800 | train_loss=0.9535 | val_loss=1.0507 | val_auc=0.639078341013825 | val_f1=0.3740\n",
            "Epoch 055 | lr=0.000800 | train_loss=0.9344 | val_loss=1.0479 | val_auc=0.6430794253185146 | val_f1=0.3618\n",
            "Epoch 056 | lr=0.000800 | train_loss=0.9168 | val_loss=1.1196 | val_auc=0.5972241799945786 | val_f1=0.3467\n",
            "Best threshold on VAL: t=0.56 | F1=0.4633 | Precision=0.4247 | Recall=0.5097\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.7170\n",
            "PR-AUC: 0.3895\n",
            "Accuracy: 0.7307\n",
            "F1: 0.4420\n",
            "Precision: 0.3865\n",
            "Recall: 0.5161\n",
            "Confusion matrix:\n",
            "[[468 127]\n",
            " [ 75  80]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1055 | val_loss=1.0829 | val_auc=0.6145188397939821 | val_f1=0.3239\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0670 | val_loss=1.0506 | val_auc=0.6452697207915424 | val_f1=0.3574\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0624 | val_loss=1.0875 | val_auc=0.5974193548387097 | val_f1=0.2452\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0556 | val_loss=1.0452 | val_auc=0.6624342640281919 | val_f1=0.3780\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0389 | val_loss=1.0407 | val_auc=0.6546597994036324 | val_f1=0.3713\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0346 | val_loss=1.0148 | val_auc=0.6836107346164273 | val_f1=0.4104\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0338 | val_loss=1.0575 | val_auc=0.636042287882895 | val_f1=0.3418\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0381 | val_loss=1.0436 | val_auc=0.6855950121984278 | val_f1=0.3880\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0224 | val_loss=1.0541 | val_auc=0.651710490647872 | val_f1=0.3899\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0268 | val_loss=1.0692 | val_auc=0.652317701274058 | val_f1=0.2435\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0194 | val_loss=1.0423 | val_auc=0.6549308755760368 | val_f1=0.3967\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0196 | val_loss=1.0396 | val_auc=0.6733857413933315 | val_f1=0.3920\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0235 | val_loss=1.1467 | val_auc=0.6842179452426131 | val_f1=0.4052\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0190 | val_loss=1.0448 | val_auc=0.6696232041203578 | val_f1=0.4056\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0062 | val_loss=1.0384 | val_auc=0.6669124423963133 | val_f1=0.4033\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0156 | val_loss=1.0381 | val_auc=0.6671835185687178 | val_f1=0.3951\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0113 | val_loss=1.0349 | val_auc=0.6652100840336135 | val_f1=0.4141\n",
            "Epoch 018 | lr=0.000800 | train_loss=1.0030 | val_loss=1.0248 | val_auc=0.6833938736785036 | val_f1=0.3884\n",
            "Epoch 019 | lr=0.000800 | train_loss=1.0012 | val_loss=1.0474 | val_auc=0.6926321496340472 | val_f1=0.2731\n",
            "Epoch 020 | lr=0.000800 | train_loss=1.0049 | val_loss=1.0095 | val_auc=0.6960802385470317 | val_f1=0.4053\n",
            "Epoch 021 | lr=0.000800 | train_loss=0.9943 | val_loss=1.0310 | val_auc=0.6614367037137436 | val_f1=0.3799\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.9825 | val_loss=1.0234 | val_auc=0.6957441040932503 | val_f1=0.3950\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.9798 | val_loss=1.0303 | val_auc=0.6786446191379778 | val_f1=0.3977\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.9882 | val_loss=0.9988 | val_auc=0.7048739495798318 | val_f1=0.4264\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.9749 | val_loss=1.0149 | val_auc=0.6983789644890215 | val_f1=0.4086\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.9754 | val_loss=1.0175 | val_auc=0.6810517755489292 | val_f1=0.4161\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.9764 | val_loss=1.0252 | val_auc=0.6886744375169422 | val_f1=0.4127\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.9776 | val_loss=1.0194 | val_auc=0.6817348875033884 | val_f1=0.4019\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.9746 | val_loss=1.0316 | val_auc=0.662564380590946 | val_f1=0.4009\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.9648 | val_loss=1.0301 | val_auc=0.6640607210626186 | val_f1=0.3946\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.9675 | val_loss=1.0516 | val_auc=0.6679208457576579 | val_f1=0.4089\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.9678 | val_loss=1.0373 | val_auc=0.667497966928707 | val_f1=0.3837\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.9592 | val_loss=1.0555 | val_auc=0.6541827053402006 | val_f1=0.3911\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.9645 | val_loss=1.0205 | val_auc=0.6781133098400651 | val_f1=0.4249\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.9691 | val_loss=1.0283 | val_auc=0.6719653022499322 | val_f1=0.4094\n",
            "Epoch 036 | lr=0.000640 | train_loss=0.9319 | val_loss=1.0461 | val_auc=0.6665004066142587 | val_f1=0.3972\n",
            "Epoch 037 | lr=0.000640 | train_loss=0.9520 | val_loss=1.0504 | val_auc=0.6420927080509624 | val_f1=0.3514\n",
            "Epoch 038 | lr=0.000640 | train_loss=0.9542 | val_loss=1.0200 | val_auc=0.6755977229601519 | val_f1=0.4018\n",
            "Epoch 039 | lr=0.000640 | train_loss=0.9416 | val_loss=1.0203 | val_auc=0.6827541339116291 | val_f1=0.3702\n",
            "Epoch 040 | lr=0.000640 | train_loss=0.9232 | val_loss=1.0271 | val_auc=0.6719327731092436 | val_f1=0.4163\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.9291 | val_loss=1.0420 | val_auc=0.6508430468961778 | val_f1=0.3719\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.9302 | val_loss=1.0331 | val_auc=0.6746543778801843 | val_f1=0.3943\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.9150 | val_loss=1.0518 | val_auc=0.6573055028462997 | val_f1=0.3698\n",
            "Epoch 044 | lr=0.000640 | train_loss=0.9283 | val_loss=1.0265 | val_auc=0.6731146652209272 | val_f1=0.4137\n",
            "Best threshold on VAL: t=0.54 | F1=0.4383 | Precision=0.3270 | Recall=0.6645\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6644\n",
            "PR-AUC: 0.3944\n",
            "Accuracy: 0.6347\n",
            "F1: 0.4043\n",
            "Precision: 0.3049\n",
            "Recall: 0.6000\n",
            "Confusion matrix:\n",
            "[[383 212]\n",
            " [ 62  93]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6873 ± 0.0220\n",
            "PR-AUC:  0.3924 ± 0.0021\n",
            "F1:      0.4125 ± 0.0215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-04"
      ],
      "metadata": {
        "id": "8BHGbKKpzg-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        # 注意：确保你的脚本开头或者这里导入了 global_max_pool\n",
        "        from torch_geometric.nn import global_max_pool\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "# 改\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss 专门用于处理类别不平衡，并让模型关注难分类样本。\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        # inputs 是 logits, targets 是 0/1 标签\n",
        "        p = torch.sigmoid(inputs)\n",
        "        ce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
        "\n",
        "        # p_t: 预测值与真实标签的接近程度\n",
        "        p_t = p * targets + (1 - p) * (1 - targets)\n",
        "\n",
        "        # Focal 核心：(1 - p_t)^gamma\n",
        "        loss = ce_loss * ((1 - p_t) ** self.gamma)\n",
        "\n",
        "        if self.alpha >= 0:\n",
        "            # alpha 用于平衡正负样本比例\n",
        "            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
        "            loss = alpha_t * loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return loss.mean()\n",
        "        return loss.sum()\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=30, #改\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "# 修改点 2: 使用 FocalLoss 替代 BCEWithLogitsLoss\n",
        "    # 对于 1:4 的不平衡比例，alpha 设为 0.25 是常用标准\n",
        "    criterion = FocalLoss(alpha=0.25, gamma=2.0)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, criterion=criterion)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, criterion=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "# 如果没有传入 criterion，默认使用基础的 BCE（兜底方案）\n",
        "    if criterion is None:\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y) # 使用与训练一致的 Loss\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=30,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        test_criterion = FocalLoss(alpha=0.8, gamma=2.0)\n",
        "        metrics = eval_model(model, test_loader, device, criterion=test_criterion, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r4-pHHsnziVE",
        "outputId": "400bbce1-9d86-4554-c116-6dbcb5a1d49e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.0527 | val_loss=0.0526 | val_auc=0.628961778259691 | val_f1=0.0000\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.0498 | val_loss=0.0547 | val_auc=0.5983193277310924 | val_f1=0.0000\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.0492 | val_loss=0.0493 | val_auc=0.629449715370019 | val_f1=0.0000\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.0494 | val_loss=0.0516 | val_auc=0.6399566278124154 | val_f1=0.0000\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.0492 | val_loss=0.0514 | val_auc=0.5859148820818649 | val_f1=0.0000\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.0487 | val_loss=0.0484 | val_auc=0.6244076985632964 | val_f1=0.0000\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.0486 | val_loss=0.0484 | val_auc=0.6649606939550012 | val_f1=0.0000\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.0478 | val_loss=0.0486 | val_auc=0.6568067226890756 | val_f1=0.0000\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.0480 | val_loss=0.0488 | val_auc=0.6579723502304148 | val_f1=0.0000\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.0479 | val_loss=0.0482 | val_auc=0.6307508809975603 | val_f1=0.0000\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.0480 | val_loss=0.0475 | val_auc=0.6722905936568175 | val_f1=0.0000\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.0478 | val_loss=0.0540 | val_auc=0.46293304418541614 | val_f1=0.0000\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.0479 | val_loss=0.0501 | val_auc=0.6674112225535376 | val_f1=0.0000\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.0482 | val_loss=0.0486 | val_auc=0.6459853618866902 | val_f1=0.0000\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.0477 | val_loss=0.0473 | val_auc=0.6602656546489564 | val_f1=0.0000\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.0477 | val_loss=0.0482 | val_auc=0.6316183247492545 | val_f1=0.0000\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.0472 | val_loss=0.0477 | val_auc=0.6515586879913254 | val_f1=0.0000\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.0474 | val_loss=0.0487 | val_auc=0.632377338031987 | val_f1=0.0000\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.0475 | val_loss=0.0471 | val_auc=0.6421577663323393 | val_f1=0.0000\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.0467 | val_loss=0.0481 | val_auc=0.6374844131200867 | val_f1=0.0000\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.0470 | val_loss=0.0478 | val_auc=0.619029547302792 | val_f1=0.0000\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.0474 | val_loss=0.0483 | val_auc=0.6412144212523719 | val_f1=0.0000\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.0476 | val_loss=0.0477 | val_auc=0.6316508538899431 | val_f1=0.0000\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.0471 | val_loss=0.0488 | val_auc=0.646288967199783 | val_f1=0.0000\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.0474 | val_loss=0.0484 | val_auc=0.6165302249932231 | val_f1=0.0000\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.0474 | val_loss=0.0472 | val_auc=0.6496177825969098 | val_f1=0.0000\n",
            "Epoch 027 | lr=0.001000 | train_loss=0.0474 | val_loss=0.0475 | val_auc=0.6298183789644891 | val_f1=0.0000\n",
            "Epoch 028 | lr=0.001000 | train_loss=0.0471 | val_loss=0.0469 | val_auc=0.6608294930875576 | val_f1=0.0000\n",
            "Epoch 029 | lr=0.001000 | train_loss=0.0471 | val_loss=0.0475 | val_auc=0.6153320683111955 | val_f1=0.0000\n",
            "Epoch 030 | lr=0.001000 | train_loss=0.0468 | val_loss=0.0474 | val_auc=0.6393602602331255 | val_f1=0.0000\n",
            "Epoch 031 | lr=0.001000 | train_loss=0.0468 | val_loss=0.0470 | val_auc=0.6487069666576308 | val_f1=0.0000\n",
            "Epoch 032 | lr=0.001000 | train_loss=0.0471 | val_loss=0.0481 | val_auc=0.5756898888587694 | val_f1=0.0000\n",
            "Epoch 033 | lr=0.001000 | train_loss=0.0470 | val_loss=0.0490 | val_auc=0.610246679316888 | val_f1=0.0000\n",
            "Epoch 034 | lr=0.001000 | train_loss=0.0472 | val_loss=0.0476 | val_auc=0.6297858498238005 | val_f1=0.0000\n",
            "Epoch 035 | lr=0.001000 | train_loss=0.0475 | val_loss=0.0478 | val_auc=0.6012577934399566 | val_f1=0.0000\n",
            "Epoch 036 | lr=0.001000 | train_loss=0.0466 | val_loss=0.0472 | val_auc=0.6571374356194091 | val_f1=0.0000\n",
            "Epoch 037 | lr=0.001000 | train_loss=0.0469 | val_loss=0.0476 | val_auc=0.6249390078612089 | val_f1=0.0000\n",
            "Epoch 038 | lr=0.001000 | train_loss=0.0467 | val_loss=0.0473 | val_auc=0.6358579560856601 | val_f1=0.0000\n",
            "Epoch 039 | lr=0.001000 | train_loss=0.0469 | val_loss=0.0468 | val_auc=0.6557657901870426 | val_f1=0.0000\n",
            "Epoch 040 | lr=0.001000 | train_loss=0.0470 | val_loss=0.0476 | val_auc=0.6179560856600705 | val_f1=0.0000\n",
            "Epoch 041 | lr=0.001000 | train_loss=0.0467 | val_loss=0.0474 | val_auc=0.6204825155868798 | val_f1=0.0000\n",
            "Best threshold on VAL: t=0.31 | F1=0.4236 | Precision=0.3624 | Recall=0.5097\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6383\n",
            "PR-AUC: 0.3591\n",
            "Accuracy: 0.6933\n",
            "F1: 0.3784\n",
            "Precision: 0.3256\n",
            "Recall: 0.4516\n",
            "Confusion matrix:\n",
            "[[450 145]\n",
            " [ 85  70]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.0562 | val_loss=0.0532 | val_auc=0.6340580103008945 | val_f1=0.0000\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.0508 | val_loss=0.0582 | val_auc=0.609259962049336 | val_f1=0.0000\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.0497 | val_loss=0.0505 | val_auc=0.6229276226619681 | val_f1=0.0000\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.0496 | val_loss=0.0519 | val_auc=0.6204391433992953 | val_f1=0.0000\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.0501 | val_loss=0.0538 | val_auc=0.6442504743833017 | val_f1=0.0000\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.0495 | val_loss=0.0511 | val_auc=0.6037516942260776 | val_f1=0.0000\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.0499 | val_loss=0.0502 | val_auc=0.6681268636486852 | val_f1=0.0000\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.0481 | val_loss=0.0515 | val_auc=0.6859203036053131 | val_f1=0.0000\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.0485 | val_loss=0.0509 | val_auc=0.6389373814041746 | val_f1=0.0000\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.0484 | val_loss=0.0482 | val_auc=0.6617511520737327 | val_f1=0.0000\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.0485 | val_loss=0.0494 | val_auc=0.6491840607210626 | val_f1=0.0000\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.0483 | val_loss=0.0484 | val_auc=0.66243968555164 | val_f1=0.0000\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.0482 | val_loss=0.0473 | val_auc=0.6853456221198158 | val_f1=0.0000\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.0483 | val_loss=0.0480 | val_auc=0.6707617240444566 | val_f1=0.0000\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.0482 | val_loss=0.0480 | val_auc=0.6384494442938465 | val_f1=0.0000\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.0483 | val_loss=0.0501 | val_auc=0.6048359989156953 | val_f1=0.0000\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.0481 | val_loss=0.0477 | val_auc=0.6429601518026564 | val_f1=0.0000\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.0477 | val_loss=0.0475 | val_auc=0.6818650040661425 | val_f1=0.0000\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.0477 | val_loss=0.0478 | val_auc=0.6443697478991596 | val_f1=0.0000\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.0480 | val_loss=0.0486 | val_auc=0.6511791813499593 | val_f1=0.0000\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.0475 | val_loss=0.0479 | val_auc=0.645432366494985 | val_f1=0.0000\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.0477 | val_loss=0.0475 | val_auc=0.6674762808349146 | val_f1=0.0000\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.0475 | val_loss=0.0479 | val_auc=0.6627703984819734 | val_f1=0.0000\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.0480 | val_loss=0.0480 | val_auc=0.6591921930062347 | val_f1=0.0000\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.0478 | val_loss=0.0482 | val_auc=0.6007698563296286 | val_f1=0.0000\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.0479 | val_loss=0.0468 | val_auc=0.6716291677961507 | val_f1=0.0000\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.0474 | val_loss=0.0478 | val_auc=0.6589428029276228 | val_f1=0.0000\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.0475 | val_loss=0.0483 | val_auc=0.6144754676063973 | val_f1=0.0000\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.0479 | val_loss=0.0474 | val_auc=0.661339116291678 | val_f1=0.0000\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.0477 | val_loss=0.0471 | val_auc=0.6701545134182706 | val_f1=0.0000\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.0476 | val_loss=0.0480 | val_auc=0.6539007861208999 | val_f1=0.0000\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.0478 | val_loss=0.0482 | val_auc=0.6926321496340472 | val_f1=0.0000\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.0476 | val_loss=0.0472 | val_auc=0.6831878557874762 | val_f1=0.0000\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.0476 | val_loss=0.0480 | val_auc=0.6900135538086202 | val_f1=0.0000\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.0480 | val_loss=0.0475 | val_auc=0.6786337760910817 | val_f1=0.0000\n",
            "Epoch 036 | lr=0.000800 | train_loss=0.0474 | val_loss=0.0476 | val_auc=0.6358362699918677 | val_f1=0.0000\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.0477 | val_loss=0.0477 | val_auc=0.6576470588235294 | val_f1=0.0000\n",
            "Epoch 038 | lr=0.000640 | train_loss=0.0474 | val_loss=0.0475 | val_auc=0.6899213879100028 | val_f1=0.0000\n",
            "Epoch 039 | lr=0.000640 | train_loss=0.0475 | val_loss=0.0476 | val_auc=0.6779289780428299 | val_f1=0.0000\n",
            "Epoch 040 | lr=0.000640 | train_loss=0.0474 | val_loss=0.0476 | val_auc=0.6602873407427486 | val_f1=0.0000\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.0471 | val_loss=0.0473 | val_auc=0.68561669829222 | val_f1=0.0000\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.0474 | val_loss=0.0474 | val_auc=0.6543561940905394 | val_f1=0.0000\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.0474 | val_loss=0.0469 | val_auc=0.6980211439414475 | val_f1=0.0000\n",
            "Epoch 044 | lr=0.000640 | train_loss=0.0473 | val_loss=0.0477 | val_auc=0.6237788018433179 | val_f1=0.0000\n",
            "Epoch 045 | lr=0.000640 | train_loss=0.0472 | val_loss=0.0478 | val_auc=0.6610355109785849 | val_f1=0.0000\n",
            "Epoch 046 | lr=0.000640 | train_loss=0.0474 | val_loss=0.0477 | val_auc=0.6884792626728111 | val_f1=0.0000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3923711082.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3923711082.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"best_model_seed{seed}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         train_model(\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3923711082.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, lr, weight_decay, epochs, patience, model_path)\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3923711082.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvirtualnode_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/gin_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-05"
      ],
      "metadata": {
        "id": "XP9MCRjI5Aph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.4, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.norms[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        # 注意：确保你的脚本开头或者这里导入了 global_max_pool\n",
        "        from torch_geometric.nn import global_max_pool\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.2, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2uk3ov-15CWm",
        "outputId": "8dd73282-154d-4a84-ca26-71dba21c8880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1055 | val_loss=1.0858 | val_auc=0.5905069124423963 | val_f1=0.3706\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.1006 | val_loss=1.0996 | val_auc=0.5851558687991326 | val_f1=0.0000\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0992 | val_loss=1.0950 | val_auc=0.585492003252914 | val_f1=0.0000\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0952 | val_loss=1.0961 | val_auc=0.5796150718351857 | val_f1=0.0000\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0954 | val_loss=1.0971 | val_auc=0.5843643263757116 | val_f1=0.3444\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0940 | val_loss=1.0968 | val_auc=0.5825698021143941 | val_f1=0.3623\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0980 | val_loss=1.0869 | val_auc=0.5810246679316888 | val_f1=0.3623\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0918 | val_loss=1.0853 | val_auc=0.5817511520737327 | val_f1=0.3688\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0906 | val_loss=1.0840 | val_auc=0.5841420439143399 | val_f1=0.3704\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0902 | val_loss=1.0930 | val_auc=0.5830360531309297 | val_f1=0.3577\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0905 | val_loss=1.0792 | val_auc=0.5809053944158309 | val_f1=0.3760\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0868 | val_loss=1.0797 | val_auc=0.5968338303063161 | val_f1=0.3762\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0831 | val_loss=1.0931 | val_auc=0.602374627270263 | val_f1=0.3840\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0891 | val_loss=1.0744 | val_auc=0.6074058010300895 | val_f1=0.3659\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0809 | val_loss=1.0799 | val_auc=0.6101816210355109 | val_f1=0.3704\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0729 | val_loss=1.0802 | val_auc=0.5929574410409325 | val_f1=0.3438\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0668 | val_loss=1.0820 | val_auc=0.5896286256438059 | val_f1=0.3256\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0693 | val_loss=1.0933 | val_auc=0.598655462184874 | val_f1=0.3431\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0634 | val_loss=1.0829 | val_auc=0.6012577934399567 | val_f1=0.3514\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0589 | val_loss=1.0829 | val_auc=0.6150880997560313 | val_f1=0.3602\n",
            "Epoch 021 | lr=0.001000 | train_loss=1.0610 | val_loss=1.0768 | val_auc=0.6113960422878828 | val_f1=0.3545\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0673 | val_loss=1.0821 | val_auc=0.5998156682027649 | val_f1=0.3608\n",
            "Epoch 023 | lr=0.001000 | train_loss=1.0678 | val_loss=1.0737 | val_auc=0.610788831661697 | val_f1=0.3664\n",
            "Epoch 024 | lr=0.001000 | train_loss=1.0657 | val_loss=1.0777 | val_auc=0.6071997831390621 | val_f1=0.3679\n",
            "Epoch 025 | lr=0.001000 | train_loss=1.0591 | val_loss=1.0663 | val_auc=0.6223963133640553 | val_f1=0.3606\n",
            "Epoch 026 | lr=0.001000 | train_loss=1.0591 | val_loss=1.0773 | val_auc=0.606771482786663 | val_f1=0.3728\n",
            "Epoch 027 | lr=0.001000 | train_loss=1.0562 | val_loss=1.0705 | val_auc=0.6147248576850094 | val_f1=0.3752\n",
            "Epoch 028 | lr=0.001000 | train_loss=1.0534 | val_loss=1.0742 | val_auc=0.6165302249932231 | val_f1=0.3770\n",
            "Epoch 029 | lr=0.001000 | train_loss=1.0508 | val_loss=1.0840 | val_auc=0.6017511520737326 | val_f1=0.3534\n",
            "Epoch 030 | lr=0.001000 | train_loss=1.0545 | val_loss=1.0763 | val_auc=0.6082298725941989 | val_f1=0.3510\n",
            "Epoch 031 | lr=0.001000 | train_loss=1.0527 | val_loss=1.0743 | val_auc=0.6140634318243426 | val_f1=0.3508\n",
            "Epoch 032 | lr=0.001000 | train_loss=1.0451 | val_loss=1.0994 | val_auc=0.6020818650040662 | val_f1=0.3562\n",
            "Epoch 033 | lr=0.001000 | train_loss=1.0490 | val_loss=1.0710 | val_auc=0.612865275142315 | val_f1=0.3534\n",
            "Epoch 034 | lr=0.001000 | train_loss=1.0469 | val_loss=1.0918 | val_auc=0.6042396313364056 | val_f1=0.3494\n",
            "Epoch 035 | lr=0.001000 | train_loss=1.0576 | val_loss=1.0727 | val_auc=0.6144483599891569 | val_f1=0.3581\n",
            "Epoch 036 | lr=0.001000 | train_loss=1.0490 | val_loss=1.0978 | val_auc=0.594697750067769 | val_f1=0.3597\n",
            "Epoch 037 | lr=0.000800 | train_loss=1.0531 | val_loss=1.0684 | val_auc=0.6174193548387097 | val_f1=0.3567\n",
            "Epoch 038 | lr=0.000800 | train_loss=1.0510 | val_loss=1.0677 | val_auc=0.6199620493358633 | val_f1=0.3644\n",
            "Epoch 039 | lr=0.000800 | train_loss=1.0480 | val_loss=1.0665 | val_auc=0.6147628083491461 | val_f1=0.3720\n",
            "Epoch 040 | lr=0.000800 | train_loss=1.0488 | val_loss=1.0652 | val_auc=0.6224667931688804 | val_f1=0.3681\n",
            "Epoch 041 | lr=0.000800 | train_loss=1.0447 | val_loss=1.0676 | val_auc=0.6206776904310111 | val_f1=0.3673\n",
            "Epoch 042 | lr=0.000800 | train_loss=1.0451 | val_loss=1.0780 | val_auc=0.6134995933857414 | val_f1=0.3686\n",
            "Epoch 043 | lr=0.000800 | train_loss=1.0496 | val_loss=1.0708 | val_auc=0.6155706153429112 | val_f1=0.3427\n",
            "Epoch 044 | lr=0.000800 | train_loss=1.0521 | val_loss=1.0715 | val_auc=0.6181946326917863 | val_f1=0.3482\n",
            "Epoch 045 | lr=0.000800 | train_loss=1.0474 | val_loss=1.0718 | val_auc=0.6121550555706153 | val_f1=0.3540\n",
            "Epoch 046 | lr=0.000800 | train_loss=1.0471 | val_loss=1.0667 | val_auc=0.6305448631065329 | val_f1=0.3459\n",
            "Epoch 047 | lr=0.000800 | train_loss=1.0416 | val_loss=1.0634 | val_auc=0.6310219571699647 | val_f1=0.3668\n",
            "Epoch 048 | lr=0.000800 | train_loss=1.0477 | val_loss=1.0714 | val_auc=0.6176633233938736 | val_f1=0.3590\n",
            "Epoch 049 | lr=0.000800 | train_loss=1.0407 | val_loss=1.0726 | val_auc=0.6223258335592301 | val_f1=0.3690\n",
            "Epoch 050 | lr=0.000800 | train_loss=1.0430 | val_loss=1.0761 | val_auc=0.6220981295744105 | val_f1=0.3554\n",
            "Epoch 051 | lr=0.000800 | train_loss=1.0388 | val_loss=1.0720 | val_auc=0.6183789644890214 | val_f1=0.3567\n",
            "Epoch 052 | lr=0.000800 | train_loss=1.0415 | val_loss=1.0696 | val_auc=0.6191271347248577 | val_f1=0.3592\n",
            "Epoch 053 | lr=0.000800 | train_loss=1.0365 | val_loss=1.0907 | val_auc=0.6146923285443209 | val_f1=0.3366\n",
            "Epoch 054 | lr=0.000800 | train_loss=1.0427 | val_loss=1.0674 | val_auc=0.6310544863106532 | val_f1=0.3592\n",
            "Epoch 055 | lr=0.000800 | train_loss=1.0365 | val_loss=1.0619 | val_auc=0.6279425318514502 | val_f1=0.3560\n",
            "Epoch 056 | lr=0.000800 | train_loss=1.0402 | val_loss=1.0720 | val_auc=0.6088804554079696 | val_f1=0.3223\n",
            "Epoch 057 | lr=0.000800 | train_loss=1.0373 | val_loss=1.0683 | val_auc=0.6256600704798048 | val_f1=0.3578\n",
            "Epoch 058 | lr=0.000800 | train_loss=1.0309 | val_loss=1.0655 | val_auc=0.6330279208457577 | val_f1=0.3529\n",
            "Epoch 059 | lr=0.000800 | train_loss=1.0393 | val_loss=1.0730 | val_auc=0.6307834101382488 | val_f1=0.3657\n",
            "Epoch 060 | lr=0.000800 | train_loss=1.0339 | val_loss=1.0657 | val_auc=0.6235294117647059 | val_f1=0.3527\n",
            "Epoch 061 | lr=0.000800 | train_loss=1.0323 | val_loss=1.0901 | val_auc=0.6255245323936025 | val_f1=0.3588\n",
            "Epoch 062 | lr=0.000800 | train_loss=1.0324 | val_loss=1.0558 | val_auc=0.6476551911087016 | val_f1=0.3295\n",
            "Epoch 063 | lr=0.000800 | train_loss=1.0269 | val_loss=1.0664 | val_auc=0.6346543778801842 | val_f1=0.3197\n",
            "Epoch 064 | lr=0.000800 | train_loss=1.0258 | val_loss=1.0688 | val_auc=0.626955814583898 | val_f1=0.3603\n",
            "Epoch 065 | lr=0.000800 | train_loss=1.0254 | val_loss=1.0657 | val_auc=0.6389265383572784 | val_f1=0.3632\n",
            "Epoch 066 | lr=0.000800 | train_loss=1.0254 | val_loss=1.0520 | val_auc=0.650550284629981 | val_f1=0.3520\n",
            "Epoch 067 | lr=0.000800 | train_loss=1.0298 | val_loss=1.0514 | val_auc=0.6450094876660342 | val_f1=0.3774\n",
            "Epoch 068 | lr=0.000800 | train_loss=1.0182 | val_loss=1.0679 | val_auc=0.6331797235023042 | val_f1=0.3586\n",
            "Epoch 069 | lr=0.000800 | train_loss=1.0165 | val_loss=1.0589 | val_auc=0.6326267281105991 | val_f1=0.3435\n",
            "Epoch 070 | lr=0.000800 | train_loss=1.0156 | val_loss=1.0567 | val_auc=0.6327893738140418 | val_f1=0.3606\n",
            "Epoch 071 | lr=0.000800 | train_loss=1.0203 | val_loss=1.0766 | val_auc=0.6322363784223365 | val_f1=0.3732\n",
            "Epoch 072 | lr=0.000800 | train_loss=1.0155 | val_loss=1.0621 | val_auc=0.6397289238275956 | val_f1=0.3287\n",
            "Epoch 073 | lr=0.000800 | train_loss=1.0104 | val_loss=1.0680 | val_auc=0.6292003252914069 | val_f1=0.3651\n",
            "Epoch 074 | lr=0.000800 | train_loss=1.0136 | val_loss=1.0543 | val_auc=0.6355977229601517 | val_f1=0.3269\n",
            "Epoch 075 | lr=0.000800 | train_loss=1.0134 | val_loss=1.0612 | val_auc=0.6387964217945242 | val_f1=0.3717\n",
            "Epoch 076 | lr=0.000800 | train_loss=1.0098 | val_loss=1.0621 | val_auc=0.642754133911629 | val_f1=0.3269\n",
            "Epoch 077 | lr=0.000800 | train_loss=1.0074 | val_loss=1.0600 | val_auc=0.6362157766332338 | val_f1=0.3581\n",
            "Epoch 078 | lr=0.000800 | train_loss=1.0140 | val_loss=1.0581 | val_auc=0.6314936297099485 | val_f1=0.3805\n",
            "Epoch 079 | lr=0.000640 | train_loss=0.9983 | val_loss=1.0668 | val_auc=0.6417132014095961 | val_f1=0.3222\n",
            "Epoch 080 | lr=0.000640 | train_loss=0.9975 | val_loss=1.0680 | val_auc=0.6353374898346434 | val_f1=0.3464\n",
            "Epoch 081 | lr=0.000640 | train_loss=0.9971 | val_loss=1.0618 | val_auc=0.629211168338303 | val_f1=0.3526\n",
            "Epoch 082 | lr=0.000640 | train_loss=0.9926 | val_loss=1.0546 | val_auc=0.638601246950393 | val_f1=0.3834\n",
            "Epoch 083 | lr=0.000640 | train_loss=0.9837 | val_loss=1.0676 | val_auc=0.6314339929520195 | val_f1=0.3632\n",
            "Epoch 084 | lr=0.000640 | train_loss=0.9841 | val_loss=1.0729 | val_auc=0.6386879913255624 | val_f1=0.3260\n",
            "Epoch 085 | lr=0.000640 | train_loss=0.9857 | val_loss=1.0665 | val_auc=0.6393602602331256 | val_f1=0.3617\n",
            "Epoch 086 | lr=0.000640 | train_loss=0.9776 | val_loss=1.0769 | val_auc=0.6330712930333424 | val_f1=0.3794\n",
            "Best threshold on VAL: t=0.44 | F1=0.3977 | Precision=0.2826 | Recall=0.6710\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6233\n",
            "PR-AUC: 0.3061\n",
            "Accuracy: 0.5573\n",
            "F1: 0.3736\n",
            "Precision: 0.2640\n",
            "Recall: 0.6387\n",
            "Confusion matrix:\n",
            "[[319 276]\n",
            " [ 56  99]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1080 | val_loss=1.0962 | val_auc=0.5619354838709677 | val_f1=0.0000\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0917 | val_loss=1.1037 | val_auc=0.533353212252643 | val_f1=0.3425\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.1006 | val_loss=1.0988 | val_auc=0.5394578476551911 | val_f1=0.0000\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.1001 | val_loss=1.0857 | val_auc=0.5529140688533477 | val_f1=0.3407\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.1034 | val_loss=1.0988 | val_auc=0.5491244239631337 | val_f1=0.0000\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0994 | val_loss=1.0886 | val_auc=0.5630523177012741 | val_f1=0.3598\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.1013 | val_loss=1.0971 | val_auc=0.5647384114936297 | val_f1=0.3571\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0944 | val_loss=1.0830 | val_auc=0.5364163730008132 | val_f1=0.3683\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0945 | val_loss=1.0863 | val_auc=0.53804283003524 | val_f1=0.3677\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0880 | val_loss=1.0880 | val_auc=0.5427432908647329 | val_f1=0.3610\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0902 | val_loss=1.0932 | val_auc=0.576589861751152 | val_f1=0.2373\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0897 | val_loss=1.0882 | val_auc=0.5549200325291407 | val_f1=0.3590\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0892 | val_loss=1.0851 | val_auc=0.5460233125508267 | val_f1=0.3660\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0872 | val_loss=1.0934 | val_auc=0.5595445920303606 | val_f1=0.3557\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0877 | val_loss=1.0837 | val_auc=0.5590024396855516 | val_f1=0.3641\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0842 | val_loss=1.0885 | val_auc=0.5555597722960152 | val_f1=0.3619\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0866 | val_loss=1.0793 | val_auc=0.549146110056926 | val_f1=0.3693\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0801 | val_loss=1.0761 | val_auc=0.5577229601518026 | val_f1=0.3644\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0835 | val_loss=1.0877 | val_auc=0.5647926267281106 | val_f1=0.3230\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0842 | val_loss=1.0796 | val_auc=0.5879533748983465 | val_f1=0.3697\n",
            "Epoch 021 | lr=0.001000 | train_loss=1.0799 | val_loss=1.0792 | val_auc=0.5690593656817566 | val_f1=0.3689\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0801 | val_loss=1.0759 | val_auc=0.5652914068853347 | val_f1=0.3700\n",
            "Epoch 023 | lr=0.001000 | train_loss=1.0741 | val_loss=1.0740 | val_auc=0.5683491461100569 | val_f1=0.3735\n",
            "Epoch 024 | lr=0.001000 | train_loss=1.0795 | val_loss=1.0864 | val_auc=0.5611114123068582 | val_f1=0.3615\n",
            "Epoch 025 | lr=0.001000 | train_loss=1.0787 | val_loss=1.0772 | val_auc=0.56036866359447 | val_f1=0.3677\n",
            "Epoch 026 | lr=0.001000 | train_loss=1.0734 | val_loss=1.0790 | val_auc=0.5528273244781783 | val_f1=0.3659\n",
            "Epoch 027 | lr=0.001000 | train_loss=1.0637 | val_loss=1.0621 | val_auc=0.5760422878828951 | val_f1=0.3831\n",
            "Epoch 028 | lr=0.001000 | train_loss=1.0714 | val_loss=1.0774 | val_auc=0.5747357007319058 | val_f1=0.3750\n",
            "Epoch 029 | lr=0.001000 | train_loss=1.0690 | val_loss=1.0692 | val_auc=0.5832854432095418 | val_f1=0.3750\n",
            "Epoch 030 | lr=0.001000 | train_loss=1.0661 | val_loss=1.0716 | val_auc=0.5815939278937381 | val_f1=0.3709\n",
            "Epoch 031 | lr=0.001000 | train_loss=1.0674 | val_loss=1.0687 | val_auc=0.6007535917592844 | val_f1=0.3814\n",
            "Epoch 032 | lr=0.001000 | train_loss=1.0640 | val_loss=1.0639 | val_auc=0.5956573597180808 | val_f1=0.3791\n",
            "Epoch 033 | lr=0.001000 | train_loss=1.0703 | val_loss=1.0751 | val_auc=0.5856004337218759 | val_f1=0.3688\n",
            "Epoch 034 | lr=0.001000 | train_loss=1.0643 | val_loss=1.0635 | val_auc=0.604640824071564 | val_f1=0.3741\n",
            "Epoch 035 | lr=0.001000 | train_loss=1.0617 | val_loss=1.0582 | val_auc=0.6181512605042017 | val_f1=0.3952\n",
            "Epoch 036 | lr=0.001000 | train_loss=1.0711 | val_loss=1.0643 | val_auc=0.5970452697207915 | val_f1=0.3846\n",
            "Epoch 037 | lr=0.001000 | train_loss=1.0582 | val_loss=1.0576 | val_auc=0.5925128761181891 | val_f1=0.4013\n",
            "Epoch 038 | lr=0.001000 | train_loss=1.0605 | val_loss=1.0693 | val_auc=0.5838113309840065 | val_f1=0.3775\n",
            "Epoch 039 | lr=0.001000 | train_loss=1.0601 | val_loss=1.0621 | val_auc=0.6011168338303062 | val_f1=0.3818\n",
            "Epoch 040 | lr=0.001000 | train_loss=1.0679 | val_loss=1.0702 | val_auc=0.6041962591488208 | val_f1=0.3832\n",
            "Epoch 041 | lr=0.001000 | train_loss=1.0597 | val_loss=1.0636 | val_auc=0.6110653293575495 | val_f1=0.3729\n",
            "Epoch 042 | lr=0.001000 | train_loss=1.0676 | val_loss=1.0661 | val_auc=0.5931580374085118 | val_f1=0.3852\n",
            "Epoch 043 | lr=0.001000 | train_loss=1.0596 | val_loss=1.0593 | val_auc=0.5996042287882895 | val_f1=0.3968\n",
            "Epoch 044 | lr=0.001000 | train_loss=1.0623 | val_loss=1.0474 | val_auc=0.6193982108972621 | val_f1=0.4044\n",
            "Epoch 045 | lr=0.001000 | train_loss=1.0585 | val_loss=1.0762 | val_auc=0.5835565193819463 | val_f1=0.3755\n",
            "Epoch 046 | lr=0.001000 | train_loss=1.0625 | val_loss=1.0767 | val_auc=0.591466522092708 | val_f1=0.3776\n",
            "Epoch 047 | lr=0.001000 | train_loss=1.0608 | val_loss=1.0553 | val_auc=0.604456492274329 | val_f1=0.3908\n",
            "Epoch 048 | lr=0.001000 | train_loss=1.0525 | val_loss=1.0711 | val_auc=0.5895256166982923 | val_f1=0.3769\n",
            "Epoch 049 | lr=0.001000 | train_loss=1.0583 | val_loss=1.0628 | val_auc=0.5966223908918405 | val_f1=0.3880\n",
            "Epoch 050 | lr=0.001000 | train_loss=1.0559 | val_loss=1.0848 | val_auc=0.5855679045811873 | val_f1=0.3653\n",
            "Epoch 051 | lr=0.001000 | train_loss=1.0548 | val_loss=1.0599 | val_auc=0.6014421252371916 | val_f1=0.3863\n",
            "Epoch 052 | lr=0.001000 | train_loss=1.0543 | val_loss=1.0521 | val_auc=0.6083111954459203 | val_f1=0.4000\n",
            "Epoch 053 | lr=0.001000 | train_loss=1.0529 | val_loss=1.0551 | val_auc=0.6071780970452697 | val_f1=0.3975\n",
            "Epoch 054 | lr=0.001000 | train_loss=1.0568 | val_loss=1.0583 | val_auc=0.6149688262401735 | val_f1=0.3813\n",
            "Epoch 055 | lr=0.001000 | train_loss=1.0582 | val_loss=1.0677 | val_auc=0.5927134724857686 | val_f1=0.3879\n",
            "Epoch 056 | lr=0.000800 | train_loss=1.0532 | val_loss=1.0627 | val_auc=0.5998427758200054 | val_f1=0.3916\n",
            "Epoch 057 | lr=0.000800 | train_loss=1.0565 | val_loss=1.0926 | val_auc=0.5706912442396314 | val_f1=0.3641\n",
            "Epoch 058 | lr=0.000800 | train_loss=1.0615 | val_loss=1.0773 | val_auc=0.5753374898346435 | val_f1=0.3732\n",
            "Epoch 059 | lr=0.000800 | train_loss=1.0525 | val_loss=1.0876 | val_auc=0.5729140688533478 | val_f1=0.3646\n",
            "Epoch 060 | lr=0.000800 | train_loss=1.0499 | val_loss=1.0668 | val_auc=0.5810300894551369 | val_f1=0.3870\n",
            "Epoch 061 | lr=0.000800 | train_loss=1.0564 | val_loss=1.0576 | val_auc=0.599387367850366 | val_f1=0.3950\n",
            "Epoch 062 | lr=0.000800 | train_loss=1.0488 | val_loss=1.0690 | val_auc=0.5893521279479534 | val_f1=0.3814\n",
            "Epoch 063 | lr=0.000800 | train_loss=1.0550 | val_loss=1.0721 | val_auc=0.5907075088099756 | val_f1=0.3858\n",
            "Epoch 064 | lr=0.000800 | train_loss=1.0507 | val_loss=1.0708 | val_auc=0.6017511520737326 | val_f1=0.3757\n",
            "Best threshold on VAL: t=0.51 | F1=0.4111 | Precision=0.2883 | Recall=0.7161\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6264\n",
            "PR-AUC: 0.2649\n",
            "Accuracy: 0.5347\n",
            "F1: 0.3779\n",
            "Precision: 0.2611\n",
            "Recall: 0.6839\n",
            "Confusion matrix:\n",
            "[[295 300]\n",
            " [ 49 106]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1075 | val_loss=1.1096 | val_auc=0.6076714556790458 | val_f1=0.3433\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0988 | val_loss=1.0983 | val_auc=0.5890431011114123 | val_f1=0.0000\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0988 | val_loss=1.0832 | val_auc=0.6072485768500949 | val_f1=0.3641\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0967 | val_loss=1.0974 | val_auc=0.6009053944158309 | val_f1=0.3508\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0912 | val_loss=1.0948 | val_auc=0.5982813770669558 | val_f1=0.3596\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0921 | val_loss=1.0756 | val_auc=0.6022933044185417 | val_f1=0.3677\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0931 | val_loss=1.0762 | val_auc=0.6100135538086202 | val_f1=0.3702\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0883 | val_loss=1.0921 | val_auc=0.5825264299268095 | val_f1=0.3596\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0940 | val_loss=1.0960 | val_auc=0.569509352127948 | val_f1=0.3508\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0917 | val_loss=1.0741 | val_auc=0.6178639197614528 | val_f1=0.3766\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0863 | val_loss=1.0959 | val_auc=0.5860775277853076 | val_f1=0.3508\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0929 | val_loss=1.0790 | val_auc=0.6017457305502847 | val_f1=0.3761\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0885 | val_loss=1.0789 | val_auc=0.5924152886961236 | val_f1=0.3703\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0941 | val_loss=1.0965 | val_auc=0.6140634318243426 | val_f1=0.3596\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0949 | val_loss=1.0854 | val_auc=0.6127188940092165 | val_f1=0.3690\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0907 | val_loss=1.0924 | val_auc=0.6179723502304147 | val_f1=0.3685\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0929 | val_loss=1.0898 | val_auc=0.6056980211439414 | val_f1=0.3623\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0982 | val_loss=1.0923 | val_auc=0.601707779886148 | val_f1=0.0000\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0889 | val_loss=1.0856 | val_auc=0.6164272160477093 | val_f1=0.3529\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0891 | val_loss=1.0723 | val_auc=0.6269232854432095 | val_f1=0.3593\n",
            "Epoch 021 | lr=0.001000 | train_loss=1.0830 | val_loss=1.0645 | val_auc=0.6154133911629167 | val_f1=0.3729\n",
            "Epoch 022 | lr=0.001000 | train_loss=1.0961 | val_loss=1.0961 | val_auc=0.6073841149362971 | val_f1=0.3696\n",
            "Epoch 023 | lr=0.001000 | train_loss=1.0987 | val_loss=1.0957 | val_auc=0.6032041203578206 | val_f1=0.3690\n",
            "Epoch 024 | lr=0.001000 | train_loss=1.0983 | val_loss=1.0946 | val_auc=0.5987964217945243 | val_f1=0.3625\n",
            "Epoch 025 | lr=0.001000 | train_loss=1.0983 | val_loss=1.0946 | val_auc=0.6041799945784765 | val_f1=0.3774\n",
            "Epoch 026 | lr=0.001000 | train_loss=1.0942 | val_loss=1.0810 | val_auc=0.5922797506099213 | val_f1=0.3654\n",
            "Epoch 027 | lr=0.001000 | train_loss=1.0874 | val_loss=1.0761 | val_auc=0.6039251829764163 | val_f1=0.3697\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3220657119.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3220657119.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"best_model_seed{seed}.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         train_model(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3220657119.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, device, lr, weight_decay, epochs, patience, model_path)\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_graphs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                             )\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 state_steps)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    169\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    319\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-06"
      ],
      "metadata": {
        "id": "f1nesMcK7YOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        # 注意：确保你的脚本开头或者这里导入了 global_max_pool\n",
        "        from torch_geometric.nn import global_max_pool\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"max\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # ---- scheduler monitors val_auc; fallback uses -val_loss ----\n",
        "        if val_auc is not None:\n",
        "            scheduler.step(val_auc)\n",
        "        else:\n",
        "            scheduler.step(-val_loss)   # 因为 mode=\"max\"，所以用 -loss 代表越大越好\n",
        "\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.2, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69fb1b7-ac0f-4243-b4c6-7156ce0d64e6",
        "id": "Z_ov13Uu9lX7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0894 | val_loss=1.0586 | val_auc=0.6412469503930603 | val_f1=0.3936\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0629 | val_loss=1.1298 | val_auc=0.6277256709135266 | val_f1=0.3654\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0595 | val_loss=1.0679 | val_auc=0.6256546489563568 | val_f1=0.2932\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0399 | val_loss=1.0530 | val_auc=0.6449444293846571 | val_f1=0.3746\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0325 | val_loss=1.0517 | val_auc=0.6404445649227433 | val_f1=0.4029\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0340 | val_loss=1.0729 | val_auc=0.6776145296828407 | val_f1=0.4063\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0255 | val_loss=1.0144 | val_auc=0.6892057468148549 | val_f1=0.4124\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0172 | val_loss=1.0289 | val_auc=0.686711846028734 | val_f1=0.3759\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0116 | val_loss=1.0248 | val_auc=0.6771916508538899 | val_f1=0.4114\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0207 | val_loss=1.0162 | val_auc=0.694692328544321 | val_f1=0.4133\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0129 | val_loss=1.0876 | val_auc=0.6137598265112497 | val_f1=0.3551\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0025 | val_loss=1.0241 | val_auc=0.6779506641366223 | val_f1=0.3911\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0067 | val_loss=1.1108 | val_auc=0.6045323936026022 | val_f1=0.2869\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0018 | val_loss=1.0269 | val_auc=0.669579831932773 | val_f1=0.4020\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0093 | val_loss=1.0391 | val_auc=0.6622499322309569 | val_f1=0.4065\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.9980 | val_loss=1.0528 | val_auc=0.6353266467877474 | val_f1=0.3689\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9954 | val_loss=1.0250 | val_auc=0.6752182163187855 | val_f1=0.4227\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0026 | val_loss=1.0707 | val_auc=0.6489997289238275 | val_f1=0.3569\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0109 | val_loss=1.0139 | val_auc=0.6809108159392789 | val_f1=0.4380\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.9923 | val_loss=1.0191 | val_auc=0.6949959338574139 | val_f1=0.4015\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9878 | val_loss=1.0642 | val_auc=0.6485551640010844 | val_f1=0.4265\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.9954 | val_loss=1.0640 | val_auc=0.6348278666305232 | val_f1=0.3792\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9854 | val_loss=1.0577 | val_auc=0.6403469775006777 | val_f1=0.4089\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9956 | val_loss=1.0288 | val_auc=0.6659257251287612 | val_f1=0.4176\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9883 | val_loss=1.0391 | val_auc=0.6535429655733261 | val_f1=0.3921\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9765 | val_loss=1.0537 | val_auc=0.6546923285443209 | val_f1=0.3924\n",
            "Epoch 027 | lr=0.001000 | train_loss=0.9793 | val_loss=1.0431 | val_auc=0.6602873407427488 | val_f1=0.3792\n",
            "Epoch 028 | lr=0.001000 | train_loss=0.9768 | val_loss=1.0659 | val_auc=0.6417023583627 | val_f1=0.3677\n",
            "Epoch 029 | lr=0.001000 | train_loss=0.9796 | val_loss=1.0179 | val_auc=0.6862347519653025 | val_f1=0.4159\n",
            "Epoch 030 | lr=0.001000 | train_loss=0.9702 | val_loss=1.0702 | val_auc=0.6601680672268907 | val_f1=0.3743\n",
            "Epoch 031 | lr=0.001000 | train_loss=0.9744 | val_loss=1.0455 | val_auc=0.6579398210897262 | val_f1=0.4147\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.9651 | val_loss=1.0235 | val_auc=0.6753483328815396 | val_f1=0.4110\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.9515 | val_loss=1.0419 | val_auc=0.6523610734616426 | val_f1=0.4037\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.9604 | val_loss=1.0348 | val_auc=0.6807373271889402 | val_f1=0.4320\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.9638 | val_loss=1.0289 | val_auc=0.6742748712388181 | val_f1=0.4238\n",
            "Epoch 036 | lr=0.000800 | train_loss=0.9542 | val_loss=1.0278 | val_auc=0.6788289509352128 | val_f1=0.4218\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.9517 | val_loss=1.0617 | val_auc=0.653835727839523 | val_f1=0.3681\n",
            "Epoch 038 | lr=0.000800 | train_loss=0.9469 | val_loss=1.0346 | val_auc=0.6699268094334508 | val_f1=0.4076\n",
            "Epoch 039 | lr=0.000800 | train_loss=0.9511 | val_loss=1.0205 | val_auc=0.6814638113309839 | val_f1=0.4171\n",
            "Epoch 040 | lr=0.000800 | train_loss=0.9487 | val_loss=1.0854 | val_auc=0.6320520466251016 | val_f1=0.3926\n",
            "Best threshold on VAL: t=0.60 | F1=0.4504 | Precision=0.3605 | Recall=0.6000\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6608\n",
            "PR-AUC: 0.3900\n",
            "Accuracy: 0.6813\n",
            "F1: 0.4099\n",
            "Precision: 0.3320\n",
            "Recall: 0.5355\n",
            "Confusion matrix:\n",
            "[[428 167]\n",
            " [ 72  83]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.1037 | val_loss=1.0869 | val_auc=0.5905882352941176 | val_f1=0.3493\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0738 | val_loss=1.0638 | val_auc=0.6480346977500678 | val_f1=0.3805\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0645 | val_loss=1.0236 | val_auc=0.6628354567633504 | val_f1=0.4041\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0561 | val_loss=1.0344 | val_auc=0.660243968555164 | val_f1=0.3799\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0405 | val_loss=1.0444 | val_auc=0.6369097316345893 | val_f1=0.3543\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0420 | val_loss=1.0392 | val_auc=0.6382108972621306 | val_f1=0.3761\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0412 | val_loss=1.0678 | val_auc=0.6566657630794254 | val_f1=0.3908\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0372 | val_loss=1.0430 | val_auc=0.6518406072106262 | val_f1=0.3925\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0400 | val_loss=1.0438 | val_auc=0.6536188669015993 | val_f1=0.3770\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0369 | val_loss=1.0252 | val_auc=0.6629655733261046 | val_f1=0.4105\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0282 | val_loss=1.0416 | val_auc=0.6296991054486311 | val_f1=0.3529\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0325 | val_loss=1.0379 | val_auc=0.6518839793982109 | val_f1=0.3911\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0254 | val_loss=1.0910 | val_auc=0.6297641637300081 | val_f1=0.3788\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0390 | val_loss=1.0626 | val_auc=0.6032854432095419 | val_f1=0.3512\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0258 | val_loss=1.0505 | val_auc=0.6313906207644349 | val_f1=0.3646\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0211 | val_loss=1.0496 | val_auc=0.625546218487395 | val_f1=0.3731\n",
            "Epoch 017 | lr=0.001000 | train_loss=1.0144 | val_loss=1.0539 | val_auc=0.6430252100840337 | val_f1=0.4218\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0220 | val_loss=1.0691 | val_auc=0.6190946055841692 | val_f1=0.3663\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0188 | val_loss=1.0212 | val_auc=0.6516237462727026 | val_f1=0.3836\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0160 | val_loss=1.0282 | val_auc=0.633841149362971 | val_f1=0.3484\n",
            "Epoch 021 | lr=0.001000 | train_loss=1.0095 | val_loss=1.0324 | val_auc=0.6347628083491461 | val_f1=0.3570\n",
            "Epoch 022 | lr=0.000800 | train_loss=1.0173 | val_loss=1.0391 | val_auc=0.6446950393060449 | val_f1=0.3867\n",
            "Epoch 023 | lr=0.000800 | train_loss=1.0091 | val_loss=1.0375 | val_auc=0.6413336947682298 | val_f1=0.3823\n",
            "Epoch 024 | lr=0.000800 | train_loss=1.0019 | val_loss=1.0466 | val_auc=0.6328327460016266 | val_f1=0.3792\n",
            "Epoch 025 | lr=0.000800 | train_loss=1.0118 | val_loss=1.0481 | val_auc=0.6216101924640824 | val_f1=0.3671\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.9984 | val_loss=1.0409 | val_auc=0.6323881810788832 | val_f1=0.3529\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.9950 | val_loss=1.0418 | val_auc=0.6449769585253456 | val_f1=0.3900\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.9892 | val_loss=1.0839 | val_auc=0.597495256166983 | val_f1=0.3514\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.9901 | val_loss=1.0482 | val_auc=0.6360748170235836 | val_f1=0.3730\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.9927 | val_loss=1.0217 | val_auc=0.6571103280021686 | val_f1=0.4028\n",
            "Best threshold on VAL: t=0.50 | F1=0.4105 | Precision=0.3467 | Recall=0.5032\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6739\n",
            "PR-AUC: 0.3517\n",
            "Accuracy: 0.6853\n",
            "F1: 0.4040\n",
            "Precision: 0.3320\n",
            "Recall: 0.5161\n",
            "Confusion matrix:\n",
            "[[434 161]\n",
            " [ 75  80]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=1.0941 | val_loss=1.0826 | val_auc=0.6129032258064516 | val_f1=0.3746\n",
            "Epoch 002 | lr=0.001000 | train_loss=1.0693 | val_loss=1.0383 | val_auc=0.6719544592030361 | val_f1=0.4000\n",
            "Epoch 003 | lr=0.001000 | train_loss=1.0558 | val_loss=1.0547 | val_auc=0.650984006505828 | val_f1=0.3636\n",
            "Epoch 004 | lr=0.001000 | train_loss=1.0514 | val_loss=1.0358 | val_auc=0.6758145838980754 | val_f1=0.4135\n",
            "Epoch 005 | lr=0.001000 | train_loss=1.0435 | val_loss=1.0275 | val_auc=0.6677039848197344 | val_f1=0.3982\n",
            "Epoch 006 | lr=0.001000 | train_loss=1.0390 | val_loss=1.0226 | val_auc=0.6566115478449444 | val_f1=0.3879\n",
            "Epoch 007 | lr=0.001000 | train_loss=1.0317 | val_loss=1.0752 | val_auc=0.6432095418812687 | val_f1=0.2667\n",
            "Epoch 008 | lr=0.001000 | train_loss=1.0404 | val_loss=1.0409 | val_auc=0.6610138248847924 | val_f1=0.3732\n",
            "Epoch 009 | lr=0.001000 | train_loss=1.0219 | val_loss=1.0484 | val_auc=0.6711846028734074 | val_f1=0.3919\n",
            "Epoch 010 | lr=0.001000 | train_loss=1.0264 | val_loss=1.0364 | val_auc=0.6730712930333425 | val_f1=0.3716\n",
            "Epoch 011 | lr=0.001000 | train_loss=1.0296 | val_loss=1.0364 | val_auc=0.6582380048793711 | val_f1=0.3854\n",
            "Epoch 012 | lr=0.001000 | train_loss=1.0189 | val_loss=1.0351 | val_auc=0.6859203036053131 | val_f1=0.3478\n",
            "Epoch 013 | lr=0.001000 | train_loss=1.0175 | val_loss=1.1647 | val_auc=0.695722417999458 | val_f1=0.4225\n",
            "Epoch 014 | lr=0.001000 | train_loss=1.0142 | val_loss=1.0958 | val_auc=0.6227161832474926 | val_f1=0.3226\n",
            "Epoch 015 | lr=0.001000 | train_loss=1.0031 | val_loss=1.0175 | val_auc=0.695310382217403 | val_f1=0.3962\n",
            "Epoch 016 | lr=0.001000 | train_loss=1.0067 | val_loss=1.0350 | val_auc=0.6816698292220114 | val_f1=0.4036\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.9989 | val_loss=1.0089 | val_auc=0.6912767687720248 | val_f1=0.4000\n",
            "Epoch 018 | lr=0.001000 | train_loss=1.0109 | val_loss=1.0223 | val_auc=0.6738845215505556 | val_f1=0.4062\n",
            "Epoch 019 | lr=0.001000 | train_loss=1.0019 | val_loss=1.0044 | val_auc=0.6891190024396856 | val_f1=0.4135\n",
            "Epoch 020 | lr=0.001000 | train_loss=1.0119 | val_loss=1.0120 | val_auc=0.6910165356465168 | val_f1=0.4023\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.9994 | val_loss=1.0226 | val_auc=0.6749037679587965 | val_f1=0.4259\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.9932 | val_loss=1.0071 | val_auc=0.7001463811330982 | val_f1=0.4213\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.9956 | val_loss=1.0333 | val_auc=0.665611276768772 | val_f1=0.3875\n",
            "Epoch 024 | lr=0.001000 | train_loss=0.9944 | val_loss=1.0162 | val_auc=0.6890973163458933 | val_f1=0.4126\n",
            "Epoch 025 | lr=0.001000 | train_loss=0.9922 | val_loss=0.9920 | val_auc=0.7044402277039847 | val_f1=0.4505\n",
            "Epoch 026 | lr=0.001000 | train_loss=0.9886 | val_loss=1.0086 | val_auc=0.692252642992681 | val_f1=0.4233\n",
            "Epoch 027 | lr=0.001000 | train_loss=0.9887 | val_loss=1.0191 | val_auc=0.6884033613445378 | val_f1=0.4034\n",
            "Epoch 028 | lr=0.001000 | train_loss=0.9787 | val_loss=1.0162 | val_auc=0.6856600704798048 | val_f1=0.4576\n",
            "Epoch 029 | lr=0.001000 | train_loss=0.9861 | val_loss=1.0156 | val_auc=0.6803252914068852 | val_f1=0.4018\n",
            "Epoch 030 | lr=0.001000 | train_loss=0.9685 | val_loss=1.0192 | val_auc=0.6862564380590946 | val_f1=0.4206\n",
            "Epoch 031 | lr=0.001000 | train_loss=0.9716 | val_loss=1.0735 | val_auc=0.6684629981024668 | val_f1=0.3985\n",
            "Epoch 032 | lr=0.001000 | train_loss=0.9770 | val_loss=1.0303 | val_auc=0.6809867172675522 | val_f1=0.3952\n",
            "Epoch 033 | lr=0.001000 | train_loss=0.9678 | val_loss=1.0455 | val_auc=0.6551152073732717 | val_f1=0.3769\n",
            "Epoch 034 | lr=0.001000 | train_loss=0.9690 | val_loss=1.0041 | val_auc=0.6926429926809433 | val_f1=0.4086\n",
            "Epoch 035 | lr=0.001000 | train_loss=0.9714 | val_loss=1.0303 | val_auc=0.683957712117105 | val_f1=0.4121\n",
            "Epoch 036 | lr=0.001000 | train_loss=0.9561 | val_loss=1.0165 | val_auc=0.6821469232854431 | val_f1=0.4153\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.9661 | val_loss=0.9986 | val_auc=0.7027053402005964 | val_f1=0.4416\n",
            "Epoch 038 | lr=0.000800 | train_loss=0.9556 | val_loss=1.0081 | val_auc=0.6897912713472486 | val_f1=0.4429\n",
            "Epoch 039 | lr=0.000800 | train_loss=0.9542 | val_loss=1.0037 | val_auc=0.7041583084846843 | val_f1=0.4234\n",
            "Epoch 040 | lr=0.000800 | train_loss=0.9367 | val_loss=1.0316 | val_auc=0.675250745459474 | val_f1=0.4160\n",
            "Epoch 041 | lr=0.000800 | train_loss=0.9434 | val_loss=1.0270 | val_auc=0.6694280292762267 | val_f1=0.3861\n",
            "Epoch 042 | lr=0.000800 | train_loss=0.9390 | val_loss=1.0180 | val_auc=0.6908755760368662 | val_f1=0.4107\n",
            "Epoch 043 | lr=0.000800 | train_loss=0.9347 | val_loss=1.0555 | val_auc=0.6555814583898076 | val_f1=0.3917\n",
            "Epoch 044 | lr=0.000800 | train_loss=0.9400 | val_loss=1.0287 | val_auc=0.6768121442125237 | val_f1=0.4153\n",
            "Epoch 045 | lr=0.000800 | train_loss=0.9439 | val_loss=1.0749 | val_auc=0.6246896177825969 | val_f1=0.3763\n",
            "Best threshold on VAL: t=0.48 | F1=0.4679 | Precision=0.3889 | Recall=0.5871\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6921\n",
            "PR-AUC: 0.4010\n",
            "Accuracy: 0.7080\n",
            "F1: 0.4252\n",
            "Precision: 0.3584\n",
            "Recall: 0.5226\n",
            "Confusion matrix:\n",
            "[[450 145]\n",
            " [ 74  81]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6756 ± 0.0128\n",
            "PR-AUC:  0.3809 ± 0.0211\n",
            "F1:      0.4130 ± 0.0089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-07"
      ],
      "metadata": {
        "id": "BVm-tT-_BVN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool,global_max_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.3, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # ---- Global Self-Attention (per-graph) ----\n",
        "        self.attn_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=4,                    # 128维用4头很稳；你也可试8\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\",\n",
        "            norm_first=True,\n",
        "        )\n",
        "        self.attn_dropout = nn.Dropout(dropout)\n",
        "        self.attn_bn = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "    def _apply_global_attention(self, x, batch):\n",
        "        \"\"\"\n",
        "        x: (N, hidden_dim)\n",
        "        batch: (N,) each node's graph id\n",
        "        return: (N, hidden_dim) after per-graph self-attention\n",
        "        \"\"\"\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "\n",
        "        # 1) split nodes by graph\n",
        "        xs = [x[batch == g] for g in range(num_graphs)]  # list of (Li, H)\n",
        "\n",
        "        # 2) pad to (B, Lmax, H)\n",
        "        x_pad = pad_sequence(xs, batch_first=True)  # (B, Lmax, H)\n",
        "\n",
        "        # 3) build key padding mask: True means \"ignore this position\"\n",
        "        lengths = torch.tensor([t.size(0) for t in xs], device=x.device)\n",
        "        Lmax = x_pad.size(1)\n",
        "        key_padding_mask = torch.arange(Lmax, device=x.device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
        "\n",
        "        # 4) self-attention\n",
        "        x_attn = self.attn_layer(x_pad, src_key_padding_mask=key_padding_mask)  # (B, Lmax, H)\n",
        "        x_attn = self.attn_dropout(x_attn)\n",
        "\n",
        "        # 5) unpad back to (N, H)\n",
        "        x_out = torch.cat([x_attn[i, :lengths[i]] for i in range(num_graphs)], dim=0)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        # ---- Global self-attention after GINE ----\n",
        "        x_attn = self._apply_global_attention(x, batch)\n",
        "        x = x + x_attn\n",
        "        # BN + ReLU：让 attention 融合后的尺度更稳定\n",
        "        x = self.attn_bn(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor((neg / pos) ** 0.5, device=device)\n",
        "\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"max\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc is not None:\n",
        "          scheduler.step(val_auc)\n",
        "        else:\n",
        "          scheduler.step(-val_loss)  # mode=\"max\" 下用 -loss 兜底\n",
        "\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.3, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb5gPuEDBWk2",
        "outputId": "e7adf11c-ea19-45e6-d840-74d5011cf55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.3.0+cu121\n",
            "Uninstalling torch-2.3.0+cu121:\n",
            "  Successfully uninstalled torch-2.3.0+cu121\n",
            "Found existing installation: torchvision 0.18.0+cu121\n",
            "Uninstalling torchvision-0.18.0+cu121:\n",
            "  Successfully uninstalled torchvision-0.18.0+cu121\n",
            "Found existing installation: torchaudio 2.3.0+cu121\n",
            "Uninstalling torchaudio-2.3.0+cu121:\n",
            "  Successfully uninstalled torchaudio-2.3.0+cu121\n",
            "Looking in links: https://download.pytorch.org/whl/cu121/torch_stable.html\n",
            "Collecting torch==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (780.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 MB\u001b[0m \u001b[31m156.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.18.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp312-cp312-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.3.0+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0+cu121) (12.1.105)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.18.0+cu121) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0+cu121) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0+cu121) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0+cu121) (1.3.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-2.3.0+cu121 torchaudio-2.3.0+cu121 torchvision-0.18.0+cu121\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt23cu121)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt23cu121)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2026.1.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7765 | val_loss=0.7517 | val_auc=0.6397072377338031 | val_f1=0.2018\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7473 | val_loss=0.7589 | val_auc=0.6544429384657089 | val_f1=0.3716\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7389 | val_loss=0.7598 | val_auc=0.621035510978585 | val_f1=0.3077\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7310 | val_loss=0.7582 | val_auc=0.608663594470046 | val_f1=0.1711\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7241 | val_loss=0.7676 | val_auc=0.6614150176199514 | val_f1=0.3855\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7227 | val_loss=0.7350 | val_auc=0.6777229601518028 | val_f1=0.3841\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7133 | val_loss=0.7420 | val_auc=0.6717267552182162 | val_f1=0.3534\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7192 | val_loss=0.7476 | val_auc=0.6629981024667932 | val_f1=0.2597\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7079 | val_loss=0.7468 | val_auc=0.6848468419625915 | val_f1=0.4213\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7260 | val_loss=0.7373 | val_auc=0.663963133640553 | val_f1=0.0613\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7072 | val_loss=0.7537 | val_auc=0.614757386825698 | val_f1=0.1379\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.7024 | val_loss=0.7300 | val_auc=0.6561344537815126 | val_f1=0.2920\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.7032 | val_loss=0.7464 | val_auc=0.6341013824884791 | val_f1=0.1163\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.7060 | val_loss=0.7598 | val_auc=0.61463811330984 | val_f1=0.0248\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.7009 | val_loss=0.7385 | val_auc=0.684564922743291 | val_f1=0.3690\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.7129 | val_loss=0.7387 | val_auc=0.65463811330984 | val_f1=0.2636\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.6961 | val_loss=0.7327 | val_auc=0.6642667389536461 | val_f1=0.2571\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.7059 | val_loss=0.7633 | val_auc=0.6584440227703985 | val_f1=0.2234\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.7084 | val_loss=0.7209 | val_auc=0.6794253185145025 | val_f1=0.3153\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.6947 | val_loss=0.7296 | val_auc=0.6817619951206287 | val_f1=0.3799\n",
            "Epoch 021 | lr=0.000800 | train_loss=0.6907 | val_loss=0.7182 | val_auc=0.6834372458660883 | val_f1=0.2922\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.6907 | val_loss=0.7302 | val_auc=0.6635619409053946 | val_f1=0.2896\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.6919 | val_loss=0.7340 | val_auc=0.6673678503659529 | val_f1=0.2654\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6908 | val_loss=0.7163 | val_auc=0.6800975874220656 | val_f1=0.3241\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6880 | val_loss=0.7276 | val_auc=0.6731255082678234 | val_f1=0.2870\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.6843 | val_loss=0.7363 | val_auc=0.6408240715641095 | val_f1=0.1858\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.6791 | val_loss=0.7080 | val_auc=0.6883870967741935 | val_f1=0.3260\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.6810 | val_loss=0.7311 | val_auc=0.6631390620764435 | val_f1=0.3411\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.6788 | val_loss=0.7007 | val_auc=0.6921008403361345 | val_f1=0.3525\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.6762 | val_loss=0.7260 | val_auc=0.6621740309026837 | val_f1=0.1848\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.6844 | val_loss=0.7133 | val_auc=0.6862564380590948 | val_f1=0.3048\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.6805 | val_loss=0.7208 | val_auc=0.6883925182976417 | val_f1=0.3908\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.6745 | val_loss=0.7353 | val_auc=0.6630848468419628 | val_f1=0.3602\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.6713 | val_loss=0.7197 | val_auc=0.6541610192464082 | val_f1=0.2537\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.6848 | val_loss=0.7178 | val_auc=0.674692328544321 | val_f1=0.3361\n",
            "Epoch 036 | lr=0.000800 | train_loss=0.6679 | val_loss=0.7173 | val_auc=0.681821631878558 | val_f1=0.2629\n",
            "Epoch 037 | lr=0.000800 | train_loss=0.6743 | val_loss=0.7310 | val_auc=0.6460070479804825 | val_f1=0.1573\n",
            "Epoch 038 | lr=0.000800 | train_loss=0.6704 | val_loss=0.7319 | val_auc=0.6975548929249118 | val_f1=0.4334\n",
            "Epoch 039 | lr=0.000800 | train_loss=0.6700 | val_loss=0.7339 | val_auc=0.646592572512876 | val_f1=0.2105\n",
            "Epoch 040 | lr=0.000800 | train_loss=0.6725 | val_loss=0.7177 | val_auc=0.671954459203036 | val_f1=0.3200\n",
            "Epoch 041 | lr=0.000800 | train_loss=0.6589 | val_loss=0.7243 | val_auc=0.6656763350501491 | val_f1=0.3500\n",
            "Epoch 042 | lr=0.000800 | train_loss=0.6647 | val_loss=0.7229 | val_auc=0.6722797506099214 | val_f1=0.3197\n",
            "Epoch 043 | lr=0.000800 | train_loss=0.6586 | val_loss=0.7305 | val_auc=0.6822011385199241 | val_f1=0.4129\n",
            "Epoch 044 | lr=0.000800 | train_loss=0.6692 | val_loss=0.7351 | val_auc=0.6457034426673895 | val_f1=0.2807\n",
            "Epoch 045 | lr=0.000800 | train_loss=0.6561 | val_loss=0.7173 | val_auc=0.6826782325833559 | val_f1=0.3333\n",
            "Epoch 046 | lr=0.000800 | train_loss=0.6554 | val_loss=0.7200 | val_auc=0.6618378964489022 | val_f1=0.2574\n",
            "Epoch 047 | lr=0.000800 | train_loss=0.6522 | val_loss=0.7259 | val_auc=0.650604499864462 | val_f1=0.3028\n",
            "Epoch 048 | lr=0.000800 | train_loss=0.6589 | val_loss=0.7273 | val_auc=0.6669232854432097 | val_f1=0.3778\n",
            "Epoch 049 | lr=0.000800 | train_loss=0.6569 | val_loss=0.7274 | val_auc=0.6570018975332068 | val_f1=0.3586\n",
            "Epoch 050 | lr=0.000640 | train_loss=0.6493 | val_loss=0.7186 | val_auc=0.6706316074817023 | val_f1=0.3605\n",
            "Epoch 051 | lr=0.000640 | train_loss=0.6346 | val_loss=0.7438 | val_auc=0.6160802385470318 | val_f1=0.2911\n",
            "Epoch 052 | lr=0.000640 | train_loss=0.6271 | val_loss=0.7253 | val_auc=0.6731905665492004 | val_f1=0.3849\n",
            "Epoch 053 | lr=0.000640 | train_loss=0.6391 | val_loss=0.7239 | val_auc=0.6525670913526701 | val_f1=0.2640\n",
            "Epoch 054 | lr=0.000640 | train_loss=0.6356 | val_loss=0.7316 | val_auc=0.6610463540254812 | val_f1=0.3810\n",
            "Epoch 055 | lr=0.000640 | train_loss=0.6279 | val_loss=0.7292 | val_auc=0.6452046625101653 | val_f1=0.3548\n",
            "Epoch 056 | lr=0.000640 | train_loss=0.6285 | val_loss=0.7438 | val_auc=0.6301761995120629 | val_f1=0.3759\n",
            "Epoch 057 | lr=0.000640 | train_loss=0.6215 | val_loss=0.7203 | val_auc=0.6821469232854432 | val_f1=0.4119\n",
            "Epoch 058 | lr=0.000640 | train_loss=0.6250 | val_loss=0.7252 | val_auc=0.6799783139062077 | val_f1=0.4101\n",
            "Best threshold on VAL: t=0.48 | F1=0.4478 | Precision=0.4167 | Recall=0.4839\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6684\n",
            "PR-AUC: 0.3830\n",
            "Accuracy: 0.7187\n",
            "F1: 0.3587\n",
            "Precision: 0.3391\n",
            "Recall: 0.3806\n",
            "Confusion matrix:\n",
            "[[480 115]\n",
            " [ 96  59]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7717 | val_loss=0.7517 | val_auc=0.6515370018975333 | val_f1=0.1900\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7526 | val_loss=0.7720 | val_auc=0.5845486581729467 | val_f1=0.0253\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7457 | val_loss=0.7403 | val_auc=0.6319327731092437 | val_f1=0.2937\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7438 | val_loss=0.7668 | val_auc=0.5799837354296556 | val_f1=0.1966\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7372 | val_loss=0.7381 | val_auc=0.643719165085389 | val_f1=0.2564\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7385 | val_loss=0.7443 | val_auc=0.6636703713743561 | val_f1=0.3502\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7251 | val_loss=0.7368 | val_auc=0.68561669829222 | val_f1=0.3755\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7242 | val_loss=0.7479 | val_auc=0.654150176199512 | val_f1=0.2629\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7175 | val_loss=0.7400 | val_auc=0.6551043643263758 | val_f1=0.0000\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7250 | val_loss=0.7318 | val_auc=0.6897804283003524 | val_f1=0.3482\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7077 | val_loss=0.7259 | val_auc=0.6762374627270263 | val_f1=0.2817\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.7061 | val_loss=0.7313 | val_auc=0.6366928706966657 | val_f1=0.3238\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.7154 | val_loss=0.7199 | val_auc=0.6811927351585796 | val_f1=0.3200\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.7142 | val_loss=0.7355 | val_auc=0.6692003252914069 | val_f1=0.2870\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.7046 | val_loss=0.7198 | val_auc=0.6777880184331797 | val_f1=0.2963\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.7128 | val_loss=0.7442 | val_auc=0.6462455950121984 | val_f1=0.0864\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.7117 | val_loss=0.7287 | val_auc=0.6716183247492546 | val_f1=0.1412\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.7102 | val_loss=0.7349 | val_auc=0.6453673082136081 | val_f1=0.0848\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.7145 | val_loss=0.7281 | val_auc=0.6606017891027379 | val_f1=0.2692\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.7088 | val_loss=0.7294 | val_auc=0.6671618324749254 | val_f1=0.3274\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.6983 | val_loss=0.7322 | val_auc=0.6853781512605043 | val_f1=0.4405\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.7025 | val_loss=0.7204 | val_auc=0.6760531309297912 | val_f1=0.2936\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.6991 | val_loss=0.7140 | val_auc=0.7000162645703442 | val_f1=0.3755\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6977 | val_loss=0.7348 | val_auc=0.6541176470588236 | val_f1=0.2412\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6997 | val_loss=0.7329 | val_auc=0.6344808891298455 | val_f1=0.2462\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.6933 | val_loss=0.7117 | val_auc=0.6951368934670642 | val_f1=0.3302\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.6950 | val_loss=0.7056 | val_auc=0.6902141501761996 | val_f1=0.3937\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.6902 | val_loss=0.7253 | val_auc=0.6711412306858227 | val_f1=0.2679\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.6905 | val_loss=0.7195 | val_auc=0.6759392789373814 | val_f1=0.3726\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.6883 | val_loss=0.7146 | val_auc=0.6950826782325834 | val_f1=0.3571\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.6884 | val_loss=0.7189 | val_auc=0.6805638384386012 | val_f1=0.3033\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.6913 | val_loss=0.7266 | val_auc=0.6782976416373001 | val_f1=0.3534\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.6779 | val_loss=0.7199 | val_auc=0.6683220384928166 | val_f1=0.2870\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.6876 | val_loss=0.7174 | val_auc=0.6682569802114393 | val_f1=0.3519\n",
            "Epoch 035 | lr=0.000640 | train_loss=0.6837 | val_loss=0.7151 | val_auc=0.6759230143670372 | val_f1=0.3913\n",
            "Epoch 036 | lr=0.000640 | train_loss=0.6720 | val_loss=0.7030 | val_auc=0.6792626728110599 | val_f1=0.3874\n",
            "Epoch 037 | lr=0.000640 | train_loss=0.6759 | val_loss=0.7203 | val_auc=0.6582813770669558 | val_f1=0.2462\n",
            "Epoch 038 | lr=0.000640 | train_loss=0.6708 | val_loss=0.7134 | val_auc=0.6686256438059095 | val_f1=0.2567\n",
            "Epoch 039 | lr=0.000640 | train_loss=0.6696 | val_loss=0.7335 | val_auc=0.6356302521008403 | val_f1=0.1371\n",
            "Epoch 040 | lr=0.000640 | train_loss=0.6772 | val_loss=0.7224 | val_auc=0.6659690973163459 | val_f1=0.2673\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.6660 | val_loss=0.7112 | val_auc=0.6867443751694225 | val_f1=0.4135\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.6642 | val_loss=0.7249 | val_auc=0.654150176199512 | val_f1=0.3293\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.6727 | val_loss=0.7173 | val_auc=0.6705557061534291 | val_f1=0.2591\n",
            "Best threshold on VAL: t=0.40 | F1=0.4371 | Precision=0.3212 | Recall=0.6839\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.7143\n",
            "PR-AUC: 0.4182\n",
            "Accuracy: 0.6493\n",
            "F1: 0.4486\n",
            "Precision: 0.3323\n",
            "Recall: 0.6903\n",
            "Confusion matrix:\n",
            "[[380 215]\n",
            " [ 48 107]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7693 | val_loss=0.7711 | val_auc=0.6648414204391434 | val_f1=0.3777\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7389 | val_loss=0.7333 | val_auc=0.6677365139604229 | val_f1=0.2188\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7285 | val_loss=0.8667 | val_auc=0.6812903225806453 | val_f1=0.4008\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7374 | val_loss=0.7342 | val_auc=0.6751856871780971 | val_f1=0.3070\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7279 | val_loss=0.7212 | val_auc=0.6925508267823257 | val_f1=0.4000\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7220 | val_loss=0.7237 | val_auc=0.6812035782054758 | val_f1=0.3972\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7159 | val_loss=0.7453 | val_auc=0.6798481973434535 | val_f1=0.1379\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7157 | val_loss=0.7538 | val_auc=0.6840552995391704 | val_f1=0.4098\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7111 | val_loss=0.7577 | val_auc=0.6827107617240444 | val_f1=0.1630\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7185 | val_loss=0.7659 | val_auc=0.6227161832474926 | val_f1=0.0380\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7137 | val_loss=0.7328 | val_auc=0.6688533477907292 | val_f1=0.3305\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.7059 | val_loss=0.7370 | val_auc=0.6812740580103009 | val_f1=0.3525\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.7040 | val_loss=0.8139 | val_auc=0.6698400650582813 | val_f1=0.4254\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.7063 | val_loss=0.7578 | val_auc=0.5792138791000271 | val_f1=0.1990\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.7023 | val_loss=0.7390 | val_auc=0.6807264841420438 | val_f1=0.2100\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.7009 | val_loss=0.7341 | val_auc=0.672865275142315 | val_f1=0.0375\n",
            "Epoch 017 | lr=0.000800 | train_loss=0.6921 | val_loss=0.7322 | val_auc=0.6610788831661697 | val_f1=0.2845\n",
            "Epoch 018 | lr=0.000800 | train_loss=0.6967 | val_loss=0.7232 | val_auc=0.6762916779615071 | val_f1=0.2032\n",
            "Epoch 019 | lr=0.000800 | train_loss=0.6953 | val_loss=0.7234 | val_auc=0.6756844673353213 | val_f1=0.2692\n",
            "Epoch 020 | lr=0.000800 | train_loss=0.6904 | val_loss=0.7329 | val_auc=0.6802385470317159 | val_f1=0.4140\n",
            "Epoch 021 | lr=0.000800 | train_loss=0.6887 | val_loss=0.7440 | val_auc=0.6324423963133641 | val_f1=0.2698\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.6911 | val_loss=0.7185 | val_auc=0.6832854432095418 | val_f1=0.3231\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.6807 | val_loss=0.7392 | val_auc=0.6295256166982922 | val_f1=0.2537\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6953 | val_loss=0.7147 | val_auc=0.6752832746001627 | val_f1=0.2963\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6842 | val_loss=0.7352 | val_auc=0.6786771482786662 | val_f1=0.4116\n",
            "Best threshold on VAL: t=0.48 | F1=0.4416 | Precision=0.4321 | Recall=0.4516\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6415\n",
            "PR-AUC: 0.3564\n",
            "Accuracy: 0.7360\n",
            "F1: 0.3926\n",
            "Precision: 0.3743\n",
            "Recall: 0.4129\n",
            "Confusion matrix:\n",
            "[[488 107]\n",
            " [ 91  64]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6747 ± 0.0300\n",
            "PR-AUC:  0.3859 ± 0.0253\n",
            "F1:      0.4000 ± 0.0371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 01-08"
      ],
      "metadata": {
        "id": "yKxcSlo4UrVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "#!pip uninstall -y torch torchvision torchaudio\n",
        "#!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "#!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "# Move import torch here\n",
        "import torch\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool,global_max_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=3, dropout=0.3,attn_dropout=0.1, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        # ---- Global Self-Attention (per-graph) ----\n",
        "        self.attn_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=4,                    # 128维用4头很稳；你也可试8\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=attn_dropout,\n",
        "            batch_first=True,\n",
        "            activation=\"gelu\",\n",
        "            norm_first=True,\n",
        "        )\n",
        "        self.attn_dropout = nn.Dropout(attn_dropout)\n",
        "        self.attn_bn = nn.BatchNorm1d(hidden_dim)\n",
        "\n",
        "\n",
        "        # 重点修改这里：+ 1 是为了给序列长度留位置\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 2 + 1, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "    def _apply_global_attention(self, x, batch):\n",
        "        \"\"\"\n",
        "        x: (N, hidden_dim)\n",
        "        batch: (N,) each node's graph id\n",
        "        return: (N, hidden_dim) after per-graph self-attention\n",
        "        \"\"\"\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "\n",
        "        # 1) split nodes by graph\n",
        "        xs = [x[batch == g] for g in range(num_graphs)]  # list of (Li, H)\n",
        "\n",
        "        # 2) pad to (B, Lmax, H)\n",
        "        x_pad = pad_sequence(xs, batch_first=True)  # (B, Lmax, H)\n",
        "\n",
        "        # 3) build key padding mask: True means \"ignore this position\"\n",
        "        lengths = torch.tensor([t.size(0) for t in xs], device=x.device)\n",
        "        Lmax = x_pad.size(1)\n",
        "        key_padding_mask = torch.arange(Lmax, device=x.device).unsqueeze(0) >= lengths.unsqueeze(1)\n",
        "\n",
        "        # 4) self-attention\n",
        "        x_attn = self.attn_layer(x_pad, src_key_padding_mask=key_padding_mask)  # (B, Lmax, H)\n",
        "        x_attn = self.attn_dropout(x_attn)\n",
        "\n",
        "        # 5) unpad back to (N, H)\n",
        "        x_out = torch.cat([x_attn[i, :lengths[i]] for i in range(num_graphs)], dim=0)\n",
        "        return x_out\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        # ---- Global self-attention after GINE ----\n",
        "        x_attn = self._apply_global_attention(x, batch)\n",
        "        x = x + x_attn\n",
        "        # BN + ReLU：让 attention 融合后的尺度更稳定\n",
        "        x = self.attn_bn(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # --- 【核心修改：Hybrid Pooling】 ---\n",
        "        # 1. 提取平均特征 (Mean)\n",
        "        m_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # 2. 提取最大特征 (Max)\n",
        "        a_pool = global_max_pool(x, batch)\n",
        "        # 3. 拼接两者：从 hidden_dim 变成 hidden_dim * 2\n",
        "        graph_emb = torch.cat([m_pool, a_pool], dim=1)\n",
        "\n",
        "        # 2. 计算序列长度 (每个 graph 的节点数)\n",
        "        # torch.bincount 会统计 batch 中每个索引出现的次数，即每个图的长度\n",
        "        lengths = torch.bincount(batch).view(-1, 1).float()\n",
        "        # 3. 对长度进行对数缩放 (使 5 和 50 的差距在数值上更平滑)\n",
        "        lengths = torch.log(lengths + 1.0)\n",
        "        # 4. 最终拼接：[Mean, Max, Length]\n",
        "        final_emb = torch.cat([graph_emb, lengths], dim=1)\n",
        "\n",
        "        # 5. 送入分类器\n",
        "        logits = self.classifier(final_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor((neg / pos) ** 0.5, device=device)\n",
        "\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-3, #改\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"max\",\n",
        "        factor=0.8, #改\n",
        "        patience=10, #改\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_auc is not None:\n",
        "          scheduler.step(val_auc)\n",
        "        else:\n",
        "          scheduler.step(-val_loss)  # mode=\"max\" 下用 -loss 兜底\n",
        "\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else (-val_loss)\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=3, dropout=0.3, pooling=\"hybrid\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-3,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94a4da1f-c1b0-4886-e280-222b73786042",
        "id": "s2X7IxpuUszA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run seed=0 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7664 | val_loss=0.7515 | val_auc=0.6073515857956084 | val_f1=0.0791\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7469 | val_loss=0.7425 | val_auc=0.6300243968555164 | val_f1=0.0592\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7435 | val_loss=0.8003 | val_auc=0.5400162645703441 | val_f1=0.2200\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7294 | val_loss=0.7540 | val_auc=0.6511791813499594 | val_f1=0.3875\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7331 | val_loss=0.7474 | val_auc=0.6867010029818379 | val_f1=0.3083\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7221 | val_loss=0.7250 | val_auc=0.6897262130658716 | val_f1=0.3618\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7144 | val_loss=0.7316 | val_auc=0.6775169422607753 | val_f1=0.1436\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7133 | val_loss=0.7446 | val_auc=0.6709026836541068 | val_f1=0.3596\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7036 | val_loss=0.7430 | val_auc=0.6520466251016537 | val_f1=0.3333\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7122 | val_loss=0.7319 | val_auc=0.6784169151531579 | val_f1=0.1780\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7075 | val_loss=0.7522 | val_auc=0.6221306587150989 | val_f1=0.1494\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.6994 | val_loss=0.7266 | val_auc=0.6773976687449174 | val_f1=0.1639\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.6954 | val_loss=0.7651 | val_auc=0.6080563838438602 | val_f1=0.0375\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.6986 | val_loss=0.7279 | val_auc=0.6598536188669016 | val_f1=0.3265\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.6954 | val_loss=0.7276 | val_auc=0.6782542694497153 | val_f1=0.1979\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.7010 | val_loss=0.7503 | val_auc=0.6244076985632963 | val_f1=0.2245\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.6962 | val_loss=0.7355 | val_auc=0.6392626728110599 | val_f1=0.2907\n",
            "Epoch 018 | lr=0.000800 | train_loss=0.6925 | val_loss=0.7388 | val_auc=0.6744483599891569 | val_f1=0.3387\n",
            "Epoch 019 | lr=0.000800 | train_loss=0.6947 | val_loss=0.7099 | val_auc=0.6856383843860125 | val_f1=0.2634\n",
            "Epoch 020 | lr=0.000800 | train_loss=0.6859 | val_loss=0.7215 | val_auc=0.6877961507183519 | val_f1=0.3664\n",
            "Epoch 021 | lr=0.000800 | train_loss=0.6884 | val_loss=0.7106 | val_auc=0.6857793439956628 | val_f1=0.3217\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.6891 | val_loss=0.7146 | val_auc=0.6824939007861209 | val_f1=0.3320\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.6875 | val_loss=0.7208 | val_auc=0.6757495256166983 | val_f1=0.2986\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6897 | val_loss=0.7182 | val_auc=0.6744808891298456 | val_f1=0.3485\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6827 | val_loss=0.7318 | val_auc=0.6595391705069125 | val_f1=0.1657\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.6791 | val_loss=0.7246 | val_auc=0.6508972621306587 | val_f1=0.2537\n",
            "Best threshold on VAL: t=0.42 | F1=0.4381 | Precision=0.3333 | Recall=0.6387\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6731\n",
            "PR-AUC: 0.3902\n",
            "Accuracy: 0.6387\n",
            "F1: 0.4018\n",
            "Precision: 0.3054\n",
            "Recall: 0.5871\n",
            "Confusion matrix:\n",
            "[[388 207]\n",
            " [ 64  91]]\n",
            "\n",
            "=== Run seed=1 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7734 | val_loss=0.7473 | val_auc=0.6069612361073462 | val_f1=0.0000\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7480 | val_loss=0.7573 | val_auc=0.6327351585795608 | val_f1=0.1053\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7494 | val_loss=0.7421 | val_auc=0.6543995662781242 | val_f1=0.3344\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7402 | val_loss=0.7605 | val_auc=0.6470046082949309 | val_f1=0.3606\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7374 | val_loss=0.7350 | val_auc=0.6475250745459474 | val_f1=0.3132\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7360 | val_loss=0.7400 | val_auc=0.6157549471401464 | val_f1=0.2174\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7253 | val_loss=0.7539 | val_auc=0.6768121442125238 | val_f1=0.3893\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7234 | val_loss=0.7410 | val_auc=0.6681919219300624 | val_f1=0.3828\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7226 | val_loss=0.7460 | val_auc=0.6550013553808619 | val_f1=0.1657\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7231 | val_loss=0.7254 | val_auc=0.677375982651125 | val_f1=0.3203\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7126 | val_loss=0.7416 | val_auc=0.6322472214692327 | val_f1=0.2054\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.7117 | val_loss=0.7387 | val_auc=0.6545838980753591 | val_f1=0.4000\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.7180 | val_loss=0.7369 | val_auc=0.6487394957983192 | val_f1=0.3063\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.7234 | val_loss=0.7370 | val_auc=0.6743290864732989 | val_f1=0.1720\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.7143 | val_loss=0.7156 | val_auc=0.666706424505286 | val_f1=0.3379\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.7117 | val_loss=0.7468 | val_auc=0.6205801030089454 | val_f1=0.0736\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.7192 | val_loss=0.7276 | val_auc=0.6664082407156411 | val_f1=0.2871\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.7090 | val_loss=0.7401 | val_auc=0.6235077256709135 | val_f1=0.2311\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.7122 | val_loss=0.7361 | val_auc=0.6443480618053674 | val_f1=0.3344\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.7103 | val_loss=0.7210 | val_auc=0.6576579018704256 | val_f1=0.3605\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.7072 | val_loss=0.7485 | val_auc=0.6602656546489564 | val_f1=0.3908\n",
            "Epoch 022 | lr=0.000800 | train_loss=0.7074 | val_loss=0.7339 | val_auc=0.6553754404987802 | val_f1=0.2574\n",
            "Epoch 023 | lr=0.000800 | train_loss=0.7033 | val_loss=0.7389 | val_auc=0.6811710490647871 | val_f1=0.3636\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6990 | val_loss=0.7379 | val_auc=0.6535863377609108 | val_f1=0.1711\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6971 | val_loss=0.7382 | val_auc=0.6220113851992409 | val_f1=0.1667\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.6966 | val_loss=0.7300 | val_auc=0.6589319598807264 | val_f1=0.3163\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.6921 | val_loss=0.7197 | val_auc=0.6745567904581189 | val_f1=0.3816\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.6864 | val_loss=0.7279 | val_auc=0.6684087828679859 | val_f1=0.2952\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.6891 | val_loss=0.7266 | val_auc=0.6590620764434806 | val_f1=0.3864\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.6851 | val_loss=0.7403 | val_auc=0.6247655191108701 | val_f1=0.3262\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.6769 | val_loss=0.7313 | val_auc=0.6316400108430469 | val_f1=0.3119\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.6854 | val_loss=0.7383 | val_auc=0.6548549742477636 | val_f1=0.3025\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.6696 | val_loss=0.7465 | val_auc=0.6156465166711846 | val_f1=0.2000\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.6798 | val_loss=0.7283 | val_auc=0.6506153429113581 | val_f1=0.3125\n",
            "Epoch 035 | lr=0.000640 | train_loss=0.6658 | val_loss=0.7502 | val_auc=0.6275738682569802 | val_f1=0.3696\n",
            "Epoch 036 | lr=0.000640 | train_loss=0.6615 | val_loss=0.7161 | val_auc=0.6660558416915152 | val_f1=0.3122\n",
            "Epoch 037 | lr=0.000640 | train_loss=0.6622 | val_loss=0.7303 | val_auc=0.6284846841962591 | val_f1=0.2640\n",
            "Epoch 038 | lr=0.000640 | train_loss=0.6470 | val_loss=0.7268 | val_auc=0.644575765790187 | val_f1=0.2358\n",
            "Epoch 039 | lr=0.000640 | train_loss=0.6617 | val_loss=0.7306 | val_auc=0.6459094605584169 | val_f1=0.2927\n",
            "Epoch 040 | lr=0.000640 | train_loss=0.6503 | val_loss=0.7458 | val_auc=0.6280075901328274 | val_f1=0.3214\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.6414 | val_loss=0.7422 | val_auc=0.6336893467064244 | val_f1=0.3137\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.6512 | val_loss=0.7508 | val_auc=0.6515803740851178 | val_f1=0.3716\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.6526 | val_loss=0.7345 | val_auc=0.6402385470317159 | val_f1=0.2934\n",
            "Best threshold on VAL: t=0.43 | F1=0.4200 | Precision=0.3429 | Recall=0.5419\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6873\n",
            "PR-AUC: 0.3961\n",
            "Accuracy: 0.6920\n",
            "F1: 0.4352\n",
            "Precision: 0.3504\n",
            "Recall: 0.5742\n",
            "Confusion matrix:\n",
            "[[430 165]\n",
            " [ 66  89]]\n",
            "\n",
            "=== Run seed=2 ===\n",
            "Epoch 001 | lr=0.001000 | train_loss=0.7761 | val_loss=0.7691 | val_auc=0.5367416644076985 | val_f1=0.0000\n",
            "Epoch 002 | lr=0.001000 | train_loss=0.7516 | val_loss=0.7745 | val_auc=0.5702033071293033 | val_f1=0.2893\n",
            "Epoch 003 | lr=0.001000 | train_loss=0.7482 | val_loss=0.7517 | val_auc=0.6505611276768772 | val_f1=0.2419\n",
            "Epoch 004 | lr=0.001000 | train_loss=0.7385 | val_loss=0.7590 | val_auc=0.6687232312279751 | val_f1=0.3920\n",
            "Epoch 005 | lr=0.001000 | train_loss=0.7338 | val_loss=0.7339 | val_auc=0.6885985361886691 | val_f1=0.1739\n",
            "Epoch 006 | lr=0.001000 | train_loss=0.7255 | val_loss=0.7370 | val_auc=0.6621523448088913 | val_f1=0.3407\n",
            "Epoch 007 | lr=0.001000 | train_loss=0.7219 | val_loss=0.7545 | val_auc=0.6561561398753049 | val_f1=0.0253\n",
            "Epoch 008 | lr=0.001000 | train_loss=0.7266 | val_loss=0.7462 | val_auc=0.6867985904039035 | val_f1=0.3871\n",
            "Epoch 009 | lr=0.001000 | train_loss=0.7176 | val_loss=0.7319 | val_auc=0.6822011385199241 | val_f1=0.3290\n",
            "Epoch 010 | lr=0.001000 | train_loss=0.7164 | val_loss=0.7310 | val_auc=0.6808782867985905 | val_f1=0.3203\n",
            "Epoch 011 | lr=0.001000 | train_loss=0.7103 | val_loss=0.7331 | val_auc=0.675370018975332 | val_f1=0.3577\n",
            "Epoch 012 | lr=0.001000 | train_loss=0.7110 | val_loss=0.7153 | val_auc=0.6991054486310653 | val_f1=0.3125\n",
            "Epoch 013 | lr=0.001000 | train_loss=0.7053 | val_loss=0.7494 | val_auc=0.6686256438059095 | val_f1=0.3862\n",
            "Epoch 014 | lr=0.001000 | train_loss=0.7108 | val_loss=0.7292 | val_auc=0.6610463540254812 | val_f1=0.2569\n",
            "Epoch 015 | lr=0.001000 | train_loss=0.6970 | val_loss=0.7160 | val_auc=0.693239360260233 | val_f1=0.3260\n",
            "Epoch 016 | lr=0.001000 | train_loss=0.6997 | val_loss=0.7331 | val_auc=0.6580862022228245 | val_f1=0.1379\n",
            "Epoch 017 | lr=0.001000 | train_loss=0.6984 | val_loss=0.7235 | val_auc=0.6767470859311466 | val_f1=0.3735\n",
            "Epoch 018 | lr=0.001000 | train_loss=0.6967 | val_loss=0.7193 | val_auc=0.6780157224179995 | val_f1=0.2963\n",
            "Epoch 019 | lr=0.001000 | train_loss=0.7056 | val_loss=0.7270 | val_auc=0.6807481702358362 | val_f1=0.2800\n",
            "Epoch 020 | lr=0.001000 | train_loss=0.7018 | val_loss=0.7086 | val_auc=0.6916237462727027 | val_f1=0.3264\n",
            "Epoch 021 | lr=0.001000 | train_loss=0.6943 | val_loss=0.7299 | val_auc=0.6703496882624017 | val_f1=0.3009\n",
            "Epoch 022 | lr=0.001000 | train_loss=0.7052 | val_loss=0.7281 | val_auc=0.6783843860124694 | val_f1=0.0958\n",
            "Epoch 023 | lr=0.001000 | train_loss=0.6993 | val_loss=0.7285 | val_auc=0.6936513960422879 | val_f1=0.4085\n",
            "Epoch 024 | lr=0.000800 | train_loss=0.6992 | val_loss=0.7056 | val_auc=0.7030089455136894 | val_f1=0.3348\n",
            "Epoch 025 | lr=0.000800 | train_loss=0.6947 | val_loss=0.7101 | val_auc=0.695733261046354 | val_f1=0.3377\n",
            "Epoch 026 | lr=0.000800 | train_loss=0.6965 | val_loss=0.7140 | val_auc=0.6890214150176199 | val_f1=0.4290\n",
            "Epoch 027 | lr=0.000800 | train_loss=0.6885 | val_loss=0.7197 | val_auc=0.6804011927351585 | val_f1=0.3105\n",
            "Epoch 028 | lr=0.000800 | train_loss=0.6830 | val_loss=0.7201 | val_auc=0.6845649227432908 | val_f1=0.3347\n",
            "Epoch 029 | lr=0.000800 | train_loss=0.6857 | val_loss=0.7169 | val_auc=0.683654106804012 | val_f1=0.3429\n",
            "Epoch 030 | lr=0.000800 | train_loss=0.6812 | val_loss=0.7066 | val_auc=0.6987042558959068 | val_f1=0.4143\n",
            "Epoch 031 | lr=0.000800 | train_loss=0.6853 | val_loss=0.7338 | val_auc=0.6432312279750609 | val_f1=0.3590\n",
            "Epoch 032 | lr=0.000800 | train_loss=0.6835 | val_loss=0.7062 | val_auc=0.687134724857685 | val_f1=0.2475\n",
            "Epoch 033 | lr=0.000800 | train_loss=0.6828 | val_loss=0.7234 | val_auc=0.6802168609379237 | val_f1=0.4026\n",
            "Epoch 034 | lr=0.000800 | train_loss=0.6748 | val_loss=0.7116 | val_auc=0.6802602331255082 | val_f1=0.3665\n",
            "Epoch 035 | lr=0.000800 | train_loss=0.6798 | val_loss=0.7276 | val_auc=0.6872106261859583 | val_f1=0.4361\n",
            "Epoch 036 | lr=0.000640 | train_loss=0.6714 | val_loss=0.7122 | val_auc=0.6810192464082406 | val_f1=0.3566\n",
            "Epoch 037 | lr=0.000640 | train_loss=0.6829 | val_loss=0.7204 | val_auc=0.6701002981837897 | val_f1=0.2234\n",
            "Epoch 038 | lr=0.000640 | train_loss=0.6759 | val_loss=0.7026 | val_auc=0.6979018704255897 | val_f1=0.4101\n",
            "Epoch 039 | lr=0.000640 | train_loss=0.6786 | val_loss=0.7006 | val_auc=0.7065979940363242 | val_f1=0.3923\n",
            "Epoch 040 | lr=0.000640 | train_loss=0.6688 | val_loss=0.7124 | val_auc=0.6814963404716725 | val_f1=0.3319\n",
            "Epoch 041 | lr=0.000640 | train_loss=0.6712 | val_loss=0.7255 | val_auc=0.6619680130116563 | val_f1=0.2640\n",
            "Epoch 042 | lr=0.000640 | train_loss=0.6705 | val_loss=0.7084 | val_auc=0.6780807806993765 | val_f1=0.3197\n",
            "Epoch 043 | lr=0.000640 | train_loss=0.6678 | val_loss=0.7038 | val_auc=0.6869287069666576 | val_f1=0.4088\n",
            "Epoch 044 | lr=0.000640 | train_loss=0.6705 | val_loss=0.7037 | val_auc=0.6987367850365953 | val_f1=0.4093\n",
            "Epoch 045 | lr=0.000640 | train_loss=0.6713 | val_loss=0.7159 | val_auc=0.6685605855245323 | val_f1=0.3119\n",
            "Epoch 046 | lr=0.000640 | train_loss=0.6628 | val_loss=0.7013 | val_auc=0.7047763621577663 | val_f1=0.3457\n",
            "Epoch 047 | lr=0.000640 | train_loss=0.6612 | val_loss=0.7171 | val_auc=0.6673678503659528 | val_f1=0.2791\n",
            "Epoch 048 | lr=0.000640 | train_loss=0.6589 | val_loss=0.7189 | val_auc=0.6788940092165898 | val_f1=0.3846\n",
            "Epoch 049 | lr=0.000640 | train_loss=0.6582 | val_loss=0.7117 | val_auc=0.6700677690431013 | val_f1=0.4029\n",
            "Epoch 050 | lr=0.000640 | train_loss=0.6614 | val_loss=0.7155 | val_auc=0.688414204391434 | val_f1=0.4092\n",
            "Epoch 051 | lr=0.000512 | train_loss=0.6483 | val_loss=0.7040 | val_auc=0.6921875847113039 | val_f1=0.3971\n",
            "Epoch 052 | lr=0.000512 | train_loss=0.6543 | val_loss=0.7196 | val_auc=0.6700894551368933 | val_f1=0.3658\n",
            "Epoch 053 | lr=0.000512 | train_loss=0.6521 | val_loss=0.7156 | val_auc=0.6795988072648413 | val_f1=0.3899\n",
            "Epoch 054 | lr=0.000512 | train_loss=0.6483 | val_loss=0.7067 | val_auc=0.6846191379777717 | val_f1=0.3651\n",
            "Epoch 055 | lr=0.000512 | train_loss=0.6490 | val_loss=0.7198 | val_auc=0.6702954730279209 | val_f1=0.3878\n",
            "Epoch 056 | lr=0.000512 | train_loss=0.6522 | val_loss=0.7168 | val_auc=0.6709026836541067 | val_f1=0.4195\n",
            "Epoch 057 | lr=0.000512 | train_loss=0.6342 | val_loss=0.7256 | val_auc=0.6686256438059094 | val_f1=0.4227\n",
            "Epoch 058 | lr=0.000512 | train_loss=0.6555 | val_loss=0.7134 | val_auc=0.6689184060721063 | val_f1=0.2936\n",
            "Epoch 059 | lr=0.000512 | train_loss=0.6400 | val_loss=0.7171 | val_auc=0.6670208728652752 | val_f1=0.3802\n",
            "Best threshold on VAL: t=0.45 | F1=0.4433 | Precision=0.3750 | Recall=0.5419\n",
            "\n",
            "Test metrics:\n",
            "ROC-AUC: 0.6758\n",
            "PR-AUC: 0.4418\n",
            "Accuracy: 0.7227\n",
            "F1: 0.4348\n",
            "Precision: 0.3756\n",
            "Recall: 0.5161\n",
            "Confusion matrix:\n",
            "[[462 133]\n",
            " [ 75  80]]\n",
            "\n",
            "=== Summary over 3 seeds ===\n",
            "ROC-AUC: 0.6788 ± 0.0061\n",
            "PR-AUC:  0.4094 ± 0.0231\n",
            "F1:      0.4239 ± 0.0157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 21 classic"
      ],
      "metadata": {
        "id": "py44mFnQ-q9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FEHrd_nrFem0",
        "outputId": "528b83ee-1933-4d86-c0ae-9444cee8b72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-183245678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGINEConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_add_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m from sklearn.metrics import (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbrca_tgca\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBrcaTcga\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mneurograph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuroGraphDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mweb_qsp_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWebQSPDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCWQDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgit_mol_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGitMolDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmolecule_gpt_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMoleculeGPTDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/datasets/web_qsp_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInMemoryDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m from torch_geometric.llm.large_graph_indexer import (\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mEDGE_RELATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mLargeGraphIndexer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlarge_graph_indexer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLargeGraphIndexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrag_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRAGQueryLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/rag_loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeatureStore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorrag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVectorRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroSamplerOutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplerOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInputEdges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputNodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackend_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeature_store\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNNRAGFeatureStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_store\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeighborSamplingRAGGraphStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvectorrag\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocumentRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/utils/backend_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mTripletLike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdgeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllm_judge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLMJudge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mg_retriever\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmolecule_gpt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMoleculeGPT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mglem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGLEM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprotein_mpnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProteinMPNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/llm/models/molecule_gpt.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBOS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_NEW_TOKENS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQFormer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_dense_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/pool/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraclus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraclus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmax_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool_neighbor_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pool_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtopk_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTopKPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msag_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAGPooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0medge_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEdgePooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/pool/topk_pool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTopKPooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     r\"\"\":math:`\\mathrm{top}_k` pooling operator from the `\"Graph U-Nets\"\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m<\u001b[0m\u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0marxiv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1905.05178\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0mTowards\u001b[0m \u001b[0mSparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/pool/topk_pool.py\u001b[0m in \u001b[0;36mTopKPooling\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mattn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     ) -> Tuple[Tensor, Tensor, OptTensor, OptTensor, Tensor, Tensor]:\n\u001b[0m\u001b[1;32m     97\u001b[0m         r\"\"\"Forward pass.\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/typing.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_caches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;32mpass\u001b[0m  \u001b[0;31m# All real errors (not unhashable args) are raised below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/typing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_TupleType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SpecialGenericAlias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1575\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0m_tp_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 66 descriptors+21 classic"
      ],
      "metadata": {
        "id": "Ib1LDZD_3LSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "P2PwT77H3Opf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 80 descriptors，使用和上方相同的代码/auc下降"
      ],
      "metadata": {
        "id": "prl2B_GHtMhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 2 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(2, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9jUAKtfYtPCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 标量edge-attr，auc下降"
      ],
      "metadata": {
        "id": "BPEM5ctg28rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 1) Install compatible torch + PyG (Colab)\n",
        "# =========================\n",
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install --no-cache-dir torch==2.3.0+cu121 torchvision==0.18.0+cu121 torchaudio==2.3.0+cu121 -f https://download.pytorch.org/whl/cu121/torch_stable.html\n",
        "!pip install --no-cache-dir torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-2.3.0+cu121.html\n",
        "\n",
        "# =========================\n",
        "# 2) Training script\n",
        "# =========================\n",
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# -*- coding: ascii -*-\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 1 -> hidden_dim (scalar hop feature)\n",
        "        self.edge_encoder = nn.Linear(1, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "IMRpR5j93IYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### 三维edge-attr，one-hot/性能若于one-hot only"
      ],
      "metadata": {
        "id": "awjkfjlb9QZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MUST set before importing torch\n",
        "import os\n",
        "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/master_thesis/sampled_data_5000/GNN\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GINEConv, global_add_pool, global_mean_pool\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    confusion_matrix,\n",
        ")\n",
        "\n",
        "from data import (\n",
        "    RESIDUAL_FEATURE_XLSX,\n",
        "    PEPTIDE_excel_PATH,\n",
        "    build_residue_feat_dict,\n",
        "    PeptideResidueDataset,\n",
        "    split_dataset,\n",
        ")\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    try:\n",
        "        torch.use_deterministic_algorithms(True)\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] deterministic_algorithms not fully supported: {e}\")\n",
        "        torch.use_deterministic_algorithms(False)\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "    worker_seed = torch.initial_seed() % 2**32\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def build_loaders_with_seed(train_dataset, val_dataset, test_dataset, batch_size, seed):\n",
        "    gen = torch.Generator()\n",
        "    gen.manual_seed(seed)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=0,\n",
        "        worker_init_fn=seed_worker,\n",
        "        generator=gen,\n",
        "    )\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "\n",
        "def _make_gin_mlp(hidden_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_dim, hidden_dim),\n",
        "    )\n",
        "\n",
        "\n",
        "class GINVirtualNodeClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = dropout\n",
        "        self.pooling = pooling\n",
        "\n",
        "        self.input_proj = nn.Linear(in_dim, hidden_dim)\n",
        "\n",
        "        self.convs = nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GINEConv(_make_gin_mlp(hidden_dim)))\n",
        "\n",
        "        self.bns = nn.ModuleList([nn.BatchNorm1d(hidden_dim) for _ in range(num_layers)])\n",
        "\n",
        "        # edge_attr encoder: 3 -> hidden_dim\n",
        "        self.edge_encoder = nn.Linear(3, hidden_dim)\n",
        "\n",
        "        self.vn_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        edge_attr = data.edge_attr\n",
        "\n",
        "        x = self.input_proj(x)\n",
        "        e = self.edge_encoder(edge_attr)\n",
        "\n",
        "        num_graphs = int(batch.max().item()) + 1 if batch.numel() > 0 else 0\n",
        "        virtualnode_emb = x.new_zeros((num_graphs, self.hidden_dim))\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = x + virtualnode_emb[batch]\n",
        "            x = self.convs[i](x, edge_index, e)\n",
        "            x = self.bns[i](x)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "            if i != self.num_layers - 1:\n",
        "                vn_update = global_add_pool(x, batch)\n",
        "                virtualnode_emb = virtualnode_emb + self.vn_mlp(vn_update)\n",
        "\n",
        "        if self.pooling == \"add\":\n",
        "            graph_emb = global_add_pool(x, batch)\n",
        "        else:\n",
        "            graph_emb = global_mean_pool(x, batch)\n",
        "\n",
        "        logits = self.classifier(graph_emb).view(-1)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def _compute_pos_weight(loader, device):\n",
        "    y_all = []\n",
        "    for data in loader:\n",
        "        y_all.append(data.y.view(-1))\n",
        "    y_all = torch.cat(y_all, dim=0).float()\n",
        "    pos = y_all.sum().item()\n",
        "    neg = len(y_all) - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0, device=device)\n",
        "    return torch.tensor(neg / pos, device=device)\n",
        "\n",
        "\n",
        "def collect_probs_labels(model, loader, device):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            labels = data.y.view(-1).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else np.array([])\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else np.array([])\n",
        "    return probs, labels\n",
        "\n",
        "\n",
        "def find_best_threshold_by_f1(probs, labels, t_min=0.05, t_max=0.95, step=0.01):\n",
        "    best_t = 0.5\n",
        "    best_f1 = -1.0\n",
        "    best_p = 0.0\n",
        "    best_r = 0.0\n",
        "\n",
        "    thresholds = np.arange(t_min, t_max + 1e-9, step)\n",
        "    for t in thresholds:\n",
        "        preds = (probs >= t).astype(int)\n",
        "        p = precision_score(labels, preds, zero_division=0)\n",
        "        r = recall_score(labels, preds, zero_division=0)\n",
        "        f1 = f1_score(labels, preds, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_t = float(t)\n",
        "            best_p = p\n",
        "            best_r = r\n",
        "\n",
        "    return best_t, best_p, best_r, best_f1\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    device,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        "    epochs=200,\n",
        "    patience=20,\n",
        "    model_path=\"best_gin_vn.pt\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "\n",
        "    pos_weight = _compute_pos_weight(train_loader, device)\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode=\"min\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        threshold=1e-4,\n",
        "        min_lr=1e-6,\n",
        "    )\n",
        "\n",
        "    best_metric = float(\"-inf\")\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        n_graphs = 0\n",
        "\n",
        "        for data in train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "            loss = criterion(logits, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "        train_loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "        val_metrics = eval_model(model, val_loader, device, pos_weight=pos_weight)\n",
        "        val_loss = val_metrics[\"loss\"]\n",
        "        val_auc = val_metrics[\"roc_auc\"]\n",
        "        val_f1 = val_metrics[\"f1\"]\n",
        "\n",
        "        lr_current = optimizer.param_groups[0][\"lr\"]\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:03d} | lr={lr_current:.6f} | train_loss={train_loss:.4f} | \"\n",
        "            f\"val_loss={val_loss:.4f} | val_auc={val_auc} | val_f1={val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        monitor = val_auc if val_auc is not None else val_f1\n",
        "        if monitor > best_metric:\n",
        "            best_metric = monitor\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), model_path, _use_new_zipfile_serialization=False)\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    return {\"best_metric\": best_metric}\n",
        "\n",
        "\n",
        "def eval_model(model, loader, device, pos_weight=None, threshold=0.5):\n",
        "    model.eval()\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_probs = []\n",
        "    all_labels = []\n",
        "    total_loss = 0.0\n",
        "    n_graphs = 0\n",
        "\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight) if pos_weight is not None else nn.BCEWithLogitsLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            logits = model(data)\n",
        "            y = data.y.view(-1).float()\n",
        "\n",
        "            loss = criterion(logits, y)\n",
        "            total_loss += loss.item() * data.num_graphs\n",
        "            n_graphs += data.num_graphs\n",
        "\n",
        "            probs = torch.sigmoid(logits).detach().cpu()\n",
        "            all_probs.append(probs)\n",
        "            all_labels.append(y.detach().cpu())\n",
        "\n",
        "    loss = total_loss / max(n_graphs, 1)\n",
        "\n",
        "    probs = torch.cat(all_probs).numpy() if all_probs else []\n",
        "    labels = torch.cat(all_labels).numpy() if all_labels else []\n",
        "\n",
        "    roc_auc = None\n",
        "    pr_auc = None\n",
        "    if len(set(labels)) >= 2:\n",
        "        roc_auc = roc_auc_score(labels, probs)\n",
        "        pr_auc = average_precision_score(labels, probs)\n",
        "\n",
        "    preds = (probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    f1 = f1_score(labels, preds) if len(labels) > 0 else 0.0\n",
        "    precision = precision_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    recall = recall_score(labels, preds, zero_division=0) if len(labels) > 0 else 0.0\n",
        "    cm = confusion_matrix(labels, preds) if len(labels) > 0 else None\n",
        "\n",
        "    return {\n",
        "        \"loss\": loss,\n",
        "        \"roc_auc\": roc_auc,\n",
        "        \"pr_auc\": pr_auc,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cm\": cm,\n",
        "    }\n",
        "\n",
        "\n",
        "def main():\n",
        "    df_feat = pd.read_excel(RESIDUAL_FEATURE_XLSX)\n",
        "    meta_cols = [\"ID\", \"Name\", \"Type\", \"SMILES (L-isomer)\"]\n",
        "    feature_cols = [c for c in df_feat.columns if c not in meta_cols]\n",
        "\n",
        "    residue_feat_dict = build_residue_feat_dict(RESIDUAL_FEATURE_XLSX, feature_cols)\n",
        "    dataset = PeptideResidueDataset(PEPTIDE_excel_PATH, residue_feat_dict)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    seeds = [0, 1, 2]\n",
        "    results = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"\\n=== Run seed={seed} ===\")\n",
        "        set_seed(seed)\n",
        "\n",
        "        train_dataset, val_dataset, test_dataset = split_dataset(dataset, seed=seed)\n",
        "        train_loader, val_loader, test_loader = build_loaders_with_seed(\n",
        "            train_dataset, val_dataset, test_dataset, batch_size=32, seed=seed\n",
        "        )\n",
        "\n",
        "        in_dim = dataset[0].x.shape[1]\n",
        "        model = GINVirtualNodeClassifier(\n",
        "            in_dim=in_dim, hidden_dim=128, num_layers=4, dropout=0.2, pooling=\"mean\"\n",
        "        )\n",
        "\n",
        "        model_path = f\"best_model_seed{seed}.pt\"\n",
        "\n",
        "        train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            val_loader,\n",
        "            device=device,\n",
        "            lr=1e-3,\n",
        "            weight_decay=1e-4,\n",
        "            epochs=200,\n",
        "            patience=20,\n",
        "            model_path=model_path,\n",
        "        )\n",
        "\n",
        "        pos_weight = _compute_pos_weight(train_loader, device)\n",
        "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "        val_probs, val_labels = collect_probs_labels(model, val_loader, device)\n",
        "        best_t, best_p, best_r, best_f1 = find_best_threshold_by_f1(val_probs, val_labels)\n",
        "        print(f\"Best threshold on VAL: t={best_t:.2f} | F1={best_f1:.4f} | Precision={best_p:.4f} | Recall={best_r:.4f}\")\n",
        "\n",
        "        metrics = eval_model(model, test_loader, device, pos_weight=pos_weight, threshold=best_t)\n",
        "\n",
        "        print(\"\\nTest metrics:\")\n",
        "        print(f\"ROC-AUC: {metrics.get('roc_auc'):.4f}\")\n",
        "        print(f\"PR-AUC: {metrics.get('pr_auc'):.4f}\")\n",
        "        print(f\"Accuracy: {metrics.get('acc'):.4f}\")\n",
        "        print(f\"F1: {metrics.get('f1'):.4f}\")\n",
        "        print(f\"Precision: {metrics.get('precision'):.4f}\")\n",
        "        print(f\"Recall: {metrics.get('recall'):.4f}\")\n",
        "        print(f\"Confusion matrix:\\n{metrics.get('cm')}\")\n",
        "\n",
        "        results.append({\n",
        "            \"seed\": seed,\n",
        "            \"best_threshold\": best_t,\n",
        "            \"test_roc_auc\": metrics.get(\"roc_auc\"),\n",
        "            \"test_pr_auc\": metrics.get(\"pr_auc\"),\n",
        "            \"test_f1\": metrics.get(\"f1\"),\n",
        "            \"test_precision\": metrics.get(\"precision\"),\n",
        "            \"test_recall\": metrics.get(\"recall\"),\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv(\"results_3seeds.csv\", index=False)\n",
        "\n",
        "    test_roc = results_df[\"test_roc_auc\"].astype(float).values\n",
        "    test_pr = results_df[\"test_pr_auc\"].astype(float).values\n",
        "    test_f1 = results_df[\"test_f1\"].astype(float).values\n",
        "\n",
        "    print(\"\\n=== Summary over 3 seeds ===\")\n",
        "    print(f\"ROC-AUC: {test_roc.mean():.4f} ± {test_roc.std():.4f}\")\n",
        "    print(f\"PR-AUC:  {test_pr.mean():.4f} ± {test_pr.std():.4f}\")\n",
        "    print(f\"F1:      {test_f1.mean():.4f} ± {test_f1.std():.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "etRLCz6q9Tdv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "10OXnAlyYlks0UjPeQ9cpmTSJLTsV0W3e",
      "authorship_tag": "ABX9TyM/Fkym4S0GTjZ909wfBd14",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}